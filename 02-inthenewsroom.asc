:chapnum: 02
:figure-number: 00

== Στην αίθουσα σύνταξης

image::figs/incoming/02-00-cover.png[float="none",role="informal"]

Πως συνυπάρχει η «δημοσιογραφία δεδομένων» μέσα στις αίθουσες σύνταξης όλου του κόσμου; Πως κορυφαίοι δημοσιογράφοι του είδους πείθουν τους συναδέλφους τους πως το να δημοσιεύεις σύνολα δεδομένων ή το να παρουσιάζεις ειδησεογραφικές εφαρμογές που βασίζονται σε δεδομένα αποτελεί καλή ιδέα? Πρέπει άραγε οι δημοσιογράφοι να μάθουν πώς να κωδικοποιούν ή πώς να δουλεύουν σε συνεργασία με ταλαντούχους προγραμματιστές; Στην ενότητα αυτή εξετάζουμε τον ρόλο των δεδομένων αλλά και την «δημοσιογραφία δεδομένων» στον Αυστραλιανό Οργανισμό Ραδιοτηλεόρασης, στο BBC, στη Chicago Tribune, στη Guardian, στον οργανισμό Texas Tribune καθώς επίσης και στη Zeit Online. Μαθαίνουμε πως να εντοπίζουμε και να προσλαμβάνουμε καλούς προγραμματιστές, πως να εμπλέκουμε ανθρώπους γύρω από ένα θέμα μέσα από δράσεις hackathons και άλλες εκδηλώσεις, πως να συνεργαζόμαστε πέρα από τα σύνορα και τα επιχειρηματικά μοντέλα, όσον αφορά την «δημοσιογραφία δεδομένων».

=== Η «δημοσιογραφία δεδομένων» στο ABC 

Ο Αυστραλιανός Οργανισμός Ραδιοτηλεόρασης αποτελεί τον εθνικό, δημόσιο οργανισμό ραδιοτηλεόρασης της χώρας. Η ετήσια χρηματοδότηση του ανέρχεται περίπου στο 1 δισεκατομμύριο δολάρια (AUS), το οποίο και διανέμεται σε εφτά ραδιοφωνικά δίκτυα, 60 τοπικούς ραδιοφωνικούς σταθμούς, τρεις υπηρεσίες ψηφιακής τηλεόρασης, μία νέα τηλεοπτική υπηρεσία διεθνούς εμβέλειας, καθώς επίσης και μια online πλατφόρμα για τη διανομή μιας συνεχώς διευρυνόμενης προσφοράς ψηφιακού αλλά και παραγόμενου από χρήστες (user-generated) περιεχομένου. Κατά την τελευταία μέτρηση, οι εργαζόμενοι ανήλθαν σε πάνω από 4,500 ισοδύναμα πλήρους απασχόλησης άτομα, από τα οποία περίπου το 70% παράγει περιεχόμενο.

Ανήκουμε σε έναν εθνικό οργανισμό ραδιοτηλεόρασης κι είμαστε ιδιαίτερα υπερήφανοι για την ανεξαρτησία μας• Αν και χρηματοδοτούμαστε από την κυβέρνηση, αυτοδιοικούμαστε βάσει νόμου. Οι παραδόσεις μας αφορούν μια ανεξάρτητη δημοσιογραφία που εξυπηρετεί το δημόσιο συμφέρον. Το ABC έχει καταφέρει να θεωρείται ως ο πιο αξιόπιστος ειδησεογραφικός οργανισμός της χώρας.

Αυτές είναι συναρπαστικές στιγμές• υπό την επίβλεψη ενός γενικού διευθυντή (το πρώην ανώτερο στέλεχος εφημερίδας, Mark Scott), οι δημιουργοί περιεχομένου στο ABC ενθαρρύνονται να είναι «ευέλικτοι» όπως το θέτει το γενικό μότο της εταιρείας.

Βέβαια, κάτι τέτοιο πιο εύκολα λέγεται παρά γίνεται.

Τελευταία έχει αναληφθεί μια πρωτοβουλία προς αυτή την κατεύθυνση η οποία ενθαρρύνει, μέσω χρηματικού ανταλλάγματος, την ανταγωνιστικότητα στην ανάπτυξη πολυπλατφορμικών πρότζεκτ.

Έτσι κάπως έγινε και η σύλληψη της ιδέας του πρώτου πρότζεκτ δημοσιογραφίας δεδομένων στο ABC.

Κάποια στιγμή στις αρχές του 2010, περιπλανήθηκα με την πρόταση μου ανά χείρας σε μια συνάντηση κορυφαίων στελεχών, αντιμέτωπος με τρία άτομα, τα οποία και ήταν υπεύθυνα για καινοτομίες και νέες ιδέες.

Αναμασούσα την πρότασή μου για αρκετό διάστημα, απολαμβάνοντας με λαιμαργία τη δημοσιογραφία δεδομένων που προσέφερε το θρυλικό τώρα, Datablog της Guardian, κι αυτό ήταν μόνο η αρχή.

Επιχείρημα μου υπήρξε πως χωρίς αμφιβολία, μέσα σε πέντε χρόνια το ABC θα αποκτούσε τη δικιά του μονάδα δημοσιογραφίας δεδομένων. Ήταν αναπόφευκτο, αποφάνθηκα. Αλλά η ερώτηση ήταν πώς θα φτάναμε σε αυτό το σημείο και ποιος επρόκειτο να το ξεκινήσει.

Για όσους αναγνώστες δεν είναι εξοικειωμένοι με το ABC, σκεφτείτε μια απέραντη γραφειοκρατία που συσσωρεύτηκε για πάνω από 70 ολόκληρα χρόνια. Η βασική του προσφορά ήταν πάντα το ραδιόφωνο και η τηλεόραση. Με την έλευση ενός δικτυακού τόπου, την τελευταία δεκαετία το προσφερόμενο περιεχόμενο ξεδιπλώθηκε σε κείμενο, καρέ φωτογραφιών και ένα βαθμό διαδραστικότητας που προηγουμένως δεν μπορούσε να φανταστεί κανείς. Ο δικτυακός χώρος ανάγκασε το ABC να αναθεωρήσει τον τρόπο μοιρασιάς της πίτας (όπου πίτα τα χρήματα) αλλά και να ξανασκεφτεί το τι είδους πίτα θα φτιάξει (δηλαδή το περιεχόμενο).

Φυσικά είναι μια εργασία που βρίσκεται σε εξέλιξη.

Αλλά κάτι άλλο συνέβαινε με τη «δημοσιογραφία δεδομένων». Η Government 2.0 (η οποία όπως ανακαλύψαμε, μάλλον παραβιάζει παρά τηρεί όσα θα όφειλε στην Αυστραλία) ξεκίνησε να προσφέρει νέους τρόπους αφήγησης ιστοριών που έως τώρα βρίσκονταν θαμμένες στα 0 και 1.

Όλα αυτά τα ανέφερα σε όσους παραβρέθηκαν στη συνάντηση. Επίσης τόνισα πως οφείλαμε να αναγνωρίσουμε νέου τύπου ικανότητες και να εκπαιδεύσουμε τους δημοσιογράφους σε νέα εργαλεία. Χρειαζόμασταν ένα πρότζεκτ για το ξεκίνημα.

Και μου έδωσαν τα λεφτά.

Στις 24 Νοεμβρίου του 2011, το πολυπλατφορμικό πρότζεκτ του ABC και οι ειδήσεις του στο διαδίκτυο, εξέπεμψαν ζωντανά με το http://bit.ly/abc-coal["Οι αριθμοί για το φυσικό αέριο κοιτασμάτων γαιάνθρακα της Αυστραλίας".]

[[FIG021]]
.Οι αριθμοί για το φυσικό αέριο κοιτασμάτων γαιάνθρακα  (ABC News Online)
image::figs/incoming/02-01.png[float="none"]

Αποτελούνταν από πέντε σελίδες με διαδραστικούς χάρτες, οπτικοποιήσεις δεδομένων και κείμενο.

Δεν ήταν αποκλειστικά «δημοσιογραφία δεδομένων», αλλά ένα υβρίδιο από δημοσιογραφικά είδη που γεννήθηκαν από την μίξη διάφορων ανθρώπων μέσα από την ομάδα και την ιστορία, η οποία και κάνει θραύση ως ένα από τα σημαντικότερα θέματα στην Αυστραλία.

Το «διαμάντι» ήταν ένας διαδραστικός χάρτης που απεικόνιζε τις πηγές φυσικού αερίου στην Αυστραλία και τις μισθώσεις τους. Οι χρήστες μπορούσαν να αναζητήσουν με βάση την τοποθεσία και να στραφούν) σε επιλογές που έδειχναν κοιτάσματα ή μισθώσεις. Με την επιλογή του zoom in, οι χρήστες μπορούσαν να δουν ποιος έκανε τις εξορύξεις, την κατάσταση του κοιτάσματος και την ημερομηνία γεώτρησης. Ένας άλλος χάρτης αναπαριστούσε την τοποθεσία της δραστηριότητας των κοιτασμάτων φυσικού αερίου σε συνάρτηση με την τοποθεσία του συστήματος υπόγειων υδάτων στην Αυστραλία. 

[[FIG023]]
.Διαδραστικός χάρτης των πηγών φυσικού αερίου και των μισθώσεων στην Αυστραλία (ABC News Online)
image::figs/incoming/02-02.png[float="none"]

Συμπεριλαμβάνονταν οπτικοποιήσεις δεδομένων που αφορούσαν ειδικά στο θέμα της σπατάλης αλατιού και παραγωγής νερού που θα προέκυπτε ανάλογα με το ποιο σενάριο θα εφαρμόζονταν.

Άλλο ένα τμήμα του πρότζεκτ ερευνούσε την απελευθέρωση χημικών στο δίκτυο  ποταμών της περιοχής.

==== Η ομάδα μας

   * Ένας κατασκευαστής και σχεδιαστής ιστοσελίδων
   *	Ένας δημοσιογράφος - επικεφαλής
   *	Ένας part-time ερευνητής με ειδικότητα στην εξαγωγή - τον καθαρισμό των δεδομένων και τα λογιστικά φύλλα Excel
   *	Ένας part-time νέος δημοσιογράφος
   *	Ένας σύμβουλος παραγωγής
   *	Ένας ακαδημαϊκός σύμβουλος με ειδικότητα στην εξόρυξη δεδομένων, την γραφική οπτικοποίηση και προηγμένες ερευνητικές ικανότητες
   *	Τις υπηρεσίες ενός διευθυντή διαχείρισης έργου (project manager) μαζί με την διοικητική βοήθεια της πολυπλατφορμικής μονάδας του ABC
   *	Σημαντικό, το γεγονός πως είχαμε ένα γκρουπ αναφοράς δημοσιογράφων και άλλων ειδικοτήτων τους οποίους και συμβουλευόμασταν όποτε κρίναμε αναγκαίο

==== Από πού λάβαμε τα δεδομένα;

Τα δεδομένα για τους διαδραστικούς χάρτες προήλθαν από το κατέβασμα (download) αρχείων shapefiles (ένα συνηθισμένο είδος αρχείων για γεωχωρικά δεδομένα) μέσα  από κυβερνητικούς δικτυακούς ιστότοπους. 

Άλλα δεδομένα σχετικά με το αλάτι και το νερό προήλθαν από μια πληθώρα εκθέσεων και αναφορών.

Τα δεδομένα για τις αποδεσμεύσεις χημικών προήλθαν από περιβαλλοντικές άδειες που εκδόθηκαν από την κυβέρνηση.

==== Τι μάθαμε;

Το πρότζεκτ “Coal Seam Gas by the Numbers” ήταν φιλόδοξο όσον αφορά το περιεχόμενο και την  κλίμακά του. Βασικότερη σκέψη μου αποτέλεσε το τι μάθαμε και πόσο διαφορετικά θα μπορούσαμε να το κάνουμε την επόμενη φορά.

Το πρότζεκτ «δημοσιογραφία δεδομένων» έφερε μέσα στην αίθουσα πολλά άτομα που φυσιολογικά δεν συναντιούνται στο ABC: με άλλα λόγια τους συντάκτες - γραφιάδες και τους χάκερς. Πολλοί από μας δεν μιλούσαμε την ίδια γλώσσα ή ακόμα δεν αναγνωρίζαμε τη δουλειά του άλλου γκρουπ. Η «δημοσιογραφία δεδομένων» είναι «αποδιοργανωτική»! 

Πρακτικά στοιχεία:

  *	Η συστέγαση της ομάδας είναι ζωτικής σημασίας. Ο προγραμματιστής και σχεδιαστής μας βρίσκονταν μακριά και ερχόταν μόνο στις συναντήσεις μας. Κάτι τέτοιο αναμφίβολα δεν είναι και ότι καλύτερο.  Τοποθετείστε όλους στο ίδιο δωμάτιο με τους δημοσιογράφους.
  *	Ο σύμβουλος EP βρισκόταν επίσης σε άλλο μέρος του κτιρίου. Έπρεπε να είμαστε πιο κοντά, για τον καθορισμό κάθε βήματος. 
  *	Διάλεξε μια ιστορία η οποία βασίζεται αποκλειστικά και μόνο στα δεδομένα.


==== Η Μεγάλη εικόνα: Ιδέες

Οι μεγάλοι μιντιακοί οργανισμοί χρειάζονται να προσαρμόσουν την χωρητικότητα στις κτιριακές υποδομές προκειμένου να ανταπεξέλθουν στις προκλήσεις της δημοσιογραφίας δεδομένων. Η διαίσθηση μου λέει, πως υπάρχουν πολλοί γκουρού-«κομπιουτεράδες» και χάκερς κρυμμένοι στα τεχνικά τμήματα των συγκεκριμένων οργανισμών που είναι απεγνωσμένοι να βγουν έξω. Επομένως, αυτό που χρειαζόμαστε είναι «συναντήσεις συντακτών - γραφιάδων και χακεράδων» μέσω workshops όπου οι κρυφοί γκουρού-«κομπιουτεράδες», οι νεότεροι δημοσιογράφοι, οι κατασκευαστές ιστοσελίδων και οι σχεδιαστές θα «βγουν από την αφάνεια» για να συνεργαστούν με πιο έμπειρους δημοσιογράφους με στόχο την ανταλλαγή δεξιοτήτων και την καθοδήγηση. Ζητούμενο: Κατέβασε αυτό το dataset και κυνήγα το!

Ipso facto, η δημοσιογραφία δεδομένωνείναι διεπιστημονική. Οι ομάδες της είναι φτιαγμένες από ανθρώπους, οι οποίοι δεν θα είχαν συνεργαστεί ποτέ μαζί στο παρελθόν. Το ψηφιακό τοπίο έχει καταστήσει τα όρια ασαφή.
  
Ζούμε σε ένα αποδομημένο,  πολιτικό σώμα στο οποίο λείπει η εμπιστοσύνη. Το επιχειρησιακό μοντέλο που άλλοτε παρήγαγε επαγγελματική ανεξάρτητη δημοσιογραφία –ατελές όπως είναι– είναι στο χείλος της κατάρρευσης. Οφείλουμε να αναρωτηθούμε, όπως πολλοί ήδη αναρωτιούνται τώρα, πως θα ήταν ο κόσμος χωρίς μια βιώσιμη τέταρτη εξουσία. Ο Αμερικάνος δημοσιογράφος και διανοούμενος Walter Lippman δήλωσε τη δεκαετία του 1920 ότι «Είναι παραδεκτό πως μια υγιής δημόσια γνώμη δεν μπορεί να υπάρξει χωρίς την πρόσβαση σε ειδήσεις». Η δήλωση αυτή δεν είναι λιγότερο αληθινή σήμερα. Στον 21ο αιώνα, ο καθένας συχνάζει μέσα στη μπλογκόσφαιρα. Είναι δύσκολο να διακρίνεις αυτούς που περιστρέφονται σε αυτήν, τους ψεύτες, τους υποκριτές τους έχοντες έννομο συμφέρον από τους επαγγελματίες δημοσιογράφους. Λίγο πολύ κάθε δικτυακός τόπος ή πηγή μπορεί να φτιαχτεί ώστε να φαίνεται αξιόπιστη, καθωσπρέπει και έντιμη. Οι αξιόπιστοι τίτλοι εφημερίδων σβήνουν, αργοπεθαίνουν. Και σε αυτό το νέο χώρο της «άχρηστης» δημοσιογραφίας, οι υπερσύνδεσμοι μπορούν να μεταφέρουν αδιάκοπα τον αναγνώστη σε άλλες περισσότερο άχρηστες, αλλά φαινομενικά εξαιρετικές πηγές που με τη σειρά τους επανασυνδέουν σε ένα ψηφιακό διάδρομο με καθρέφτες. Ο τεχνικός όρος για αυτό: οι σαχλαμάρες μπερδεύουν το μυαλό.

Στον ψηφιακό χώρο, ο καθένας είναι και ένας αφηγητής τώρα, σωστά; Λάθος. Εάν η επαγγελματική δημοσιογραφία – και με αυτό εννοώ όσους ενστερνίζονται την  δεοντολογική, ισορροπημένη, θαρραλέα αφήγηση που βασίζεται στην αναζήτηση της αλήθειας– πρόκειται να επιβιώσει, τότε η τέχνη πρέπει να επανακαθορίσει τον εαυτό της στον ψηφιακό χώρο. Η δημοσιογραφία δεδομένων αποτελεί ένα ακόμα εργαλείο με το οποίο θα πλοηγηθούμε στον ψηφιακό χώρο. Είναι εκεί όπου θα σχεδιάσουμε, ταξινομήσουμε, φιλτράρουμε, εξάγουμε και θα δούμε την ιστορία ανάμεσα σε όλα αυτά τα μηδέν και ένα. Στο μέλλον θα δουλεύουμε δίπλα-δίπλα με του χάκερς, τους προγραμματιστές, τους σχεδιαστές και αυτούς που γράφουν κώδικα. Είναι μια μετάβαση που απαιτεί σοβαρή κτιριακή χωρητικότητα. Χρειαζόμαστε νέους μάνατζερ ειδήσεων που αντιλαμβάνονται αυτή την ψηφιακή/δημοσιογραφική σχέση,  να ξεκινήσουν να επενδύουν σε ένα τέτοιο οικοδόμημα.

&mdash; _Wendy Carlisle, Australian Broadcasting Corporation_

=== Δημοσιογραφία δεδομένων στο BBC

Ο όρος δημοσιογραφία δεδομένων μπορεί να καλύψει ένα εύρος διαφόρων κλάδων και χρησιμοποιείται με ποικίλους τρόπους στους ειδησεογραφικούς οργανισμούς, επομένως ίσως είναι χρήσιμο να ορίσουμε τι εννοούμε λέγοντας δημοσιογραφία δεδομένων στο BBC. Ευρέως, ο συγκεκριμένος όρος καλύπτει πρότζεκτ που χρησιμοποιούν τα δεδομένα για να κάνουν ένα η περισσότερα από τα παρακάτω:

  *	Να επιτρέψουν στον αναγνώστη να ανακαλύψει πληροφορίες που σχετίζονται προσωπικά 
  *	Να αποκαλύψουν μια ιστορία, η οποία είναι αξιοσημείωτη και παραμένει άγνωστη
  *	Να βοηθήσουν τον αναγνώστη να κατανοήσει καλύτερα ένα περίπλοκο θέμα


Οι κατηγορίες αυτές μπορεί να αλληλεπικαλύπτονται, και σε ένα online περιβάλλον, μπορούν συχνά να ωφελούνται από κάποιο επίπεδο οπτικοποίησης.

==== Κάντο προσωπικό

Στον ειδησεογραφικό δικτυακό τόπο του BBC, χρησιμοποιούμε για τα καλά τα δεδομένα, παρέχοντας υπηρεσίες και εργαλεία στους χρήστες μας πάνω από μία δεκαετία.

Το πιο σύμφωνο παράδειγμα, που δημοσιεύσαμε πρώτα το 1999, είναι οι πίνακες των σχολείων μας (http://bbc.in/school-league-tables[school league tables]), οι οποίοι χρησιμοποιούν τα δεδομένα που δημοσιεύονται κάθε χρόνο από την κυβέρνηση. Οι αναγνώστες μπορούν να βρουν τα τοπικά σχολεία καταχωρώντας τον ταχυδρομικό κώδικα και να τα συγκρίνουν με βάση διάφορους δείκτες. Οι δημοσιογράφοι που ασχολούνται με τον χώρο της εκπαίδευσης δουλεύουν επίσης με την ομάδα ανάπτυξης προκειμένου να «ψαρεύουν» δεδομένα για τις ιστορίες πριν τη δημοσίευση. 

Όταν ξεκινήσαμε να το κάνουμε αυτό, δεν υπήρχε κάποιος επίσημος δικτυακός τόπος που να παρείχε δυνατότητα στο κοινό να εξερευνήσει τα δεδομένα. Αλλά τώρα που το αρμόδιο Τμήμα για την Εκπαίδευση (Department for Education) έχει τη δική του παρόμοια υπηρεσία, η προσφορά μας έχει μετατοπιστεί στο να επικεντρώνουμε περισσότερο στις ιστορίες που αναδύονται από τα δεδομένα.

Η πρόκληση στο συγκεκριμένο κομμάτι πρέπει να σχετίζεται με την παροχή πρόσβασης σε δεδομένα για τα οποία υπάρχει ένα ξεκάθαρο δημόσιο ενδιαφέρον. Ένα πρόσφατο παράδειγμα ενός πρότζεκτ όπου εκθέσαμε ένα ευρύ σύνολο δεδομένων φυσιολογικά όχι διαθέσιμο στο ευρύτερο κοινό, ήταν η ξεχωριστή αναφορά http://bbc.in/road-deaths[«Κάθε θάνατος σε κάθε δρόμο»]. Παρείχαμε αναζήτηση με βάση τον ταχυδρομικό κώδικα, επιτρέποντας στους χρήστες να βρίσκουν την τοποθεσία όλων των  θανατηφόρων τροχαίων ατυχημάτων στο Ηνωμένο Βασίλειο την περασμένη δεκαετία.

http://bbc.in/police-data[Οπτικοποιήσαμε κάποια από τα κύρια γεγονότα και νούμερα] που προκύπτουν από τα στοιχεία της αστυνομίας και, για να δώσουμε στο πρότζεκτ ένα ανθρώπινο πρόσωπο και μια πιο δυναμική αίσθηση, συνεργαστήκαμε με την Λονδρέζικη Ένωση Ασθενοφόρων (London Ambulance Association) αλλά και τον ραδιοφωνικό - τηλεοπτικό σταθμό του BBC στο Λονδίνο προκειμένου να παρακολουθήσουμε τα ατυχήματα σε όλη τη πρωτεύουσα όπως ακριβώς αυτά συνέβησαν.  Αυτό παρουσιάστηκε http://bbc.in/road-deaths-feed[ζωντανά μέσω διαδικτύου], όπως επίσης και μέσω Twitter με χρήση του hashtag #crash24, και οι συγκρούσεις απεικονίζονταν πάνω στον http://bbc.in/road-deaths-map[χάρτη] όπως αναφέρονταν. 

==== Απλά εργαλεία

Συνάμα με την παροχή τρόπων για την εξερεύνηση μεγάλων συνόλων δεδομένων, είχαμε επίσης επιτυχία στη δημιουργία απλών εργαλείων για τους χρήστες που παρέχουν μικρά κομμάτια πληροφοριών που σχετίζονται προσωπικά. Τα συγκεκριμένα εργαλεία ελκύουν όσους δεν διαθέτουν πολύ χρόνο και ίσως αποφεύγουν την εξερεύνηση μιας μακροσκελής ανάλυσης. Η ικανότητα να μοιράζεσαι εύκολα ένα προσωπικό γεγονός είναι κάτι που έχουμε ξεκινήσει να ενσωματώνουμε ως στάνταρ.

Ένα απλοϊκό παράδειγμα της προσέγγισης αυτής είναι το δικό μας χαρακτηριστικό πρότζεκτ http://bbc.in/KQsSzB[«Ο κόσμος στα επτά δισεκατομμύρια: Ποιος είναι ο αριθμός σου;»], δημοσιευμένο να συμπίπτει με την επίσημη ημερομηνία κατά την οποία ο παγκόσμιος πληθυσμός ξεπέρασε τα επτά δισεκατομμύρια. Συμπληρώνοντας την ημερομηνία γέννησης τους, οι χρήστες μπορούσαν να ανακαλύψουν το νούμερο τους, όσον αφορά τον παγκόσμιο πληθυσμό, πότε γεννήθηκαν και μετά να κοινοποιήσουν αυτόν τον αριθμό μέσω Twitter ή Facebook. Η εφαρμογή χρησιμοποιούσε δεδομένα που προέρχονταν από το ίδρυμα ανάπτυξης πληθυσμού των Ηνωμένων Εθνών. Υπήρξε πολύ δημοφιλής και μάλιστα έγινε στο Ηνωμένο Βασίλειο ο σύνδεσμος με τις περισσότερες κοινοποιήσεις στο Facebook το 2011.

[[FIG024]]
.Ο κόσμος στα επτά δισεκατομμύρια (BBC)
image::figs/incoming/02-05.png[float="none"]

Ένα άλλο πρόσφατο παράδειγμα είναι η http://bbc.in/JepssY[αριθμομηχανή του BBC] για τον προϋπολογισμό, η οποία επέτρεπε στους χρήστες να ανακαλύψουν πόσο καλύτερα ή χειρότερα θα είναι όταν τεθεί σε ισχύ ο προϋπολογισμός του Άγγλου Υπουργού Οικονομικών – και μετά να κοινοποιήσουν αυτό το ποσοστό. Συνεργαστήκαμε με την λογιστική εταιρία KPMG LLP, που μας παρείχε υπολογισμούς βασισμένους στον ετήσιο προϋπολογισμό, και στη συνέχεια εργαστήκαμε σκληρά για να δημιουργήσουμε ένα ελκυστικό περιβάλλον - διεπαφή, η οποία και θα ενθάρρυνε τους χρήστες να ολοκληρώσουν την εργασία.

==== Εξορίζοντας τα δεδομένα

Αλλά που βρίσκεται η δημοσιογραφία σε όλο αυτό; Η διαδικασία της εύρεσης ιστοριών μέσα στα δεδομένα αποτελεί έναν πιο παραδοσιακό ορισμό της δημοσιογραφίας δεδομένων. Υπάρχει καμιά αποκλειστικότητα «θαμμένη» μέσα στη βάση δεδομένων; Είναι οι αριθμοί ακριβείς; Αποδεικνύουν άραγε η διαψεύδουν ένα πρόβλημα; Όλες αυτές είναι ερωτήσεις για τις οποίες ο δημοσιογράφος δεδομένων ή ένας ρεπόρτερ που χρησιμοποιεί τη βοήθεια υπολογιστή, πρέπει να αναρωτηθούν οι ίδιοι. Αλλά μεγάλο μέρος του χρόνου μπορεί να χρησιμοποιηθεί εξετάζοντας λεπτομερώς ένα τεράστιο σύνολο από δεδομένα, με την ελπίδα να βρεθεί κάτι αξιόλογο.

Στο κομμάτι αυτό, έχουμε ανακαλύψει πως, είναι πιο παραγωγικό να συνεργάζεσαι με ερευνητικές ομάδες ή προγράμματα που διαθέτουν την τεχνογνωσία και τον χρόνο να ερευνήσουν μια ιστορία. Το πρόγραμμα Πανόραμα που ασχολείται με την τρέχουσα επικαιρότητα αφιέρωσε μήνες δουλειάς σε συνεργασία με το κέντρο ερευνητικής δημοσιογραφίας, συγκεντρώνοντας δεδομένα για τους μισθούς στον δημόσιο τομέα. Το αποτέλεσμα ήταν ένα τηλεοπτικό ντοκιμαντέρ και μια ειδική online αναφορά υπό τον τίτλο, http://bbc.in/IKPrL2[«Αμοιβές στο δημόσιο: Οι αριθμοί»], όπου όλα τα δεδομένα δημοσιεύτηκαν και οπτικοποιήθηκαν με ανάλυση πεδίο προς πεδίο.

Παράλληλα με τη συνεργασία με δημοσιογράφους που διενεργούν έρευνα, το να έχεις πρόσβαση σε πολυάριθμους δημοσιογράφους με εξειδικευμένη γνώση είναι κάτι  εξίσου ουσιαστικό. Όταν ένας συνάδελφος από την ομάδα στη δουλειά, ανέλυσε την ανασκόπηση των στοιχείων για τις περικοπές των δαπανών που δημοσιεύτηκαν από την κυβέρνηση, κατέληξε στο συμπέρασμα πως τα παρουσίαζε μεγαλύτερα απ’ ότι ήταν στην πραγματικότητα. Το αποτέλεσμα ήταν μια αποκλειστική ιστορία με τίτλο, http://bbc.in/LcuGFV[“Making sense of the data”] συνοδευόμενη από μια http://bbc.in/IIADrj[ξεκάθαρη οπτικοποίηση], η οποία και απέσπασε το βραβείο της Βασιλικής Στατιστικής Κοινότητας (Royal Statistical Society). 

==== Κατανοώντας ένα θέμα

Αλλά η δημοσιογραφία δεδομένων δεν χρειάζεται να είναι μια αποκλειστικότητα που κανείς άλλος δεν έχει εντοπίσει. Η δουλειά της ομάδας οπτικοποίησης των δεδομένων είναι να συνδυάσει μια καλή σχεδίαση με μια ξεκάθαρη συντακτικά αφήγηση προκειμένου να παρέχει μια επιβλητική εμπειρία στον χρήστη. Η εμπλοκή οπτικοποιήσεων με τα σωστά δεδομένα μπορεί να χρησιμοποιηθεί για να δώσει μια καλύτερη κατανόηση/εξήγηση ενός θέματος ή μιας ιστορίας, μια προσέγγιση που εμείς στο BBC χρησιμοποιούμε συχνά στις αφηγήσεις μας. Μια τεχνική που χρησιμοποιείται στον οικονομικό μας δείκτη για την ανεργία στο Ηνωμένο Βασίλειο (UK claimant count tracker), είναι η http://bbc.in/KF7IKU[γραφική απεικόνιση heat-map] των δεδομένων στο πέρασμα του χρόνου, για να δοθεί μια πιο ξεκάθαρη οπτική της εξέλιξης/αλλαγής.

Η λειτουργία δεδομένων http://bbc.in/IIAHHI[«το δίκτυο του χρέους της Ευρωζώνης»] εξερευνά το μπλεγμένο δίκτυο του εσωτερικού δανεισμού της κάθε χώρας. Βοηθά δίνοντας εξηγήσεις με έναν οπτικό τρόπο σε ένα πολυσύνθετο θέμα, χρησιμοποιώντας χρώμα και αναλογικά βέλη σε συνδυασμό με ξεκάθαρο κείμενο. Μεγάλο ενδιαφέρον έχει, να ενθαρρύνεις τον χρήστη να εξερευνήσει ένα συγκεκριμένο χαρακτηριστικό ή να ακολουθήσει μια αφήγηση, χωρίς να τον κάνεις να αισθανθεί καταβεβλημένος από τα νούμερα.

==== Μια σύνοψη της ομάδας

Η ομάδα που παράγει δημοσιογραφία δεδομένων για τον ειδησεογραφικό τόπο του BBC αποτελείται από περίπου 20 δημοσιογράφους, σχεδιαστές και προγραμματιστές.

Παράλληλα με τα πρότζεκτ δεδομένων και τις οπτικοποιήσεις, η ομάδα παράγει όλα τα infographics και τα πολυμεσικά διαδραστικά χαρακτηριστικά του ειδησεογραφικού δικτυακού τόπου. Όλα μαζί αυτά δημιουργούν μια συλλογή τεχνικών αφήγησης που καταλήξαμε να αποκαλούμε οπτική δημοσιογραφία. Δεν έχουμε άτομα που προσδιορίζονται συγκεκριμένα ως δημοσιογράφοι δεδομένων, αλλά όλο το συντακτικό προσωπικό της ομάδας πρέπει να είναι ικανό στην χρήση βασικών εφαρμογών λογιστικών φύλλων για την ανάλυση δεδομένων, όπως  το Excel και τα Google Docs.

Κεντρικό σημείο σε κάθε πρότζεκτ δεδομένων είναι οι τεχνικές ικανότητες και η συμβουλή των προγραμματιστών μας όπως επίσης και οι ικανότητες οπτικοποίησης των σχεδιαστών μας.  Ενώ είμαστε όλοι πρωτίστως, δημοσιογράφοι, σχεδιαστές ή προγραμματιστές συνεχίζουμε να δουλεύουμε σκληρά προκειμένου να αυξήσουμε την κατανόηση και την επάρκεια μας σε οποιοδήποτε άλλο τομέα ειδικότητας.

Ο πυρήνας των προϊόντων για την εξερεύνηση των δεδομένων είναι το Excel, τα Google Docs και η εφαρμογή Fusion Tables της Google. Η ομάδα έχει επίσης χρησιμοποιήσει αλλά σε μικρότερο βαθμό, την MySQL, τις ΒΔ στην Access και την Solr για την εξερεύνηση μεγαλύτερων συνόλων δεδομένων• ενώ χρησιμοποίησε και τις RDF και SPARQL με στόχο την αναζήτηση τρόπων με τους οποίους μπορούμε να μοντελοποιούμε γεγονότα χρησιμοποιώντας τεχνολογίες Διασυνδεδεμένων Δεδομένων (Linked Data technologies). Οι προγραμματιστές θα χρησιμοποιήσουν επίσης την γλώσσα προγραμματισμού της επιλογής τους, είτε αυτή λέγεται ActionScript, Python ή Perl για να ταιριάξουν, αναλύσουν ή γενικά να ξεχωρίσουν ένα σύνολο από δεδομένα που μπορεί να δουλεύουμε. Η Perl χρησιμοποιείται για κάποιες από τις δημοσιεύσεις. 

Χρησιμοποιούμε την Google, τους χάρτες της Bing, το Google Earth μαζί με το σύστημα Esri's ArcGIS για την εξερεύνηση και οπτικοποίηση γεωγραφικών δεδομένων. 

Όσον αφορά τα γραφικά χρησιμοποιούμε την σουίτα της Adobe συμπεριλαμβανομένων των προγραμμάτων After Effects, Illustrator, Photoshop και Flash αν και σπάνια θα δημοσιεύουμε την εποχή αυτή αρχεία σε flash καθώς η JavaScript –και συγκεκριμένα η JQuery και άλλες βιβλιοθήκες JavaScript όπως είναι οι Highcharts, Raphael και D3 –ανταποκρίνονται όλο και περισσότερο στις ανάγκες μας για την οπτικοποίηση των δεδομένων.

&mdash; _Bella Hurrell and Andrew Leimdorfer, BBC_

=== Πως δουλεύει στην Chicago Tribune η ομάδα των ειδησεογραφικών εφαρμογών

Η ομάδα που ασχολείται με τις ειδησεογραφικές εφαρμογές στην Chicago Tribune αποτελείται από ένα σύνολο χαρούμενων χάκερς ενσωματωμένο στην αίθουσα σύνταξης. Δουλεύουμε κοντά με τους συντάκτες και τους ρεπόρτερς για να βοηθούμε: 1) στην έρευνα και μετάδοση των ιστοριών, 2) στην απεικόνιση των ιστοριών διαδικτυακά και 3) στο «χτίσιμο» σταθερών δικτυακών πηγών για τους ανθρώπους της Chicagoland.  

Είναι σημαντικό το ότι βρισκόμαστε στην αίθουσα σύνταξης. Συνήθως βρίσκουμε δουλειά μέσα από τις συνομιλίες που έχουμε πρόσωπο-με-πρόσωπο με τους ρεπόρτερς. Γνωρίζουν πως είμαστε ευτυχισμένοι βοηθώντας στη δημιουργία ενός λογισμικού screen scraper για έναν άθλιο κυβερνητικό δικτυακό τόπο, διαλύοντας μια στοίβα από αρχεία pdf ή διαφορετικά με το να μετατρέπουμε μη αξιοποιήσιμο υλικό (non data) σε κάτι που μπορείς να αναλύσεις. Κατά κάποιο τρόπο είναι η απώλεια αρχηγού που έχουμε σαν ομάδα (αντικαθιστά τον αρχηγό που λείπει από την ομάδα μας)• με αυτό τον τρόπο συγκεντρώνουμε πληροφορίες από την αρχή για πιθανά πρότζεκτ δεδομένων.

Σε αντίθεση με πολλές ομάδες στο συγκεκριμένο πεδίο, η δική μας ομάδα ιδρύθηκε από τεχνολόγους για τους οποίους η δημοσιογραφία αποτέλεσε στροφή στην καριέρα τους. Κάποιοι από μας απέκτησαν ένα πτυχίο Μάστερ στη δημοσιογραφία μετά από πολλά χρόνια κωδικοποίησης για επιχειρηματικούς σκοπούς και άλλοι μεταπήδησαν προσωρινά από την κοινότητα ανοικτής διακυβέρνησης (open government community).

Δουλεύουμε με ευέλικτο τρόπο. Για να εξασφαλίσουμε πως είμαστε πάντα συντονισμένοι, κάθε πρωινό ξεκινάει με μια 5λεπτη γρήγορη σύσκεψη. Συνήθως οργανωνόμαστε σε ζευγάρια•  δύο προγραμματιστές σε ένα πληκτρολόγιο είναι συχνά πιο παραγωγικοί απ’ ότι δύο προγραμματιστές σε δύο πληκτρολόγια. Τα περισσότερα πρότζεκτ δεν χρειάζονται πάνω από μια εβδομάδα για να παραχθούν, αλλά σε μεγαλύτερα πρότζεκτ δουλεύουμε για περισσότερες εβδομάδες και δείχνουμε τη δουλειά μας στους ενδιαφερόμενους (συνήθως ρεπόρτερ και συντάκτες) κάθε εβδομάδα. «Απέτυχε γρήγορα» είναι το βασικό σύνθημα. Εάν το κάνεις λάθος, είναι ανάγκη να το καταλάβεις όσο το δυνατόν συντομότερα, ειδικά όταν προγραμματίζεις έχοντας συγκεκριμένη προθεσμία! 

Υπάρχει και η θετική πλευρά στο επαναλαμβανόμενο χάκιννκ με συγκεκριμένη προθεσμία: αναβαθμίζουμε πάντα την εργαλειοθήκη μας. Κάθε εβδομάδα επινοούμε μια εφαρμογή ή δύο και στη συνέχεια, σε αντίθεση με τα συνηθισμένα καταστήματα λογισμικού, μπορούμε να το τοποθετήσουμε στο πίσω μέρος του μυαλού μας και να προχωρήσουμε στο επόμενο πρότζεκτ. Είναι μια απόλαυση που μοιραζόμαστε με τους ρεπόρτερ, και κάθε βδομάδα μαθαίνουμε κάτι καινούργιο.

[[FIG025]]
.Η ομάδα ειδησεογραφικών εφαρμογών της Chicago Tribune (φώτο: Heather Billings)
image::figs/incoming/02-00.jpg[float="none"]

Όλες οι ιδέες για τις εφαρμογές προέρχονται από τους ρεπόρτερ και συντάκτες που βρίσκονται στην αίθουσα σύνταξης. Αυτό, πιστεύω, μας ξεχωρίζει από αντίστοιχες ομάδες σε άλλες αίθουσες σύνταξης που συχνά γεννούν τις δικές τους ιδέες. Έχουμε χτίσει δυνατές προσωπικές και επαγγελματικές σχέσεις στην αίθουσα σύνταξης και ο κόσμος γνωρίζει πως όταν έχει δεδομένα, έρχεται σε εμάς.

Μεγάλος μέρος της δουλειάς μας, είναι η υποστήριξη του ρεπόρτερ. Βοηθούμε τους ρεπόρτερ να σκαλίζουν τα δεδομένα, να μετατρέπουν αρχεία .pdf σε λογιστικά φύλλα, να χρησιμοποιούν την τεχνική screen-scraping σε δικτυακούς τόπους κ.α. Είναι μια υπηρεσία που μας αρέσει να παρέχουμε γιατί μας βάζει έγκαιρα στη δουλειά που γίνεται μέσα στην αίθουσα σύνταξης. Ένα μέρος από αυτή τη δουλειά γίνεται μια εφαρμογή για ειδήσεις: ένας χάρτης, ένας πίνακας ή μερικές φορές ένας μεγαλύτερης κλίμακας δικτυακός τόπος. 

Στο παρελθόν, συνδεόμασταν στις εφαρμογές μέσω των γραπτών ιστοριών, κάτι που δεν απέφερε μεγάλη κίνηση. Στις μέρες μας, οι εφαρμογές βρίσκονται στη κορυφή του δικτυακού μας τόπου με τους συνδέσμους που οδηγούν σε αυτές να βρίσκονται και μέσα στις ιστορίες, κάτι που λειτουργεί θετικά τόσο για τις εφαρμογές όσο και για τις ιστορίες. Υπάρχει μια http://www.chicagotribune.com/news/data/[ενότητα στον δικτυακό τόπο για τη δουλειά μας], που δεν έχει όμως μεγάλη κίνηση. Αλλά αυτό δεν αποτελεί έκπληξη. Το «Ε, σήμερα θέλω μερικά δεδομένα!» δεν βοηθάει και πολύ.

Λατρεύουμε τις προβολές των σελίδων μας (από τους χρήστες), και λατρεύουμε τις επιβραβεύσεις από συναδέλφους αλλά αυτό δεν είναι το παν. Το κίνητρο πρέπει πάντα να είναι ο αντίκτυπος• στις ζωές των ανθρώπων, στο νόμο, στο να καθιστούμε τους πολιτικούς υπόλογους των πράξεών τους, και ούτω καθεξής. Ο γραπτός λόγος θα μιλήσει στην κυρίαρχη τάση και θα παρουσιαστεί με συμπάθεια μέσα από κάποια ανέκδοτα. Αλλά τι πρέπει να κάνουν οι αναγνώστες αφού τελειώσουν μια ιστορία. Είναι οι οικογένειες τους ασφαλείς; Εκπαιδεύονται τα παιδιά τους σωστά; Η δουλειά μας έχει επιτυχία όταν βοηθά έναν αναγνώστη να βρει την δική του/της ιστορία μέσα στα δεδομένα. Παραδείγματα προσωποποιημένης δουλειάς που κάναμε και βρήκε αντίκτυπο υπήρξαν οι http://nursinghomes.apps.chicagotribune.com/[εφαρμογές για τις αναφορές ασφάλειας των οίκων ευγηρίας] και οι εφαρμογές για τις http://schools.chicagotribune.com/[κάρτες αναφορικά με την επίδοση των σχολείων].

&mdash; _Brian Boyer, Chicago Tribune_ 

=== To Datablog της Guardian στο παρασκήνιο 

Όταν παρουσιάσαμε το Datablog, δεν είχαμε ιδέα ποιος θα ενδιαφερόταν για ακατέργαστα δεδομένα, στατιστικά και οπτικοποιήσεις. Όπως αναρωτήθηκε ένας αρκετά ανώτερος στο γραφείο μου «Γιατί κανείς να ήθελε κάτι τέτοιο;».

Το http://www.guardian.co.uk/datablog[Datablog της Guardian], το οποίο επιμελήθηκα, επρόκειτο να είναι ένα μικρό blog που θα προσφέρει ολοκληρωμένα τα δεδομένα που βρίσκονται πίσω από τις ειδήσεις μας. Τώρα αποτελείται από μια http://guardian.co.uk/data[αρχική σελίδα]• έρευνες για στοιχεία που αφορούν την παγκόσμια διακυβέρνηση και ανάπτυξη• οπτικοποιήσεις δεδομένων από τους γραφίστες της Guardian και από το διαδίκτυο, καθώς και εργαλεία για την εξερεύνηση στοιχείων που σχετίζονται με τις δημόσιες δαπάνες. Κάθε μέρα, χρησιμοποιούμε τα φύλλα εργασίας της Google για να μοιραστούμε το σύνολο των δεδομένων που βρίσκονται πίσω από τη δουλειά μας• Οπτικοποιούμε και αναλύουμε τα δεδομένα αυτά, και στη συνέχεια τα χρησιμοποιούμε για να παρέχουμε ιστορίες για την εφημερίδα και τον δικτυακό μας τόπο.

Όντας ένας συντάκτης ειδήσεων - δημοσιογράφος που δουλεύει με τα γραφικά, αποτέλεσε μια φυσιολογική προέκταση της δουλειάς που ήδη έκανα, το να συσσωρεύω νέα σύνολα δεδομένων και να τα οργανώνω κάνοντας τα πιο αξιοποιήσιμα σε μια προσπάθεια να κάνω κατανοητές τις ειδησεογραφικές ιστορίες της ημέρας. 

Η ερώτηση που μου τέθηκε έχει απαντηθεί για μας. Υπήρξαν μερικά απίστευτα χρόνια όσον αφορά τα δημόσια δεδομένα (που σχετίζονται με τη δημόσια σφαίρα). Ο πρόεδρος Ομπάμα στην πρώτη του νομοθετική πράξη, άνοιξε τους «θόλους» δεδομένων της Αμερικανικής Κυβέρνησης, και το παράδειγμα του ακολουθήθηκε σύντομα από κυβερνητικούς δικτυακούς τόπους δεδομένων ανά τον κόσμο: Στην Αυστραλία, τη Νέα Ζηλανδία αλλά και το Data.gov.uk της Βρετανικής Κυβέρνησης.

Είχαμε το σκάνδαλο με τις δαπάνες μελών του Κοινοβουλίου (MPs), η πιο απροσδόκητη περίπτωση δημοσιογραφίας δεδομένων για τους Βρετανούς – η συνέπεια που προέκυψε σήμαινε πως η Κυβέρνηση είναι τώρα υποχρεωμένη να αφήνει ελεύθερες, τεράστιες ποσότητες δεδομένων κάθε χρόνο. 

Είχαμε τις γενικές εκλογές όπου κάθε ένα από τα κύρια πολιτικά κόμματα ήταν δεσμευμένο για τη διαφάνεια των δεδομένων, ανοίγοντας τους δικούς μας «θόλους» δεδομένων στον κόσμο. Είχαμε εφημερίδες που αφιέρωναν πολύτιμο χώρο σε στήλες στην κυκλοφορία της βάσης δεδομένων COINS (Combined Online Information System – Σύστημα πληροφοριών με ανάλυση των δαπανών του κράτους) του Υπουργείου Οικονομικών.

Την ίδια ώρα, καθώς το δίκτυο αντλούσε όλο και περισσότερα δεδομένα, αναγνώστες απ’ όλο τον κόσμο ενδιαφέρονται τώρα περισσότερο από ποτέ για τα ακατέργαστα στοιχεία που βρίσκονται πίσω από τις ειδήσεις. Όταν παρουσιάσαμε το Datablog, σκεφτήκαμε πως το κοινό θα ήταν οι προγραμματιστές εφαρμογών. Στη πραγματικότητα, είναι οι άνθρωποι που θέλουν να μάθουν περισσότερα για τις εκπομπές άνθρακα, τη μετανάστευση στην Ανατολική Ευρώπη, την κατάρρευση με τους θανάτους στο Αφγανιστάν ή ακόμα και το πόσες φορές χρησιμοποίησαν τη λέξη «αγάπη» στα τραγούδια τους οι Beatles (613). 

[[FIG026]]
.Οπτικοποίηση της διαδικασίας παραγωγής στο Datablog της Guardian (the Guardian)
image::figs/incoming/02-ZZ.jpg[float="none"]

++++
<?dbfo-need height="1in"?>
++++

Σταδιακά, η δουλειά στο Datablog έχει εκφράσει και συμπληρώσει τις ιστορίες που αντιμετωπίσαμε. Συλλέξαμε 458,000 έγγραφα σχετικά με τις δαπάνες των μελών του Κοινοβουλίου και αναλύσαμε τα λεπτομερή δεδομένα για τα οποία τα μέλη του Κοινοβουλίου είχαν ισχυριστεί κάτι. Βοηθήσαμε τους χρήστες μας να εξερευνήσουν λεπτομερείς βάσεις δεδομένων με τις δαπάνες του Υπουργείου Οικονομικών και δημοσιεύσαμε τα δεδομένα που βρίσκονται πίσω από τις ειδήσεις.

Αλλά η αλλαγή του παιχνιδιού για τη δημοσιογραφία δεδομένων συνέβη την Άνοιξη του 2010, ξεκινώντας από ένα φύλλο εργασίας: 92,201 σειρές δεδομένων, που κάθε μία περιελάμβανε μια λεπτομερέστατη ανάλυση για ένα στρατιωτικό γεγονός στο Αφγανιστάν. Αυτά συνέστησαν και τις διαρροές εγγράφων (war logs) για τον πόλεμο στο Wikileaks. Το πρώτο μέρος, με άλλα λόγια. Επρόκειτο να υπάρχουν δύο ακόμη επεισόδια να ακολουθήσουμε: Ο πόλεμος στο Ιράκ και οι συναλλαγματικές ισοτιμίες λίρας - δολαρίου. Ο επίσημος όρος για τα δύο πρώτα μέρη ήταν SIGACTS (Significant Actions Database): Η σημαντική βάση δεδομένων των δράσεων-στρατιωτικών επιχειρήσεων του Αμερικανικού στρατού.

Στους ειδησεογραφικούς οργανισμούς όλα σχετίζονται με βάση την γεωγραφία και την εγγύτητα με το γραφείο ειδήσεων - σύνταξης (news desk). Εάν είσαι κοντά, είναι εύκολο να προτείνεις ιστορίες και να γίνεις μέρος της διαδικασίας• Αντιθέτως, έξω από το οπτικό πεδίο είναι κυριολεκτικά αδιανόητο. Πριν από το WikiLeaks, ήμασταν τοποθετημένοι σε έναν διαφορετικό όροφο, με τα γραφιστικά. Με την εμφάνιση του WikiLeaks έκτοτε, έχουμε τοποθετηθεί στον ίδιο όροφο δίπλα στην αίθουσα των ειδήσεων. Αυτό σημαίνει πως είναι ευκολότερο για μας να προτείνουμε ιδέες στο γραφείο αλλά και για τους ρεπόρτερς που βρίσκονται μέσα στην αίθουσα σύνταξης να μας σκεφτούν για να βοηθήσουμε με τις ιστορίες.

Δεν πάει πολύς καιρός από τότε που οι δημοσιογράφοι αποτελούσαν τους «φύλακες» των επίσημων δεδομένων. Εμείς θα γράφαμε ιστορίες για τα νούμερα τις οποίες κυκλοφορούσαμε σε ένα ευγνώμων κοινό, που δεν ενδιαφέρονταν για τα ακατέργαστα στατιστικά. Η ιδέα μας να επιτρέπουμε τις ακατέργαστες πληροφορίες στις εφημερίδες μας, αποτέλεσε ανάθεμα. 

Η δυναμική αυτή πέρα από την αναγνώριση, έχει αλλάξει τώρα. Ο ρόλος μας είναι να γίνουμε ερμηνευτές• βοηθώντας τους ανθρώπους να κατανοήσουν τα δεδομένα έστω απλά δημοσιεύοντας τα, επειδή έτσι κι αλλιώς παρουσιάζουν ενδιαφέρον από μόνα τους. 

Αλλά τα νούμερα χωρίς ανάλυση είναι απλά νούμερα, κάτι με το οποίο συμβαδίζουμε. Όταν ο Πρωθυπουργός της Βρετανίας ισχυρίστηκε πως οι εξεγέρσεις τον Αύγουστο του 2011 δεν σχετίζονταν με τη φτώχεια, ήμασταν σε θέση να απεικονίσουμε τις διευθύνεις των εξεγερμένων με βάση τους δείκτες της φτώχειας προκειμένου να δείξουμε την αλήθεια πίσω από τον ισχυρισμό. 

Πίσω από όλες αυτές τις ιστορίες μας που βασίζονται στη δημοσιογραφία δεδομένων, υπάρχει μια διαδικασία. Μια διαδικασία που αλλάζει συνεχώς καθώς χρησιμοποιούμε νέα εργαλεία και τεχνικές. Κάποιοι άνθρωποι ισχυρίζονται πως η απάντηση σχετίζεται με το να γίνεις ένα είδος σούπερ χάκερ, να γράφεις κώδικα και να εμβαθύνεις στην SQL. Μπορείς να αποφασίσεις να ακολουθήσεις την προσέγγιση αυτή. Αλλά μεγάλο μέρος της δουλειάς που κάνουμε, αφορά μόνο το Excel. 
Πρώτα απ’ όλα, εντοπίζουμε τα δεδομένα ή τα λαμβάνουμε από μια πληθώρα πηγών, όπως οι  έκτακτες ειδήσεις, τα κυβερνητικά στοιχεία, οι δημοσιογραφικές έρευνες και ούτω καθεξής. Στη συνέχεια, ξεκινάμε να εξετάσουμε προσεκτικά τι μπορούμε να κάνουμε με τα δεδομένα• χρειαζόμαστε να τα συνδυάσουμε με κάποιο άλλο σύνολο δεδομένων; Πως μπορούμε να δείξουμε τις αλλαγές στην πάροδο του χρόνου; Αυτά τα λογιστικά φύλλα συχνά πρέπει να είναι σοβαρά συμμαζεμένα – όλες αυτές οι περιττές στήλες και τα περίεργα συγχωνευμένα κελιά δεν βοηθούν στην πραγματικότητα.  Και αυτό, υποθέτοντας πως δεν είναι PDF, αποτελεί το χειρότερο από όλα τα γνωστά φορμάτ που υπάρχουν για δεδομένα.

Συχνά, επίσημα δεδομένα έρχονται μαζί με την προσθήκη των επίσημων κωδικών τους• κάθε σχολείο, νοσοκομείο, περιφέρεια και τοπική αρχή έχει έναν μοναδικό κωδικό αναγνώρισης.

++++
<?dbfo-need height="1in"?>
++++

Οι χώρες έχουν επίσης αντίστοιχους κωδικούς) (για παράδειγμα ο κωδικός του Ηνωμένου Βασιλείου είναι GB). Είναι χρήσιμοι επειδή μπορεί να θέλεις να ξεκινήσεις να επεξεργάζεσαι μαζί σύνολα δεδομένων, και είναι εκπληκτικό το πόσες διαφορετικές ορθογραφίες και συνθέσεις λέξεων μπορείς να βρεις με αυτόν τον τρόπο. Υπάρχει η Βιρμανία και η Μιανμάρ για παράδειγμα που είναι το ίδιο, ή η Fayette County στις Ηνωμένες Πολιτείες (υπάρχουν 11 σαν κι αυτήν στις πολιτείες από την Τζώρτζια μέχρι την Γουέστ Βιρτζίνια). Οι κωδικοί μας επιτρέπουν να συγκρίνουμε όλες αυτές τις κοινές λέξεις.

Και το τέλος αυτής της ιστορίας είναι η παραγωγή: θα είναι μια ιστορία, ένα γραφικό ή μια οπτικοποίηση, αλλά και τι εργαλεία θα χρησιμοποιήσουμε; Τα καλύτερα εργαλεία για μας είναι τα δωρεάν με τα οποία μπορούμε να παράγουμε κάτι στα γρήγορα. Τα πιο πολύπλοκα γραφήματα παράγονται από την ομάδα των προγραμματιστών μας. 

Αυτό σημαίνει πως συνήθως χρησιμοποιούμε τα σχέδια της Google για μικρά γραμμικά γραφήματα και πίτες, ή τους πίνακες σύντηξης (Fusion Tables) της Google για την εύκολη και γρήγορη δημιουργία χαρτών.

Μπορεί να φαίνεται καινούργιο, αλλά δεν είναι.

Στο πρώτο τεύχος της Guardian που κυκλοφόρησε στο Μάντσεστερ (Σάββατο 5 Μαΐου, 1821), τα νέα βρισκόταν στην πίσω σελίδα όπως σε όλα έντυπα της συγκεκριμένης ημέρας. Το πρώτο αντικείμενο στην μπροστινή σελίδα ήταν μια διαφήμιση για ένα χαμένο Λαμπραντόρ.

Ανάμεσα στις ιστορίες και στα αποσπάσματα ποίησης, το ένα τρίτο αυτής της πίσω σελίδας καλύπτεται με καλά γεγονότα (well facts). Ένας αναλυτικός πίνακας για τις δαπάνες των σχολείων της περιοχής που όπως αναφέρει ο «ΝΗ» (πηγή) δεν είχε ποτέ πριν βγει στη δημοσιότητα.

Ο ΝΗ ήθελε τα δεδομένα του να δημοσιευτούν επειδή διαφορετικά τα γεγονότα θα έμεναν να παρουσιαστούν από ανεκπαίδευτους κληρικούς. Το κίνητρο του ήταν το εξής, «με τόση πληροφορία που περιέχουν είναι πολύτιμα• επειδή, χωρίς να γνωρίζουμε τον βαθμό στον οποίο η εκπαίδευση …επικρατεί, οι καλύτερες δυνατές γνώμες που μπορούν να διαμορφωθούν από την κατάσταση και τη μελλοντική εξέλιξη της κοινωνίας πρέπει, απαραιτήτως να είναι λανθασμένες». Με άλλα λόγια, εάν οι άνθρωποι δεν ξέρουν τι συμβαίνει, πως θα μπορέσει η κοινωνία να γίνει καλύτερη;

Δεν μπορώ να φανταστώ τώρα μια καλύτερη επεξήγηση για το τι προσπαθούμε να κάνουμε. Ότι κάποτε αποτελούσε μια ιστορία στις πίσω σελίδες, τώρα μπορεί να αποτελέσει κύρια είδηση της πρώτης σελίδας.

&mdash; _Simon Rogers, the Guardian_

=== Δημοσιογραφία δεδομένων στη διαδικτυακή έκδοση της Zeit

Το πρότζεκτ για τη σύγκριση του πλούτου των νοικοκυριών που βασίζεται στο PISA (http://bit.ly/Pisa_Wealth[Programme for International Student Assessment]), αποτελεί μια διαδραστική οπτικοποίηση που καθιστά ικανή τη σύγκριση των βιοτικών επιπέδων σε διαφορετικές χώρες. Χρησιμοποιεί δεδομένα προερχόμενα από το http://bit.ly/Pisa_2009[PISA 2009], μια αναλυτική αναφορά της OECD (Organisation for Economic Co-operation and Development) για την κατάταξη-αξιολόγηση εκπαιδευτικών συστημάτων παγκοσμίως, που δημοσιεύτηκε τον Δεκέμβριο του 2010. Η αναφορά είναι βασισμένη σε ένα ερωτηματολόγιο το οποίο και ρωτά 15χρονους μαθητές για τις συνθήκες διαβίωσης τους μέσα στο σπίτι.

Η βασική ιδέα αφορούσε την ανάλυση και οπτικοποίηση των συγκεκριμένων δεδομένων για την παροχή ενός μοναδικού τρόπου σύγκρισης των βιοτικών επιπέδων σε διαφορετικές χώρες.

[[FIG027]]
.Σύγκριση του πλούτου βασισμένη στην αναφορά PISA (Zeit Online)
image::figs/incoming/02-03-AA.png[float="none"]

Αρχικά, η συντακτική μας ομάδα αποφάσισε ποια στοιχεία φαίνονταν να είναι χρήσιμα και έπρεπε να είναι οπτικοποιημένα προκειμένου να γίνουν συγκρίσιμα τα βιοτικά επίπεδα, συμπεριλαμβανομένων:

   *	Πλούτου (αριθμός τηλεοράσεων, αυτοκίνητα και διαθέσιμα μπάνια στο σπίτι)
   *	Οικογενειακής κατάστασης (εάν υπάρχουν παππούδες που ζουν με την οικογένεια, ποσοστό οικογενειών με ένα μόνο παιδί, ανεργία στους γονείς και επαγγελματική κατάσταση της μητέρας)
   *	Πρόσβασης σε πηγές γνώσης-ενημέρωσης (Σύνδεση στο διαδίκτυο στο σπίτι, συχνότητα χρήσης ηλεκτρονικού ταχυδρομείου και ποσότητα ιδιοκτησίας βιβλίων)
   *	Τριών επιπλέον δεικτών σχετικά με το επίπεδο της ανάπτυξης κάθε χώρας

Με τη βοήθεια της εσωτερικής σχεδιαστικής ομάδας, τα παραπάνω στοιχεία μεταφράστηκαν σε αυτό-επεξηγηματικά εικονίδια. Δημιουργήθηκε μια κατάλληλη διεπαφή-σχεδίαση για τον επισκέπτη/χρήστη (front end) έτσι ώστε να είναι εφικτή η σύγκριση μεταξύ των διαφορετικών χωρών, παρακολουθώντας τες σαν να έπαιζαν χαρτιά.

Στη συνέχεια, επικοινωνήσαμε με ανθρώπους από το Δίκτυο Ανοικτών Δεδομένων (http://opendata-network.org/[Open Data Network]) της Γερμανίας για να βρούμε προγραμματιστές που θα μπορούσαν να βοηθήσουν με το πρότζεκτ. Η συγκεκριμένη κοινότητα που αποτελείται από ανθρώπους με υψηλό κίνητρο πρότεινε τον Gregor Aisch, έναν πολύ ταλαντούχο σχεδιαστή ειδικευμένο στην παρουσίαση πληροφοριών, για να δημιουργήσει την εφαρμογή που θα έκανε τα όνειρα μας πραγματικότητα (χωρίς τη χρήση Flash, κάτι που ήταν πολύ σημαντικό για εμάς!). Ο Gregor δημιούργησε μια διαδραστική, πολύ υψηλής ποιότητας οπτικοποίηση με ένα όμορφο στιλ με φούσκες, βασισμένο στη βιβλιοθήκη Raphaël-Javascript.

Το αποτέλεσμα της συνεργασίας μας ήταν ένα πολύ επιτυχημένο διαδραστικό εργαλείο που έφερε μεγάλη επισκεψιμότητα. Είναι εύκολο να συγκρίνεις οποιεσδήποτε δύο χώρες, κάτι που το καθιστά χρήσιμο ως ένα εργαλείο αναφοράς. Αυτό σημαίνει πως μπορούμε να το ξαναχρησιμοποιούμε στη καθημερινή μας δουλειά κατά την σύνταξη. Για παράδειγμα, εάν καλύπτουμε κάτι που σχετίζεται με τις συνθήκες διαβίωσης στην Ινδονησία, μπορούμε εύκολα και γρήγορα να ενσωματώσουμε ένα γραφικό που θα http://bit.ly/Pisa_Indonesia_Germany[συγκρίνει τις συνθήκες διαβίωσης σε Ινδονησία και Γερμανία]. Η τεχνογνωσία που μεταφέρθηκε στην ομάδα μας, υπήρξε μια σπουδαία επένδυση για μελλοντικά πρότζεκτ.

Στην διαδικτυακή έκδοση της Zeit, έχουμε βρει πως τα http://www.zeit.de/datenjournalismus[δικά μας πρότζεκτ δημοσιογραφίας δεδομένων] μας έχουν φέρει μεγάλη επισκεψιμότητα και  μας έχουν βοηθήσει να εμπλακούμε με το κοινό με νέους τρόπους. Για παράδειγμα, υπήρξε μεγάλη (δημοσιογραφική) κάλυψη σχετικά με την κατάσταση στο πυρηνικό εργοστάσιο της Φουκουσίμα μετά το τσουνάμι στην Ιαπωνία. Μετά την εκπομπή ραδιενεργού υλικού από το εργοστάσιο παραγωγής ενέργειας, όλοι σε απόσταση 30 χιλιομέτρων από το εργοστάσιο υποβλήθηκαν σε εκκένωση. Οι άνθρωποι μπορούσαν να διαβάσουν και να δουν αρκετά σχετικά με τις εκκενώσεις. Η διαδικτυακή έκδοση της Zeit βρήκε έναν πρωτότυπο τρόπο για να εξηγήσει τον αντίκτυπο που είχε το γεγονός στο δικό μας, Γερμανικό κοινό. Ρωτήσαμε: http://bit.ly/near_nuclear[πόσοι άνθρωποι ζουν κοντά σε ένα πυρηνικό σταθμό ενέργειας στη Γερμανία]; Πόσοι ζουν μέσα σε μια ακτίνα 30 χιλιομέτρων; Ένας χάρτης απεικονίζει πόσοι άνθρωποι θα πρέπει να υποβληθούν σε εκκένωση σε μια παρόμοια κατάσταση στη Γερμανία. Το αποτέλεσμα: παρά πολύ μεγάλη επισκεψιμότητα• στην πραγματικότητα το πρότζεκτ κοινοποιήθηκε ευρέως (went viral) στη σφαίρα των μέσων κοινωνικής δικτύωσης. Τα πρότζεκτ δημοσιογραφίας δεδομένων μπορούν συγκριτικά εύκολα να προσαρμοστούν σε άλλες γλώσσες. Δημιουργήσαμε μια έκδοση στα Αγγλικά όσον αφορά την εγγύτητα σε σταθμούς πυρηνικής ενέργειας στις Ηνωμένες Πολιτείες, κάτι που έφερε μεγάλη επισκεψιμότητα. Οι ειδησεογραφικοί οργανισμοί επιδιώκουν να αναγνωρίζονται ως έγκυρες και αξιόπιστες πηγές μεταξύ των αναγνωστών τους. Βρήκαμε ότι τα πρότζεκτ δημοσιογραφίας δεδομένων σε συνδυασμό με το γεγονός πως επιτρέπουμε στους αναγνώστες μας να κοιτάξουν και να ξαναχρησιμοποιήσουν τα ακατέργαστα δεδομένα, μας αποφέρει έναν υψηλό βαθμό αξιοπιστίας. 

Για δύο χρόνια το τμήμα R&D και ο αρχισυντάκτης της Zeit Online, Wolfgang Blau, υπερασπίζονται τη δημοσιογραφία δεδομένων ως ένας σημαντικός τρόπος για να πεις τις ιστορίες. Διαφάνεια, αξιοπιστία, και η εμπλοκή των χρηστών αποτελούν σημαντικά κομμάτια της φιλοσοφίας μας. Αυτός είναι και ο λόγος γιατί η δημοσιογραφία δεδομένων αποτελεί ένα φυσικό κομμάτι της τωρινής και μελλοντικής μας δουλειάς. Οι οπτικοποιήσεις δεδομένων μπορούν να προσδώσουν περαιτέρω αξία στη λήψη μιας ιστορίας, και είναι ένας ελκυστικός τρόπος παρουσίασης του περιεχομένου ολόκληρης της συντακτικής ομάδας. 

Για παράδειγμα, στις 9 Νοεμβρίου 2011, η Deutsche Bank δεσμεύτηκε να σταματήσει τη χρηματοδότηση σε εταιρείες κατασκευής βομβών διασποράς. Αλλά σύμφωνα με μια μελέτη του μη κερδοσκοπικού οργανισμού Facing Finance, η τράπεζα μετά από αυτή την υπόσχεση που έδωσε, συνέχισε να εγκρίνει δάνεια σε παραγωγούς πυρομαχικών διασποράς. Η http://zeit.de/wirtschaft/cluster-munition[δική μας οπτικοποίηση] που βασίζονταν στα δεδομένα, έδειχνε στους αναγνώστες μας τις διάφορες ροές των χρημάτων. Τα διαφορετικά τμήματα της εταιρείας Deutsche Bank είναι ταξινομημένα στην κορυφή, με τις εταιρείες που κατηγορήθηκαν για ανάμειξη στην κατασκευή πυρομαχικών διασποράς να βρίσκονται στο κάτω μέρος. Ενδιάμεσα, τα μεμονωμένα δάνεια παρουσιάζονται κατά μήκος μιας χρονολογικής σειράς (timeline). Ένα roll over με τον κέρσορα επάνω στους κύκλους εμφανίζει τις λεπτομέρειες της κάθε συναλλαγής. Ασφαλώς η ιστορία θα μπορούσε να «βγει» και ως ένα γραμμένο άρθρο. Αλλά η οπτικοποίηση δίνει τη δυνατότητα στους αναγνώστες μας να κατανοήσουν και να εξερευνήσουν τις χρηματοοικονομικές εξαρτήσεις με έναν πιο εύληπτο τρόπο.

[[FIG028]]
.Οι βόμβες και η βιομηχανία παραγωγής τους (Zeit Online)
image::figs/incoming/02-03-DD.png[float="none"]

To take another example: the https://www.destatis.de/EN/Homepage.html[German Federal Statistic Office] has published a great dataset on vital statistics for Germany, including http://bit.ly/German_Federal_Statistics[modeling various demographic scenarios up until 2060]. The typical way to represent this is a population pyramid, such as https://www.destatis.de/bevoelkerungspyramide/[the one from the Federal Statistics Agency].

With our colleagues from the science department, we tried to give our readers a better way to explore the projected demographic data about our future society. With http://www.zeit.de/wissen/altersstruktur[our visualization], we present a statistically representative group of 40 people of different ages from the years 1950 till 2060.They are organized into eight different groups. It looks like a group photo of German society at different points in time. The same data visualized in a traditional population pyramid gives only a very abstract feeling of the situation, but a group with kids, younger people, adults, and elderly people means our readers can relate to the data more easily. You can just hit the play button to start a journey through eleven decades. You can also enter your own year of birth and gender to become part of the group photo: to see your demographic journey through the decades and your own life expectancy.

&mdash; _Sascha Venohr, Zeit Online_

[[FIG0210]]
.Visualizing demographic data (Zeit Online)
image::figs/incoming/02-03-CC.png[scale="94",float="none"]

=== How to Hire a Hacker

One of the things that I am regularly asked by journalists is "how do I get a coder to help me with my project?" Don't be deceived into thinking that this is a one-way process; civic-minded hackers and data-wranglers are often just as keen to get in touch with journalists.

Journalists are power-users of data driven tools and services. From the perspective of developers, journalists think outside the box to use data tools in contexts developers haven't always considered before (feedback is invaluable!). They also help to build context and buzz around projects and help to make them relevant. It is a symbiotic relationship.

Fortunately, this means that whether you are looking to hire a hacker or looking for possible collaborations on a shoestring budget, there will more than likely be someone out there who is interested in helping you.

So how do you find them? Says Aron Pilhofer from The New York Times:

[quote]
____
You may find that your organzation already has people with all the skills you need, but they are not necessarily already in your newsroom. Wander around, visit the technology and IT departments, and you are likely to strike gold. It is also important to appreciate coder culture: come across someone who has a computer that looks like the one in <<FIG0211>>...then you are probably onto a winner.
____

[[FIG0211]]
.Badge of honor: hackers are often easy to spot (photo by Lucy Chambers)
image::figs/incoming/02-04.jpg[float="none"]

Here are a few more ideas:

Post on job websites::
  Identify and post to websites aimed at developers who work in different programming languages. For example, the http://www.python.org/community/jobs/[Python Job Board].
Contact relevant mailing lists::
  For example, the http://bit.ly/nicar-subscribe[NICAR-L] and http://bit.ly/ddj-list[Data Driven Journalism] mailing lists.
Contact relevant organizations::
  For example, if you want to clean up or scrape data from the web, you could contact an organization such as https://scraperwiki.com/[Scraperwiki], who have a great address book of trusted and willing coders.
Join relevant groups/networks::
  Look out for initiatives such as http://hackshackers.com/[Hacks/Hackers] which bring journalists and techies together. Hacks/Hackers groups are now springing up all around the world. You could also try posting something to their http://bit.ly/hacks-hackers-jobs[jobs newsletter].
Local interest communities::
  You could try doing a quick search for an area of expertise in your area (e.g. "javascript" + "london"). Sites such as Meetup.com can also be a great place to start.
Hackathons and competitions::
  Whether or not there is prize money available, app and visualization competitions and development days are often fruitful ground for collaboration and making connections.
Ask a geek!::
  Geeks hang around with other geeks. Word of mouth is always a good way to find good people to work with.

&mdash; _Lucy Chambers, Open Knowledge Foundation_

.Hacker Skills
****
Once you've found a hacker, how do you know if they are any good? We asked Alastair Dant from the Guardian for his views on how to spot a good one:

They code the full stack::
  When dealing with deadlines, it's better to be a jack of all trades than a master of one. News apps require data wrangling, dynamic graphics, and derring-do.
They see the whole picture::
  Holistic thinking favors narrative value over technical detail. I'd rather hear one note played with feeling than unceasing virtuosity in obscure scales. Find out how happy someone is to work alongside a designer.
They tell a good story::
  Narrative presentation requires arranging things in space and time. Find out what project they're most proud of and ask them to walk you through how it was built; this will reveal as much about their ability to communicate as their technical understanding.
They talk things through::
  Building things fast requires mixed teams working towards common goals. Each participant should respect their fellows and be willing to negotiate. Unforeseen obstacles often require rapid re-planning and collective compromise.
They teach themselves::
  Technology moves fast. It's a struggle to keep up with. Having met good developers from all sorts of backgrounds, the most common trait is a willingness to learn new stuff on demand.

&mdash; _Lucy Chambers, Open Knowledge Foundation, interviewing Alastair Dant, Lead pass:[<phrase role='keep-together'>Interactive</phrase>] Technologist, the Guardian_
****

++++
<?dbfo-need height="1in"?>
++++

.How To Find Your Dream Developer
****
The productivity difference between a good and a great developer is not linear--it's exponential. Hiring well is extremely important. Unfortunately, hiring well is also very difficult. It's hard enough to vet candidates if you are not an experienced technical manager. Add to that the salaries that news organizations can afford to pay, and you've got quite a challenge.

At Tribune, we recruit with two angles: an emotional appeal and a technical appeal. The emotional appeal is this: journalism is essential to a functioning democracy. Work here and you can change the world. Technically, we promote how much you'll learn. Our projects are small, fast, and iterative. Every project is a new set of tools, a new language, a new topic (fire safety, the pension system), that you must learn. The newsroom is a crucible. I've never managed a team that has learned so much, so fast, as our team.

As for where to look, we've had great luck finding great hackers in the open government community. The Sunlight Labs mailing list is where do-gooder nerds with crappy day jobs hang out at night. Another potential resource is Code for America. Every year, a group of fellows emerges from CfA, looking for their next big project. And as a bonus, CfA has a rigorous interview process; they've already done the vetting for you. Nowadays, programming-interested journalists are also emerging from journalism schools. They're green, but they've got tons of potential.

Lastly, it's not enough to just hire developers. You need technical management. A lone-gun developer (especially fresh from journalism school, with no industry experience) is going to make many bad decisions. Even the best programmer, when left to her own devices, will choose technically interesting work over doing what's most important to your audience.

Call this hire a news applications editor, a project manager, whatever. Just like writers, programmers need editors, mentorship, and somebody to wrangle them towards making software on deadline.

&mdash; _Brian Boyer, Chicago Tribune_
****


=== Harnessing External Expertise Through Hackathons

In March 2010, Utrecht-based digital culture organzation SETUP put on an event called http://setup.nl/content/hacking-journalism[Hacking Journalism]. The event was organized to encourage greater collaboration between developers and journalists.

"We organize hackathons to make cool applications, but we can't recognize interesting stories in data. What we build has no social relevance," said the programmers. "We recognize the importance of data journalism, but we don't have all the technical skills to build the things we want," said the journalists.

[[FIG0212]]
.Journalists and developers at RegioHack (photo by Heinze Havinga)
image::figs/incoming/02-XY.jpg[float="none"]

Working for a regional newspaper, there was no money or incentive to hire a programmer for the newsroom. Data journalism was still an unknown quantity for Dutch newspapers at that time.

The hackathon model was perfect; a relaxed environment for collaboration, with plenty of pizza and energy drinks. http://www.regiohack.nl/[RegioHack] was a hackathon organized by my employer, the regional newspaper http://www.destentor.nl/[De Stentor], our sister publication http://www.tctubantia.nl/[TC Tubantia], and http://saxion.nl/[Saxion Hogescholen Enschede], who provided the location for the event.

The setup was as follows: everyone could enlist for a 30-hour hackathon. We provided the food and drink. We aimed for 30 participants, which we divided into 6 groups. These groups would focus on different topics, such as crime, health, transport, safety, aging, and power. For us, the three main objectives for this event were as follows:

Find stories::
  For us, data journalism is something new and unknown. The only way we can prove its use is through well crafted stories. We planned to produce at least three data stories.

++++
<?dbfo-need height="1in"?>
++++

Connect people::
  We, the journalists, don't know how data journalism is done and we don't pretend to. By putting journalists, students, and programmers in one room for 30 hours, we want them to share knowledge and insights.

Host a social event::
  Newspapers don't organize a lot of social events, let alone hackathons. We wanted to experience how such an event can yield results. In fact, the event could have been tense: 30 hours with strangers, lots of jargon, bashing your head against basic questions, and working out of your comfort zone. By making it a social event (remember the pizza and energy drinks?), we wanted to create an environment in which journalists and programmers could feel comfortable and collaborate effectively.

Before the event, TC Tubantia had an interview with the widow of a policeman who had written a book on her husband's working years. She also had a document with all registered murders in the eastern part of the Netherlands, maintained by her husband since 1945. Normally, we would publish this document on our website. This time, we made a http://bit.ly/tableau-dashboard[dashboard using the Tableau software]. We also http://bit.ly/regiohack-blog[blogged] about how this came together on our RegioHack site.

During the hackathon, one project group came up with the subject of development of schools and the aging of our region. http://bit.ly/tableau-workbook[By making a visualization of future projections], we understood which cities would get in trouble after a few years of decline in enrollments. With this insight, we made an article on how this would affect schools in our region.

We also started a very ambitious project called De Tweehonderd van Twente (in English, The Two Hundred of Twente) to determine who had the most power in our region and build a database of the most influential people. Through a Google-ish calculation--who has the most ties with powerful organizations--a list of influential people will be composed. This could lead to a series of articles, but it's also a powerful tool for journalists. Who has connections with who? You can ask questions to this database and use it in your daily routine. Also, this database has cultural value. Artists already asked if they could use this database when finished, in order to make interactive art installations.

[[FIG0213]]
.New communities around data journalism (photo by Heinze Havinga)
image::figs/incoming/02-YY.jpg[float="0"]

After RegioHack, we noticed that journalists considered data journalism a viable addition to traditional journalism. My colleagues continued to use and build on the techniques learned on that day to create more ambitious and technical projects, such as a database of the administrative costs of housing. With this data, I made http://bit.ly/stentor-map[an interactive map in Fusion Tables]. We asked our readers to play around with the data and crowdsourced results at http://bit.ly/scratchbook-crowdsourcing, for example. After a lot of questions on how we made a map in Fusion Tables, I also recorded a http://bit.ly/vermanen-video[video tutorial].

++++
<?dbfo-need height="1in"?>
++++

What did we learn? We learned a lot, but we also came along a lot of obstacles. We recognized these four:

Where to begin: question or data?::
  Almost all projects stalled when searching for information. Most of the time, they began with a journalistic question. But then? What data is available? Where can you find it? And when you find this data, can you answer your question with it? Journalists usually know where they can find information when doing research for an article. With data journalism, most journalists don't know what information is available.

Little technical knowledge::
  Data journalism is quite a technical discipline. Sometimes you have to scrape, other times you'll have to do some programming to visualize your results. For excellent data journalism, you'll need two aspects: the journalistic insight of an experienced journalist and the technical know-how of a digital all-rounder. During RegioHack, this was not a common presence.

Is it news?::
  Participants mostly used one dataset to discover news, instead of searching interconnections between different sources. The reason for this is that you need some statistical knowledge to verify news from data journalism.

What's the routine?::
  What everything above comes down to is that there's no routine. The participants have some skills under their belt, but don't know how and when to use them. One journalist compared it with baking a cake. "We have all the ingredients: flour, eggs, milk, etcetera. Now we throw it all in a bag, shake it, and hope a cake comes out." Indeed, we have all the ingredients, but don't know what the recipe is.

What now? Our first experiences with data journalism could help other journalists or programmers aspiring to enter the same field of work, and we are working to produce a report.

We are also considering how to continue RegioHack in a hackathon form. We found it fun, educational, and productive and a great introduction to data journalism.

But for data journalism to work, we have to integrate it in the newsroom. Journalists have to think in data, in addition to quotes, press releases, council meetings, and so on. By doing RegioHack, we proved to our audience that data journalism isn't just hype. We can write better informed and more distinctive articles, while presenting our readers with different articles in print and online.

&mdash; _Jerry Vermanen, NU.nl_

=== Following the Money: Data Journalism and Cross-Border Collaboration ===

Investigative journalists and citizens interested in uncovering organized crime and corruption that affect the lives of billions worldwide, with each passing day, have unprecedented access to information. Huge volumes of data are made available online by governments and other organizations, and it seems that much needed information is more and more in everyone's grasp. However, at the same time, corrupt officials in governments and organized crime groups are doing their best to conceal information in order to hide their misdeeds. They make efforts to keep people in the dark while conducting ugly deals that cause disruptions at all society levels and lead to conflict, famine, or other crises.

It is the duty of investigative journalists to expose such wrongdoings, and by doing so, disable corrupt and criminal mechanisms.

[[FIG0214]]
.The Investigative Dashboard (OCCRP)
image::figs/incoming/02-RR.png[scale="92",float="0"]

There are three main guidelines that, if followed, can lead to good, thorough journalism when investigating major acts of corruption and crime even in the most austere of environments:

Think outside your country::
  In many instances, it is much easier to get information from abroad than from within the country where the investigative journalist operates. Information gathered from abroad via foreign information databases or by using other countries' access to information laws might be just what you need to put the investigative puzzle together. On top of that, criminals and corrupt officials don't keep their money in the place they have stolen it from. They would rather deposit it in foreign banks or invest in other countries. Crime is global. Databases that assist the investigative journalist in tracking the money worldwide can be found in many places on the Internet. For example, the http://www.investigativedashboard.org/category/wwd/[Investigative Dashboard] enables journalists to follow the money across borders.

Make use of existing investigative journalism networks::
  Investigative journalists all over the world are grouped in
organzations such as http://www.reportingproject.net/[The Organized Crime and Corruption Reporting Project], http://www.fairreporters.org/[The African Forum for Investigative
Reporting], http://arij.net/[The Arab Reporters for Investigative
Journalism], and http://www.gijn.org/[The Global investigative Journalism Network]. Journalists can also make use of professional journalism platforms such as IJNet, where global journalism related information is exchanged on a daily basis. Many of the reporters grouped in networks work on similar issues and confront similar situations, so it makes a lot of sense to exchange information and methods. Emailing lists or social network groups are attached to these networks, so it is quite easy to get in touch with fellow journalists and to ask for information or advice. Investigative story ideas can also be gathered from such forums and emailing lists.

Make use of technology and collaborate with hackers::
  Software helps investigative journalists access and process information. Various types of software assist the investigator in cutting through the noise, in digging and making sense of large volumes of data, and in finding the right documents needed to break the story. There are many ready-made software programs that can be used as tools for analyzing, gathering, or interpreting information--and more importantly, investigative journalists need to be aware that there are scores of computer programmers ready to help if asked. These programmers or hackers know how to obtain and handle information, and they can assist a great deal with the investigative effort. These programmers, some of them members of global open data movements, can become invaluable allies in the fight against crime and corruption, able to assist journalists in gathering and analyzing information.

A good example of an interface between programmers and citizens is https://scraperwiki.com/[ScraperWiki], a site where journalists
can ask programmers for help with extracting data from websites. Investigative Dashboard http://bit.ly/dashboard-resources[maintains a list of ready-made tools] that could help journalists gather, shape, and analyze data.

The usefulness of the aforementioned guidelines has been visible in many instances. One good example is the work of Khadija Ismayilova, a very experienced Azeri investigative reporter who works in an austere environment when it comes to information access. Ms. Ismayilova has to overcome obstacles on a daily basis in order to offer the Azeri public good and reliable information. In June of 2011, Khadija Ismayilova, an investigative reporter with Radio Free Europe/Radio Liberty's (RFE/RL) Baku-based office reported that the daughters of the Azeri president, Ilham Aliyev, secretly run http://bit.ly/rferl-azerfon[a fast-rising telecom company, Azerfon] through offshore companies based in Panama. The company boasts nearly 1.7 million subscribers, covers 80 percent of the country's territory, and was (at the time) Azerbaijan's only provider of 3G services. Ismayilova spent three years trying to find out who the owners of the telecom company were, but the government refused to disclose shareholder information and lied numerous times about the company's ownership. They even claimed that the company was owned by the Germany-based Siemens AG, a claim that has been flatly denied by that corporation. The Azeri reporter managed to find out that Azerfon was owned by a few Panama-based private companies. This seemed to be a dead end to her reporting until she got help from outside. In early 2011, Ms. Ismayilova learned through the Investigative Dashboard that Panama-based companies can be tracked down through http://ohuiginn.net/panama/[an application] developed by programmer and activist Dan O'Huiginn. With this tool, she finally managed to uncover the fact that the president's two daughters were involved with the telecom company through the Panama-based businesses.

In fact, O'Huiginn created a tool that helped journalists from all over the world to report on corruption--Panama, a very well-known offshore haven, has been widely used by several corrupt officials as a place to hide stolen money (from cronies of the former Egyptian president, Hosni Mubarak to dirty officials in the Balkans or in Latin America). What the programmer-activist has done is called web scraping; a method that allows the extraction and reshaping of information so that it can be used by investigators. O'Huiginn scraped the http://www.registro-publico.gob.pa/[Panama registry of companies] because this registry, although open, only allowed searches if the investigative reporter knew the name of the commercial company he or she was looking for. This limited the possibilities of investigation, as reporters usually look for names of persons in order to track down their assets. He extracted the data and created a new website where name-based searches are also possible. The new website allowed investigative reporters in many countries to fish for information, to run names of officials in governments and Parliaments, and to check if they secretly owned corporations in Panama (just as the family of the Azerbaijan president did).

There are other advantages to using the guidelines highlighted above, besides better access to information. One of them has to do with minimizing harm and ensuring better protection for investigative reporters who work in hostile environments. This is due to the fact that when working in a network, the journalist is not alone; the investigative reporter works with colleagues in other countries, so it is harder for criminals to pass:[<phrase role='keep-together'>pinpoint</phrase>] who is responsible for their wrongdoings being exposed. As a result, retaliation by governments and corrupt officials is much harder to achieve.

Another thing to keep in mind is that information that doesn't seem very valuable in a geographical area might be crucially important in another. The exchange of information over investigative networks can lead to breaking very important stories. For example, the information that a Romanian was caught in Colombia with 1 kilogram of cocaine is most probably not front page news in Bogota, but could be very important to the Romanian public if a local reporter manages to find out that the person who was caught with the narcotics is working for the government in Bucharest.

Efficient investigative reporting is the result of cooperation between investigative journalists, programmers, and others who want to use data to contribute to create a cleaner, fairer, and more just global society.

&mdash; _Paul Radu, Organized Crime and Corruption Reporting Project_ 

=== Our Stories Come As Code 

http://www.opendatacity.de/[OpenDataCity] was founded towards the end of 2010. There was pretty much nothing that you could call data journalism happening in Germany at this time.

Why did we do this? Many times we heard people working for newspapers and broadcasters say: ``No, we are not ready to start a dedicated data journalism unit in our newsroom. But we would be happy to outsource this to someone else.''

As far as we know, we are the only company specializing exclusively in data journalism in Germany. There are currently three of us: two of us with a journalism background and one with a deep understanding of code and visualization. We work with a handful of freelance hackers, designers, and journalists.

In the last twelve months we have undertaken four data journalism projects with newspapers, and have offered training and consultancy to media workers, scientists, and journalism schools. The first app we did was TAZ, an http://bit.ly/taz-airport-noise[interactive tool on airport noise] around the the newly built airport in Berlin. Our next notable project was an http://bit.ly/zeit-telephone[application about data retention] of the mobile phone usage of a German politician with ZEIT Online. For this, we won a http://bit.ly/grimme-award[Grimme Online Award] and a Lead Award in Germany, and an Online Journalism Award from the http://bit.ly/online-news-award[Online Journalism Association] in the US. At the time of writing, we have several projects in the pipeline, ranging from simpler interactive infographics up to designing and developing a kind of data journalism middleware.

[[FIG0215]]
.Airport noise map (Taz.de)
image::figs/incoming/02-TT.png[float="none"]

Of course, winning prizes helps build a reputation. But when we talk to the publishers, who have to approve the projects, our argument for investing into data journalism is not about winning prizes. Rather it is about getting attention over a longer period of time in a sustainable way. That is, building things for their long term impact, not for the scoop, which is often forgotten after a few days.

Here are three arguments that we have used to encourage publishers to undertake longer term projects:

++++
<?dbfo-need height="1in"?>
++++

Data projects don't date::
  Depending on their design, new material can be added to data journalism apps. And they are not just for the users, but can be used internally for reporting and analysis. If you're worried that this means that your competitors will also benefit from your investment, you could keep some features or some data for internal use only.
You can build on your past work::
  When undertaking a data project, you will often create bits of code that can be reused or updated. The next project might take half the time, because you know much better what to do (and what not to), and you have bits and pieces you can build on.
Data journalism pays for itself::
  Data-driven projects are cheaper than traditional marketing campaigns. Online news outlets will often invest in things like Search Engine Optimization (SEO) and Search Engine Marketing (SEM). A executed data project will normally generate a lot of clicks and buzz, and may go viral. Publishers will typically pay less for this than trying to generate the same attention by clicks and links through SEM.

Our work is not very different from other new media agencies: providing applications or services for news outlets. But maybe we differ in that we think of ourselves first and foremost as journalists. In our eyes, the products we deliver are articles or stories, albeit ones which are provided not in words and pictures, audio or video, but in code. When we are talking about data journalism, we have to talk about technology, software, devices, and how to tell a story with them.

To give an example, we just finished working on an application that pulls in realtime data via a scraper from the German railway website, thus enabling us to develop an interactive http://zugmonitor.sueddeutsche.de/[Train Monitor for Süddeutsche Zeitung], showing the delays of long-distance trains in real time. The application data is updated every minute or so, and we are providing an API for it, too. We started doing this several months ago, and have so far collected a huge dataset that grows every hour. By now it amounts to hundreds of thousands of rows of data. The project enables the user to explore this realtime data, and to do research in the archive of previous months. In the end, the story we are telling will be significantly defined by the individual action of the users.

In traditional journalism, due to the linear character of written or broadcasted media, we have to think about a beginning, the end, the story arc, and the length and angle of our piece. With data journalism things are different. There is a beginning, yes. People come to the website and get a first impression of the interface. But then they are on their own. Maybe they stay for a minute, or half an hour.

++++
<?dbfo-need height="1in"?>
++++

Our job as data journalists is to provide the framework or environment for this. As well as the coding and data management bits, we have to think of clever ways to design experiences. The User Experience (UX) derives mostly from the (Graphical) User Interface (GUI). In the end, this is the part which will make or break a project. You could have the best code working in the background handling an exciting dataset. But if the front end sucks, nobody will care about it.

There is still a lot to learn about and to experiment with. But luckily there is the games industry, which has been innovating with respect to digital narratives, ecosystems, and interfaces for several decades now. So when developing data journalism applications, we should closely watch how game design works and how stories are told in games. Why are casual games like Tetris such fun? And what makes the open worlds of sandbox games like Grand Theft Auto or Skyrim rock?

We think that data journalism is here to stay. In a few years, data journalism workflows will be quite naturally embedded in newsrooms, because news websites will have to change. The amount of data that is publicly available will keep on increasing. But luckily, new technologies will continue to enable us to find new ways of telling stories. Some of the stories will be driven by data, and many applications and services will have a journalistic character. The interesting question is which strategy newsrooms will develop to foster this process. Are they going to build up teams of data journalists integrated into their newsroom? Will there be R&D departments, a bit like in-house startups? Or will parts of the work be outsourced to specialized companies? We are still right at the beginning and only time will tell.

&mdash; _Lorenz Matzat, OpenDataCity_

=== Kaas & Mulvad: Semi-Finished Content for Stakeholder Groups

Stakeholder media is an emerging sector, largely overlooked by media theorists, which could potentially have a tremendous impact either through online networks or by providing content to news media. It can be defined as (usually online) media controlled by organizational or institutional stakeholders, which is used to advance certain interests and communities. NGOs typically create such media; so do consumer groups, professional associations, labor unions, and so on. The key limit on its ability to influence public opinion or other stakeholders is often that it lacks the capacity to undertake discovery of important information, even more so than the downsized news media. Kaas & Mulvad, a for-profit Danish corporation, is one of the first investigative media enterprises that provides expert capacity to these stakeholder outlets.

The firm originated in 2007 as a spinoff of the non-profit Danish Institute for Computer-Assisted Reporting (Dicar), which sold investigative reports to media and trained journalists in data analysis. Its founders, Tommy Kaas and Nils Mulvad, were previously reporters in the news industry. Their new firm offers what they call ``data plus journalistic insight'' (content that remains semi-finished, requiring further editing or rewriting) mainly to stakeholder media, which finalize the content into news releases or stories and distribute it through both news media and their own outlets (such as websites). Direct clients include government institutions, PR firms, labor unions, and NGOs such as EU Transparency and the World Wildlife Fund. The NGO work includes monitoring farm and fishery subsidies, and regular updates on EU lobbyist activities generated through ``scraping'' of pertinent websites. Indirect clients include foundations that fund NGO projects. The firm also works with the news industry; a tabloid newspaper purchased their celebrity monitoring service, for example.

[[FIG0216]]
.Stakeholder media companies (Fagblaget3F)
image::figs/incoming/02-MM.png[float="none"]

++++
<?dbfo-need height="1in"?>
++++

Data journalism projects in their portfolio include:

http://bit.ly/3F-unemployment[Unemployment Map for 3F]:: 
  A data visualization with key figures about unemployment in Denmark undertaken for 3F, which is the union for unskilled labor in Denmark.

http://bit.ly/3F-living[Living Conditions for 3F]::
  Another project for 3F shows how different living conditions are in different parts of Denmark. The map uses 24 different indicators.

http://bit.ly/3F-debt-index[Debt for ``Ugebrevet A4'']::
  A project that calculates a ``debt index'' and visualizes the differences in private economy.

http://bit.ly/3F-dangerous-facilities[Dangerous Facilities in Denmark]::
  A project which maps and analyzes the proximity of dangerous facilities to kindergartens and other daycare institutions, undertaken for "Børn&Unge," a magazine published by BUPL, the Danish Union of Early Childhood and Youth Educators.

http://data.vestas.com[Corporate Responsibility Data for Vestas]::
  Data visualization on five areas of CR-data for the Danish wind turbine company, Vestas, with auto-generated text. Automatically updated on a quarterly basis with 400 web pages from world scale data down to the single production unit.

http://xpoint.experian.dk/navnekort[Name Map for Experian]::
  Type in your last name and look at the distribution of this name around different geographical areas in Denmark.

http://ekstrabladet.dk/kup/fodevarer[Smiley Map for Ekstra Bladet]::
  Every day Kaas & Mulvad extract all the bad food inspections and map all the latest for the Danish tabloid Ekstra Bladet (see halfway down the website for the map).

Kaas & Mulvad are not the first journalists to work with stakeholder media. Greenpeace, for example, routinely engages journalists as collaborators for its reports. But we know of no other firm whose offerings to stakeholder media are data-driven; it is much more typical for journalists to work with NGOs as reporters, editors, or writers. The current focus in computer-assisted news media is on search and discovery (think of WikiLeaks); here again, Kaas & Mulvad innovate by focusing on data analysis. Their approach requires not only programming skills, but also an understanding of what kind of information can make a story with impact. It can safely be said that anyone who wishes to imitate their service would probably have to acquire those two skill sets through partnership, because individuals rarely possess both.

==== Processes: Innovative IT Plus Analysis

The firm undertakes about 100 projects per year, ranging in duration from a few hours to a few months. It also continuously invests in projects that expand its capacity and offerings. The celebrity monitoring service was one such experiment. Another involved scraping the Internet for news of home foreclosures and creating maps of the events. The partners say that their first criteria for projects is whether they enjoy the work and learn from it; markets are sought after a new service is defined. They make it clear that in the news industry, they found it difficult to develop new methods and new business.

Mulvad comments that:

____
We have no editors or bosses to decide which projects we can do, which software or hardware we can buy. We can buy the tools according to project needs, like the best solutions for text scraping and mining. Our goal is to be cutting edge in these areas. We try to get customers who are willing to pay, or if the project is fun we do it for a lower charge.
____

==== Value Created: Personal and Firm Brands and Revenue

Turnover in 2009 was approximately 2.5 million Danish kroner, or €336,000. The firm also sustains the partners' reputations as cutting edge journalists, which maintains demand for their teaching and speaking services. Their public appearances, in turn, support the firm's brand.

==== Key Insights of This Example

  * The news industry's crisis of declining capacity is also a crisis of under-utilization of capacity. Kaas and Mulvad had to leave the news industry to do work they valued, and that pays. Nothing prevented a news organization from capturing that value.
  * In at least some markets, there exists a profitable market for ``semi-finished'' content that can serve the interests of stakeholder groups.
  * However, this opportunity raises the issue of how much control journalists can exercise over the presentation and use of their work by third parties. We recall that this issue already exists within the news industry (where editors can impose changes on a journalist's product), and it has existed within other media industries (such as the film industry, where conflicts between directors and studios over ``final cuts'' are hardly rare). It is not a particular moral hazard of stakeholder media, but it will not disappear, either. More attention is needed to the ethics of this growing reality and market.
  * From a revenue standpoint, a single product or service is not enough. Successful watchdog enterprises would do better to take a portfolio approach, in which consulting, teaching, speaking, and other services bring in extra revenue and support the watchdog brand.

&mdash; _Edited excerpt from Mark Lee Hunter and Luk N. Van Wassenhove, ``Disruptive News Technologies: Stakeholder Media and the Future of Watchdog Journalism Business Models''. INSEAD Working Paper, 2010_

=== Business Models for Data Journalism 

Amidst all the interest and hope regarding data-driven journalism, there is one question that newsrooms are always curious about: what are the business models?

While we must be careful about making predictions, a look at the recent history and current state of the media industry can give us some insight. Today there are many news organizations who have gained by adopting new approaches.

Terms like "data journalism" and the newest buzzword, "data science," may sound like they describe something new, but this is not strictly true. Instead these new labels are just ways of characterizing a shift that has been gaining strength over decades.

Many journalists seem to be unaware of the size of the revenue that is already generated through data collection, data analytics, and visualization. This is the business of information refinement. With data tools and technologies, it is increasingly possible to shed light on highly complex issues, be this international finance, debt, demography, education, and so on. The term "business intelligence" describes a variety of IT concepts that aim to provide a clear view on what is happening in commercial corporations. The big and profitable companies of our time, including McDonalds, Zara, and H&M, rely on constant data tracking to turn out a profit. And it works pretty well for them.

What is changing right now is that the tools developed for this space are now becoming available for other domains, including the media. And there are journalists who get it. Take Tableau, a company that provides a suite of visualization tools. Or the ``Big Data'' movement, where technology companies use (often open source) software packages to dig through piles of data, extracting insights in milliseconds.

These technologies can now be applied to journalism. Teams at the Guardian and The New York Times are constantly pushing the boundaries in this emerging field. And what we are currently seeing is just the tip of the iceberg.

But how does this generate money for journalism? The big, worldwide market that is currently opening up is all about transformation of publicly available data into something our that we can process: making data visible and making it human. We want to be able to relate to the big numbers we hear every day in the news--what the millions and billions mean for each of us.

There are a number of very profitable data-driven media companies, who have simply applied this principle earlier than others. They enjoy healthy growth rates and sometimes impressive profits. One example is Bloomberg. The company operates about 300,000 terminals and delivers financial data to its users. If you are in the money business, this is a power tool. Each terminal comes with a color-coded keyboard and up to 30,000 options to look up, compare, analyze, and help you to decide what to do next. This core business generates an estimated $6.3 billion (US) per year--at least as estimated in http://nyti.ms/IQcRgY[a 2008 piece by The New York Times]. As a result, Bloomberg has been hiring journalists left, right and center, they bought the venerable but loss-making ``Business Week,'' and so on.

Another example is the Canadian media conglomerate today known as Thomson Reuters. They started with one newspaper, bought up a number of well-known titles in the UK, and then decided two decades ago to leave the newspaper business. Instead, they have grown based on information services, aiming to provide a deeper perspective for clients in a number of industries. If you worry about how to make money with specialized information, my advice would be to just http://en.wikipedia.org/wiki/The_Thomson_Corporation[read about the company's history on Wikipedia].

And look at the Economist. The magazine has built an excellent, influential brand on its media side. At the same time, the ``Economist Intelligence Unit'' is now more like a consultancy, reporting about relevant trends and forecasts for almost any country in the world. They are employing hundreds of journalists and claim to serve about 1.5 million customers worldwide.

And there are many niche data-driven services that could serve as inspiration: eMarketer in the US, providing comparisons, charts, and advice for anybody interested in internet marketing; Stiftung Warentest in Germany, an institution looking into the quality of products and services; Statista, again from Germany, a start-up helping to visualize publicly available information.

Around the world, there is currently a wave of startups in this sector, naturally covering a wide range of areas; for example, Timetric, which aims to ``reinvent business research,'' OpenCorporates, Kasabi, Infochimps, and Data Market. Many of these are arguably experiments, but together they can be taken as an important sign of change.

Then there is the public media, which in terms of data-driven journalism, is a sleeping giant. In Germany, €7.2 billion per year is flowing into this sector. Journalism is a special product: if done well, it is not just about making money, but serves an important role in society. Once it is clear that data journalism can provide better, more reliable insights more easily, some of this money could be used for new jobs in newsrooms.

With data journalism, it is not just about being first, but about being a trusted source of information. In this multichannel world, attention can be generated in abundance, but _trust_ is an increasingly scarce resource. Data journalists can help to collate, synthesize, and present diverse and often difficult sources of information in a way that gives their audience real insights into complex issues. Rather than just recycling press releases and retelling stories they've heard elsewhere, data journalists can give readers a clear, comprehensible, and preferably customizable perspective with interactive graphics and direct access to primary sources. Not trivial, but certainly valuable.

So what is the best approach for aspiring data journalists to explore this field and convince management to support innovative projects?

++++
<?dbfo-need height="1in"?>
++++

The first step should be to look for immediate opportunities close to home: low-hanging fruit. For example, you might already have collections of structured texts and data that you could use. A prime example of this is the ``Homicide database'' of the Los Angeles Times. Here, data and visualizations are the core, not an afterthought. The editors collect all the crimes they find and only then write articles based on this. Over time, such collections are becoming better, deeper, and more valuable.

This might not work the first time. But it will over time. One very hopeful indicator here is that the Texas Tribune and ProPublica, which are both arguably post-print media companies, reported that funding for their non-profit journalism organizations exceeded their goals much earlier than planned.

Becoming proficient in all things data--whether as a generalist or as a specialist focused on one aspect of the data food chain--provides a valuable perspective for people who believe in journalism. As one well-known publisher in Germany recently said in an interview, ``There is this new group who call themselves data journalists. And they are not willing to work for peanuts anymore.''

&mdash; _Mirko Lorenz, Deutsche Welle_
