:chapnum: 03
:figure-number: 00

== Case Studies

image::figs/incoming/03-00-cover.png[float="none",role="informal"]

Στην ενότητα αυτή, θα εξετάσουμε σε βάθος, διάφορες περιπτώσεις δημοσιογραφίας δεδομένων-από εφαρμογές που αναπτύχθηκαν σε μία μέρα, μέχρι έρευνες διάρκειας εννέα μηνών. Μαθαίνουμε πώς οι πηγές δεδομένων χρησιμοποιούνται για να αυξήσουν και να βελτιώσουν την κάλυψη όλων των γεγονότων, από εκλογικές εκστρατείες  μέχρι δαπάνες, ταραχές μέχρι διαφθορά, την επίδοση των σχολείων μέχρι και την τιμή του νερού. Εκτός από τους μεγάλους δημοσιογραφικούς οργανισμούς όπως το «BBC», η «Chicago Tribune», η «Guardian», η «Financial Times», η «Helsingin Sanomat», η «La Nación», η «Wall Street Journal», και η «ZeitOnline», μαθαίνουμε και για μικρότερες πρωτοβουλίες όπως το «California Watch», το «Hack/HackersBuenos Aires», τη «ProPublica», και μια ομάδα τοπικών πολιτών-δημοσιογράφων στη Βραζιλία οι οποίοι αποκαλούνται «Friends of Januária».

=== Το «Opportunity Gap»

Η εφαρμογή  http://projects.propublica.org/schools[«Opportunity Gap»] χρησιμοποίησε δεδομένα στα οποία δεν είχε δώσει ποτέ πριν δικαιώματα πρόσβασης σε πολίτες το Υπουργείο Παιδείας των ΗΠΑ και απέδειξε ότι κάποιες πολιτείες, όπως η Φλόριντα, έχουν εξισορροπήσει τα πράγματα και προσφέρουν περίπου ίση πρόσβαση σε υψηλού επιπέδου μαθήματα σε πλούσιους και φτωχούς φοιτητές, ενώ σε άλλες πολιτείες όπως στο Kansas, στο Maryland, και στην Oklahoma, προσφέρουν λιγότερες ευκαιρίες σε περιοχές με φτωχότερες οικογένειες.

[[FIG031]]
.The Opportunity Gap project (ProPublica)
image::figs/incoming/03-YY.png[float="none"]


Τα δεδομένα περιλαμβάνουν κάθε δημόσιο σχολείο σε μια περιοχή με 3.000 μαθητές ή περισσότερους. Εκπροσωπήθηκαν περισσότερα τα ¾ του συνόλου των παιδιών από τα δημόσια σχολεία. Ένας δημοσιογράφος από το δικό μας γραφείο ειδήσεων εξασφάλισε τα δεδομένα και ο Υπεύθυνος αναφορών με τη βοήθεια υπολογιστή (Computer-Assisted Reporting Director) έκανε εκτενή εκκαθάριση.

Ήταν ένα έργο περίπου τριών μηνών. Συνολικά, έξι άνθρωποι ασχολήθηκαν με το θέμα αυτό και με την ανάπτυξης της εφαρμογής ειδήσεων: δύο συντάκτες, ένας δημοσιογράφος, ένας ειδικός στο ρεπορτάζ με βοήθεια υπολογιστή (Computer assistant reporting), και δύο προγραμματιστές. Οι περισσότεροι από εμάς δεν δουλεύαμε αποκλειστικά όλη την περίοδο. 

Το έργο πραγματικά απαιτούσε συνδυασμένες ικανότητες: εξειδικευμένη γνώση διαδικτύου, κατανόηση των βέλτιστων πρακτικών δεδομένων, ικανότητες σχεδίασης και προγραμματισμού, και ούτω καθεξής. Το πιο σημαντικό είναι ότι απαιτούσε να αναδειχθεί ένα θέμα μέσα από τα δεδομένα. Επίσης, χρειάστηκε επεξεργασία, όχι μόνο του θέματος αλλά και της ίδιας της εφαρμογής για τις ειδήσεις. 

Για το ξεκαθάρισμα και την ανάλυση των δεδομένων χρησιμοποιήσαμε περισσότερο το Excel και τα «scripts», όπως επίσης και την MS Access. Η εφαρμογή ειδήσεων σχεδιάστηκε με «Ruby on Rails» και χρησιμοποιήθηκε εκτενώς η Java Script.

Επιπλέον με την επισκόπηση του θέματος, η δημοσιογραφική μας κάλυψη αφορούσε και την ανάπτυξη διαδραστικής εφαρμογής ειδήσεων, η οποία επιτρέπει στους αναγνώστες να κατανοήσουν και να βρουν παραδείγματα μέσα από μια μεγάλη εθνική βάση δεδομένων που σχετίζεται με αυτές. Χρησιμοποιώντας, την εφαρμογή των ειδήσεων, ο αναγνώστης θα μπορούσε να βρει το σχολείο του - για παράδειγμα, το http://goo.gl/HJVCf[«Central High School»] στο Newark, N.J.— και να δει άμεσα την απόδοση του σχολείου σε ένα ευρύ φάσμα από τομείς. Τότε οι χρήστες θα μπορούν να πατήσουν ένα πλήκτρο θα ονομάζεται http://goo.gl/WrAIi[«Compare High and Low Poverty Schools»], και αμέσως θα τους εμφανίζοντας άλλα σχολεία, σε σχέση με την οικονομική τους κατάσταση, και σε ποιο βαθμό προσφέρουν υψηλότερου επιπέδου μαθηματικά, το πρόγραμμα αξιολόγησης «Advanced Placement»(πρόγραμμα αξιολόγησης), και άλλα σημαντικά μαθήματα. Στο παράδειγμά μας, το «Central High» βρίσκεται κοντά στο «Millburn Sr. High». Το «Opportunity Gap» έδειξε πως μόνο το 1% των μαθητών του «Milburn» έχει Δωρεάν ή Μειωμένο γεύμα αλλά το 72% κάνει τουλάχιστον ένα μάθημα «AP». Στο άλλο άκρο, το «International High» προσφέρει στο 85% των μαθητών του Δωρεάν/Μειωμένης Τιμής γεύμα και μόνο το 1% κάνει μαθήματα «AP».

Μέσα από αυτό το παράδειγμα, ένας αναγνώστης μπορεί να χρησιμοποιήσει κάτι που γνωρίζει-το τοπικό του σχολείο-για να καταλάβει κάτι που δεν ξέρει: την κατανομή της πρόσβασης στην εκπαίδευση, και το βαθμό στο οποίο η φτώχεια αποτελεί προγνωστικό παράγοντα αυτής της πρόσβασης. 

Επίσης, ενσωματώσαμε την εφαρμογή με το Facebook, έτσι ώστε οι αναγνώστες να μπορούν να συνδέονται με το λογαριασμό τους στο Facebook και η εφαρμογή μας να τους ενημερώνει αυτόματα για τα σχολεία τα οποία ίσως τους ενδιαφέρουν. 

Η κυκλοφορία όλων των εφαρμογών μας με ειδήσεις είναι εξαιρετική και είμαστε περήφανοι για τον τρόπο που αυτή η εφαρμογή παρουσιάζει ένα πολύπλοκο θέμα. Πιο συγκεκριμένα, βοηθάει τους αναγνώστες να δουν ένα θέμα όπως τους αφορά. 

Όπως συμβαίνει σε πολλά έργα τα οποία ξεκίνησαν με κυβερνητικά δεδομένα, τα δεδομένα χρειάζονται επεξεργασία. Για παράδειγμα, ενώ υπάρχουν μόνο περίπου 30 πιθανά μαθήματα «Advanced Placement», κάποια σχολεία αναφέρουν ότι έχουν εκατοντάδες αυτών. Αυτό απαιτεί χειροκίνητο έλεγχο, τηλεφωνήματα στα σχολεία για επιβεβαίωση και διορθώσεις.

Επίσης δουλέψαμε πολύ σκληρά για να διασφαλίσουμε ότι η εφαρμογή περιέγραψε το θέμα και με «ευρεία» και «στενή» οπτική. Αυτό σημαίνει ότι η εφαρμογή χρειάζεται να παρουσιάζει στο χρήστη μια ευρεία και αποσπασματική εθνική εικόνα. Με αυτό τον τρόπο, γίνεται σύγκριση ανάμεσα στις πολιτείες, σχετικά με την πρόσβαση στην εκπαίδευση. Όμως δεδομένου ότι η αφαίρεση πολλές φορές δημιουργεί σύγχυση στους αναγνώστες ως προς το ποια δεδομένα αφορούν τους ίδιους, θέλαμε επίσης οι αναγνώστες να μπορούν να βρουν το τοπικό τους σχολείο και να το συγκρίνουν με σχολεία υψηλού και χαμηλού βιοτικού επιπέδου, στην περιοχή τους.

Αν μπορούσα να συμβουλέψω τους επίδοξους δημοσιογράφους δεδομένων που ενδιαφέρονται να αναλάβουν τέτοιου είδους έργα, θα ήθελα να τους πω να γνωρίζουν το υλικό και να είναι φιλοπερίεργοι! Όλοι οι κανόνες που ισχύουν για τα άλλα είδη δημοσιογραφίας ισχύουν κι εδώ. Θα πρέπει να καταγράψετε τα γεγονότα σωστά, βεβαιωθείτε ότι παρουσιάζετε την είδηση σωστά, και –πολύ σημαντικό- βεβαιωθείτε ότι η εφαρμογή σας δε διαφωνεί με την είδηση που γράψατε. Εάν διαφωνεί, τότε ένα από τα δύο είναι λάθος.

Επίσης, αν θέλετε να μάθετε να προγραμματίζετε, το πιο σημαντικό πράγμα είναι να ξεκινήσετε. Ίσως θα σας άρεσε να μάθετε μέσα από μαθήματα ή μέσα από βιβλία ή βίντεο, αλλά βεβαιωθείτε ότι έχετε μια πραγματικά καλή ιδέα για ένα έργο και μια προθεσμία ώστε να το ολοκληρώσετε. Αν υπάρχει ένα θέμα στο κεφάλι σας το οποίο μπορεί μόνο να προέλθει από μία εφαρμογή για ειδήσεις, τότε το να μην ξέρετε να προγραμματίζετε δεν πρόκειται να σας σταματήσει!

&mdash; _Scott Klein, ProPublica_

=== Μια Έρευνα διάρκειας Εννιά Μηνών στα Ευρωπαϊκά Διαρθρωτικά Ταμεία

Το 2010, οι http://www.ft.com/intl/eu-funds[«Financial Times»] και το http://bit.ly/bureau-billions[«Bureau of Investigative Journalism» (BIJ)] ένωσαν τις δυνάμεις τους για να κάνουν μια έρευνα στα Ευρωπαϊκά Διαρθρωτικά Ταμεία. Η πρόθεση τους ήταν να επανεξετάσουν ποιοι είναι οι δικαιούχοι των Ευρωπαϊκών Διαρθρωτικών Ταμείων και να ελέγξουν αν τα χρήματα τοποθετούνται για καλή χρήση. Στα 347 δισεκατομμύρια των τελευταίων επτά ετών, τα Διαρθρωτικά Ταμεία είναι το δεύτερο μεγαλύτερο πρόγραμμα επιδότησης της Ευρωπαϊκής Ένωσης. Το πρόγραμμα υπάρχει εδώ και δεκαετίες, αλλά εκτός από ευρείες, γενικευμένες επισκοπήσεις, υπήρχε έλλειψη διαφάνειας σχετικά με το ποιοι είναι οι δικαιούχοι. Ως μέρος της αλλαγής των κανόνων στον τρέχοντα γύρο χρηματοδότησης, οι αρχές είναι υποχρεωμένες να δημοσιοποιήσουν τη λίστα των δικαιούχων, συμπεριλαμβανομένου της περιγραφής του έργου και του ποσού που λαμβάνουν από την κοινοτική και εθνική χρηματοδότηση.

[[FIG032]]
.EU Structural Funds investigation (Financial Times and The Bureau of Investigative Journalism)
image::figs/incoming/03-OO-01.png[float="none"]

Η ομάδα του έργου αποτελούνταν από 12 δημοσιογράφους και ένα πλήρους απασχόλησης προγραμματιστή και συνεργάστηκαν για εννιά μήνες. Η συλλογή δεδομένων μόνο, πήρε αρκετούς μήνες. Το έργο είχε ως αποτέλεσμα μέσα σε πέντε μέρες από την κάλυψη των «Financial Times» και του «BIJ», ένα ντοκιμαντέρ του ραδιοφώνου του BBC και διάφορα τηλεοπτικά ντοκιμαντέρ. Πριν ξεκινήσετε ένα έργο του επιπέδου αυτής της προσπάθειας, πρέπει να είστε βέβαιοι ότι τα ευρήματα είναι πρωτότυπα και ότι θα καταλήξετε σε σημαντικές ειδήσεις που κανείς άλλος δεν μπορεί να έχει. Η διαδικασία αυτή χωρίζεται σε έναν αριθμό από διακριτά βήματα.

==== 1. Προσδιορισμός του ποιος κρατάει τα δεδομένα και πώς τα κρατάει

Η Γενική Διεύθυνση Περιφερειών της Ευρωπαϊκής Επιτροπής έχει http://bit.ly/ec-portal[μια πύλη] για ιστοσελίδες των περιφερειακών αρχών, στην οποία δημοσιεύει τα δεδομένα. Πιστεύαμε ότι η Επιτροπή θα έχει μια γενική βάση δεδομένων των έργων στα οποία θα μπορούσαμε να έχουμε άμεσα πρόσβαση είτε θα μπορούσαμε να αποκτήσουμε πρόσβαση μέσω του αιτήματος για Ελευθερία στην Πληροφόρηση. Καμία τέτοια βάση δεδομένων δεν υπάρχει στο επίπεδο λεπτομέρειας που απαιτείται. Συνειδητοποιήσαμε γρήγορα ότι πολλοί από τους συνδέσμους που παρέχει η Επιτροπή είναι ελαττωματικοί και ότι οι περισσότερες αρχές δημοσιεύουν τα δεδομένα σε μορφή PDF, και όχι σε πιο φιλικά προς ανάλυση πρότυπα όπως το CSV ή το XML.

Μια ομάδα 12 ατόμων εργάστηκε για να εντοπίσει τα πιο πρόσφατα δεδομένα και να ταξινομήσει τις υπερσυνδέσεις σε ένα υπολογιστικό φύλλο που χρησιμοποιήσαμε συνεργατικά. Δεδομένου ότι τα πεδία δεδομένων δεν ήταν ομοιόμορφα (για παράδειγμα οι κεφαλίδες ήταν σε διαφορετικές γλώσσες, κάποιες βάσεις δεδομένων χρησιμοποιούσαν διαφορετικά νομίσματα, και κάποιες περιείχαν αναλύσεις Ευρωπαϊκών και Εθνικών Πόρων) ήταν απαραίτητο να είμαστε όσο το δυνατόν πιο ακριβείς στη μετάφραση και περιγραφή των πεδίων των δεδομένων που ήταν διαθέσιμα σε κάθε σύνολο.

==== 2. Λήψη και προετοιμασία των δεδομένων

Το επόμενο βήμα αποτελείται από τη λήψη όλων των υπολογιστικών φύλλων, των αρχείων PDF και σε μερικές περιπτώσεις την αναζήτηση στο διαδίκτυο για τα αρχικά δεδομένα. Κάθε σύνολο δεδομένων έπρεπε μετά να τυποποιηθεί. Η πιο επίπονη δουλειά ήταν η εξαγωγή δεδομένων από αρχεία PDF, τα οποία είχαν πολλές εκατοντάδες σελίδες. Το περισσότερο μέρος αυτής της εργασίας έγινε με προγράμματα όπως το UnPDFκαι το ABBYY FineReader, τα οποία επιτρέπουν την εξαγωγή δεδομένων σε άλλα πρότυπα, όπως CSV ή Excel. 

Επίσης, μέρος του έργου ήταν και ο έλεγχος ότι τα εργαλεία εξαγωγής από PDF είχαν καταγράψει σωστά τα δεδομένα. Αυτό γινόταν με φιλτράρισμα, ταξινόμηση και πρόσθεση των συνόλων (για να διασφαλιστεί ότι αντιστοιχούσαν με αυτό που είχε αποτυπωθεί στα αρχεία PDF).

==== 3. Δημιουργία βάσης δεδομένων

Ο προγραμματιστής της ομάδας  έστησε μία SQL βάση δεδομένων. Καθένα από τα έτοιμα αρχεία χρησιμοποιούνταν ως ένα δομικό στοιχείο για το σύνολο της βάσης SQL, το οποίο θα μπορούσε να αναζητηθεί σε πραγματικό χρόνο μέσω των λέξεων κλειδιών.

==== 4. Επανέλεγχος και ανάλυση

Η ομάδα ανέλυσε τα δεδομένα με δύο κύριους τρόπους:

Μέσω της βάσης δεδομένων (front end)::
  Αυτό συνεπάγεται την πληκτρολόγηση συγκεκριμένων λέξεων-κλειδιών ενδιαφέροντος (για παράδειγμα, «καπνός», «ξενοδοχείο», «εταιρία Α» στη μηχανή αναζήτησης. Με τη βοήθεια του «Google Translate», το οποίο είχε συνδεθεί με τη λειτουργία αναζήτησης της δικιάς μας βάσης δεδομένων, αυτές οι λέξεις –κλειδιά θα μεταφράζονταν σε 21 γλώσσες και θα επέστρεφαν τα κατάλληλα δεδομένα. Τα δεδομένα αυτά θα μπορούσαν να είναι διαθέσιμα στους δημοσιογράφους για περαιτέρω έρευνα στα ατομικού ενδιαφέροντος έργα τους.     
  
Μέσω μακροοικονομικής ανάλυσης χρησιμοποιώντας όλη τη βάση δεδομένων::
  Περιστασιακά, θα κάναμε λήψη μιας πλήρης βάσης δεδομένων, την οποία έπειτα θα μπορούσαμε να αναλύσουμε (για παράδειγμα, χρησιμοποιώντας λέξεις κλειδιά, ή αθροίζοντας δεδομένα ανά χώρα, περιοχή, το είδος της δαπάνης, αριθμό έργων ανά δικαιούχο, κτλ.)
  
Στο θέμα μας χρησιμοποιήθηκαν και οι δύο μέθοδοι, αλλά επίσης επί τόπου έρευνα και έρευνα από το γραφείο. 

Ο επανέλεγχος της ακεραιότητας των δεδομένων (συγκέντρωση και έλεγχος με αυτά που οι αρχές ανακοίνωναν ότι είχαν κατανεμηθεί) απαιτούσε ένα σημαντικό διάστημα. Ένα από τα κύρια προβλήματα ήταν ότι οι αρχές θα κοινοποιούσαν ως επί το πλείστον μόνο το ποσό της «κοινοτικής και εθνικής χρηματοδότησης». Σύμφωνα με τους κανόνες της Ε.Ε., κάθε πρόγραμμα επιτρέπεται να χρηματοδοτεί ένα συγκεκριμένο ποσοστό του συνολικού κόστους, χρησιμοποιώντας κοινοτική χρηματοδότηση. Το επίπεδο της χρηματοδότησης αποφασίζεται, σε επίπεδο προγράμματος, από το αποκαλούμενο ποσοστό συγχρηματοδότησης. Κάθε πρόγραμμα (για παράδειγμα, περιφερειακή ανταγωνιστικότητα) αποτελείται από πολυάριθμα έργα. Στα επίπεδα του έργου, ένα έργο θα μπορούσε τεχνικά να λάβει 100% της κοινοτικής χρηματοδότησης και κάποιο άλλο καθόλου, εφ’ όσον βρίσκονται στο ίδιο γκρουπ, καθώς το ποσό της κοινοτικής χρηματοδότησης στο επίπεδο του προγράμματος δεν υπερβαίνει το εγκεκριμένο ποσοστό συγχρηματοδότησης.   

Αυτό σήμαινε ότι, χρειαζόταν να ελέγξουμε κάθε πόσο κοινοτικής χρηματοδότησης, που αναφέραμε στα θέματά μας, με την εν λόγω δικαιούχο εταιρία.

&mdash; _Cynthia O'Murchu, Financial Times_

=== The Eurozone Meltdown

Έτσι λοιπόν, έχουμε να http://on.wsj.com/tYM82O[καλύψουμε την κατάρρευση της Ευρωζώνης], κάθε κομμάτι αυτής. Τις δραματικές σκηνές καθώς οι κυβερνήσεις συγκρούονται και οι οικονομίες μιας ζωής χάνονται. Η αντίδραση των ηγετών του κόσμου, τα μέτρα λιτότητας και οι διαμαρτυρίες κατά των μέτρων λιτότητας. Κάθε μέρα στη Wall Street Journal, υπάρχουν διαγράμματα για την απώλεια θέσεων εργασίας, τη μείωση του ΑΕΠ, που βυθίζει τις παγκόσμιες αγορές. Είναι οριακό. Σε μουδιάζει.

Οι αρχισυντάκτες της ομάδας του «Page One» έκαναν μια συνάντηση για να συζητήσουν ιδέες για την κάλυψη του θέματος με το κλείσιμο ενός χρόνου και καθώς φεύγαμε από τη συνάντηση βρίσκω τον εαυτό μου να αναρωτιέται: πώς είναι να το περνάει κανείς αυτό; 

Είναι το ίδιο όπως το 2008, όταν είχα απολυθεί και οι άσχημες ειδήσεις έπαιζαν αδιάκοπα; Μιλούσαμε για τις θέσεις εργασίας και για χρήματα κάθε βράδυ στο δείπνο, σχεδόν ξεχνώντας πως θα μπορούσαν αυτά να στεναχωρούν την κόρη μου. Και τα σαββατοκύριακα, ήταν τα χειρότερα. Προσπαθούσα να αρνηθώ το φόβο που είχα, από ένα μόνιμο πιάσιμο στο σβέρκο μου  και το σφίξιμο από το άγχος στο θώρακά μου. Το ίδιο νιώθει και μια οικογένεια στην Ελλάδα; Στην Ισπανία; Γύρισα πίσω και ακολούθησα τον Mike Allen, τον συντάκτη της «Page One», στο γραφείο του και έριξα την ιδέα να αφηγηθούμε την κρίση μέσα από τις οικογένειες της Ευρωζώνης, εξετάζοντας αρχικά τα δεδομένα, βρίσκοντας δημογραφικά στοιχεία για να αντιληφθούμε τι κάνει κάθε οικογένεια και έπειτα να το καλύψουμε με φωτογραφίες και συνεντεύξεις, καταγραφή των απόψεων κάθε ηλικίας. Θα μπορούσαμε να χρησιμοποιήσουμε μια όμορφη προσωπογραφία, τις απόψεις - και τα δεδομένα. Πίσω στο γραφείο μου, έγραψα μια περίληψη και ζωγράφισα ένα λογότυπο.


[[FIG033]]
.Η Κατάρρευση της Ευρωζώνης: σύνοψη (Wall Street Journal)
image::figs/incoming/03-ZZ-01.png[float="none"]

Για τις επόμενες τρεις εβδομάδες κυνηγούσα αριθμούς: μετρήσεις γάμων, θανάτων, το μέγεθος της οικογένειας, και δαπάνες για την υγεία. Βρήκα πληροφορίες για τις συνθήκες διαβίωσης και τα ποσοστά διαζυγίων, έψαξα έρευνες για την ευημερία και τα ποσοστά αποταμίευσης. Έψαξα τμήματα εθνικών στατιστικών, κάλεσα το γραφείο πληθυσμού των Ηνωμένων Εθνών, την IMF, Eurostat, και τον OECD μέχρι που βρήκα ένα οικονομολόγο που είχε περάσει την καριέρα του ανιχνεύοντας οικογένειες. Με οδήγησε σε μία ερευνήτρια σχετική με τη σύνθεση της οικογένειας. Μου υπέδειξε ορισμένα επίσημα επεξηγηματικά έγγραφά για το θέμα μου.

Με τον αρχισυντάκτη μου, Sam Enriquez,περιορίσαμε τις χώρες. Συγκεντρώσαμε μια ομάδα να συζητήσουμε την οπτική προσέγγιση και ποιοι δημοσιογράφοι θα μπορούσαν να παραδώσουν λέξεις, ήχο και θέμα. Ο Matt Craig, αρχισυντάκτης φωτογραφίας της «Page One», όρισε τη δουλειά και βρήκε τους φωτογράφους.

Ο Matt Murray, ο Αναπληρωτής Διευθύνων Σύμβουλος για παγκόσμια κάλυψη, έστειλε ένα σημείωμα στο γραφείο των αρχισυντακτών ζητώντας τη βοήθεια των δημοσιογράφων. (Αυτό ήταν σημαντικό: η έγκριση ήταν από ανώτερο.) 

Αλλά αρχικά ασχοληθήκαμε από τα δεδομένα. Τα πρωινά, έκανα εξαγωγή των δεδομένων σε υπολογιστικά φύλλα και έφτιαχνα διαγράμματα για να δούμε τις τάσεις: συρρίκνωση των οικονομιών, απώλεια των συντάξεων, μητέρες που αναγκάζονται να επιστρέψουν στην εργασία, δαπάνες για την υγεία μαζί με το δημόσιο χρέος και την ανεργία. Το απόγευμα μπορούσα να εξετάσω τα δεδομένα αυτά σε ομάδες, αντιπαραθέτοντας τις χώρες τη μία με την άλλη και βρίσκοντας τα θέματα. 

Το έκανα αυτό για μια εβδομάδα ώσπου χάθηκα και άρχισα να αμφιβάλλω για τον εαυτό μου.  Ίσως αυτή ήταν η λάθος προσέγγιση. Ίσως δεν αφορούσε τις χώρες, αλλά τους γονείς, τα παιδιά και τους παππούδες. Τα δεδομένα μεγάλωναν. 

Και συρρικνώθηκαν. Κάποιες φορές ξόδεψα ώρες συλλέγοντας πληροφορίες μόνο για να ανακαλύψω ότι δεν μου έλεγαν απολύτως τίποτα. Αυτό σήμαινε ότι είχα ψάξει εντελώς λάθος σειρά δεδομένων. Μερικές φορές τα δεδομένα ήταν τόσο παλιά.

[[FIG034]]
.Η διαδικασία της κρίσης της χρηστικότητας ενός συνόλου δεδομένων μπορεί να είναι ιδιαίτερα χρονοβόρα εργασία (Sarah Slobin)
image::figs/incoming/03-ZZ-04.png[float="none"]

Και τότε τα δεδομένα αυξάνονταν πάλι, καθώς αντιλαμβανόμουν ότι είχα ακόμα ερωτήσεις, και δεν καταλάβαινα τις οικογένειες.

Έπρεπε  να το παρακολουθήσω, να το διαμορφώσω. Έτσι, έκανα μια γρήγορη σειρά από γραφικά στο πρόγραμμα Illustrator και ξεκίνησα να τα τακτοποιώ και να τα επεξεργάζομαι.

Καθώς τα διαγράμματα εμφανίζονταν, έκανα μια συνεκτική εικόνα για τις οικογένειες.


[[FIG035]]
.Γραφική απεικόνιση: παρουσιάζει τις κρυμμένες τάσεις και  τα μοτίβα στα σύνολα των δεδομένων (Sarah Slobin)
image::figs/incoming/03-ZZ-06.png[scale="96",float="none"]

[[FIG036]]
.Οι αριθμοί αντιπροσωπεύουν ανθρώπους : η αξία των δεδομένων έγκειται στις προσωπικές ιστορίες που αντιπροσωπεύουν (Wall Street Journal)
image::figs/incoming/03-ZZ-07.png[scale="92",float="none"]

Ξεκινήσαμε. Κάλεσα κάθε δημοσιογράφο. Τους έστειλα τα διαγράμματα, τον ευρύ βαθμό έντασης και μια ανοιχτή πρόσκληση να ανακαλύψουν ιστορίες που θα ένιωθαν ότι ήταν ουσιαστικές, οι οποίες θα μπορούσαν να φέρουν την κρίση πιο κοντά στους αναγνώστες. Χρειαζόμασταν μια μικρή οικογένεια από το Άμστερνταμ, και μεγαλύτερες από Ισπανία και Ιταλία. Θέλαμε να ακούσουμε όλες τις ηλικίες για να δούμε πώς μια προσωπική ιστορία διαμορφώνει απαντήσεις.

Από δω και στο εξής, θα ήμουν ξύπνιος νωρίς το πρωί για να ελέγξω τα emails και να είμαι προσεκτικός με τη διαφορά ώρας μεταξύ των χωρών. Οι δημοσιογράφοι επέστρεφαν με υπέροχα θέματα, περιλήψεις, και εκπλήξεις που δεν είχα προβλέψει.

Για φωτογράφηση, ξέραμε ότι θέλαμε πορτρέτα των γενεών. Το όραμα του Matt ήταν να έχει τους φωτογράφους του να παρακολουθούν τη ζωή κάθε μέλους της οικογένειας  κατά τη διάρκεια της ημέρας. Επέλεξε φωτορεπόρτερ (visual journalists) οι οποίοι είχαν γυρίσει τον κόσμο, καλύπτοντας ειδήσεις και πολέμους ακόμα. Ο Matt ήθελε κάθε τελευταίο πλάνο να τελειώνει στο τραπέζι, την ώρα του δείπνου. Ο Sam πρότεινε να περιλαμβάνεται στο πλάνο και το μενού. 

Στο σημείο αυτό το ζήτημα ήταν να περιμένουμε να δούμε τι θα μας έλεγαν οι φωτογραφίες. Περιμένοντας να δούμε τι είχαν πει οι οικογένειες. Σχεδιάσαμε μια πιο διαδραστική άποψη. Έκλεψα μια παλέτα από το μυθιστόρημα του Tintin, δουλέψαμε μέσα από την αλληλεπίδραση. Και όταν ήταν όλα μαζί και είχαμε τα «storyboards», προσθέσαμε πίσω κάποια (όχι πολλά αλλά κάποια) από τα αρχικά διαγράμματα. Τόσα ώστε να χαρακτηρίζουν κάθε ιστορία, τόσα ώστε να κάνουν πιο σκληρό το θέμα μας. Τα δεδομένα γίνονταν μια παύση στην ιστορία μας, ένας τρόπος για να «αλλάξουμε ταχύτητα».

[[FIG037]]
.Η ζωή στη Ευρωζώνη (Wall Street Journal)
image::figs/incoming/03-ZZ-09.png[float="none"]

Στο τέλος, τα δεδομένα ήταν οι άνθρωποι. Ήταν οι φωτογραφίες και οι ιστορίες. Ήταν αυτό που πλαισιώνει κάθε αφήγηση και οδηγεί στην ένταση μεταξύ των χωρών.

Μέχρι τη στιγμή που δημοσιεύσαμε, ακριβώς πριν την πρωτοχρονιά καθώς ήμασταν όλοι σκεπτικοί για το τι βρισκόταν στον ορίζοντα, ήξερα όλα τα μέλη των οικογενειών με το όνομά τους. Ακόμα αναρωτιέμαι πώς είναι σήμερα. Και αν αυτό δεν μοιάζει σαν έργο δεδομένων, εγώ είμαι μια χαρά με αυτό. Επειδή αυτές οι στιγμές, που τεκμηριώνονται  στο «Life in the Eurozone», αυτές οι ιστορίες που κάθεστε για ένα γεύμα και συζητάτε για τη δουλειά και τη ζωή με την οικογένειά σας ήταν κάτι που μπορούσαμε να το μοιραστούμε με τους αναγνώστες μας. Η κατανόηση των δεδομένων ήταν αυτό που το κατέστησε δυνατό. 

&mdash; _Sarah Slobin, Wall Street Journal_

=== Κάλυψη του Δημόσιου Ταμείο με το OpenSpending.org

Το 2007, ο Jonathan ήρθε στο «Open Knowledge Foundation» με πρόταση μίας σελίδας για ένα έργο που ονομαζόταν http://www.wheredoesmymoneygo.org/[_Where Does My Money Go?_] το οποίο σκόπευε να κάνει ευκολότερο για του πολίτες στο Ηνωμένο Βασίλειο να καταλάβουν πώς ξοδεύονται τα δημόσια χρήματα. Αυτό επρόκειτο να είναι μια απόδειξη ενός μεγαλύτερου έργου για να αναπαραστήσουμε οπτικά πληροφορίες για το Δημόσιο, με βάση την πρωτοποριακή εργασία των Otto και Marie Neurath  του  Isotype Institute το 1940.

[[FIG038]]
.Where Does My Money Go? (Open Knowledge Foundation)
image::figs/incoming/03-PP-02.png[float="none"]

Το έργο _«Where Does My Money Go?»_ έδωσε τη δυνατότητα στους χρήστες να εξερευνήσουν δεδομένα του δημοσίου από μια μεγάλη ποικιλία πηγών χρησιμοποιώντας διαισθητικά εργαλεία ανοικτού κώδικα. Κερδίσαμε ένα βραβείο που βοήθησε να αναπτύξουμε ένα δείγμα (prototype) του έργου, και αργότερα λάβαμε χρηματοδότηση από το Channel 4’s 4IP να το μετατρέψουμε αυτό σε μια πλήρως αναπτυγμένη εφαρμογή στο διαδίκτυο. Ο ειδικός στη σχεδίαση πληροφορίας David McCandless (από την ιστοσελίδα http://www.informationisbeautiful.net/[«Information is Beautiful»]) σχεδίασε διαφορετικές απόψεις των δεδομένων που βοηθούσαν τους ανθρώπους να καταλάβουν τα μεγάλα νούμερα – συμπεριλαμβανομένου της εφαρμογής «Country and Regional Analysis», η οποία δείχνει πώς εκταμιεύονται τα χρήματα σε διάφορα μέρη της χώρας, και της εφαρμογής http://wheredoesmymoneygo.org/dailybread.html[«Daily Bread»] που δείχνει στους πολίτες μια κατανομή των φορολογικών εισφορών ανά μέρα σε λίρες και πένες. 

[[FIG039]]
.Το έργο «Where Does My Money Go?»  Η αριθμητική εφαρμογή υπολογισμού του φόρου «Daily Bread» (Open Knowledge Foundation)
image::figs/incoming/03-PP-01.png[float="none"]

Εκείνη την εποχή, το «άγιο δισκοπότηρο» για το έργο ήταν τα δεδομένα που έφεραν το πονηρό ακρωνύμιο http://data.gov.uk/dataset/coins[Combined Online Information System] (ή COINS), η οποία ήταν η πιο ολοκληρωμένη και λεπτομερής βάση δεδομένων των δημόσιων οικονομικών στο Ηνωμένο Βασίλειο, που ήταν διαθέσιμη. Δουλεύοντας με τη Lisa Evans (πριν προσχωρήσει στην ομάδα του «Guardian Datablog»), τη  Julian Todd και τον Francis Irving (τώρα διάσημοι από το Scraperwiki), τον Martin Rosenbaum (BBC) και άλλους, συμπληρώσαμε πολλές αιτήσεις για τα δεδομένα – πολλές από αυτές αποτυχημένες (ο μύθος είναι εν μέρει τεκμηριωμένος από τη Lisa στην πλευρική στήλη link:getting_data.html#foi-spending[«Using FOI to Understand Spending»]).

++++
<?dbfo-need height="1in"?>
++++

Όταν τα δεδομένα τελικά κυκλοφόρησαν στα μέσα του 2010, θεωρήθηκε ευρέως σαν πραξικόπημα για τους υποστηρικτές της διαφάνειας. Μας δόθηκε εκ των προτέρων πρόσβαση στα δεδομένα ώστε να μπορούμε να τα «ανεβάζουμε» στη διαδικτυακή μας εφαρμογή και ο Τύπος μας έδωσε ιδιαίτερη προσοχή όταν το γεγονός δημοσιοποιήθηκε. Την ημέρα της δημοσίευσης, είχαμε δεκάδες δημοσιογράφους να εμφανίζονται στο δικό μας IRC κανάλι να συζητάνε και να ρωτάνε σχετικά με την ανακοίνωση, όπως επίσης και να αναρωτιούνται για το πώς θα ξεκινήσουν και θα εξερευνήσουν την εφαρμογή (τα αρχεία είχαν 10 gigabytes μέγεθος). Ενώ μερικοί ειδήμονες ισχυρίστηκαν ότι η μαζική ανακοίνωση http://bit.ly/archive-silicon[ήταν τόσο περίπλοκη], μερικοί γενναίοι δημοσιογράφοι ασχολήθηκαν με ενθουσιασμό με τα δεδομένα για να δώσουν στους αναγνώστες τους μια πρωτοφανή εικόνα σχετικά με το πώς δαπανώνται οι δημόσιες χρηματοδοτήσεις. H Guardian ανάρτησε σε http://bit.ly/guardian-coins[blog] την είδηση της έκδοσης καθώς την κάλυψαν και πολλά άλλα μέσα ενημέρωσης, και έδωσαν αναλύσεις των χρηματοδοτήσεων χρησιμοποιώντας τα δεδομένα. 

Δεν πήρε αρκετό χρόνο πριν αρχίσουμε να λαμβάνουμε αιτήματα και ερωτήσεις σχετικά με την εκτέλεση παρόμοιων έργων σε άλλες χώρες στον κόσμο. Λίγο μετά την έναρξη του http://offenerhaushalt.de[«OffenerHaushalt»] - μια έκδοση ενός προγράμματος που αφορούσε το γερμανικό κρατικό προϋπολογισμό, η οποία δημιουργήθηκε από τον Friedrich Lindenberg- λανσάραμε το http://openspending.org/[«OpenSpending»], μια διεθνή έκδοση του προγράμματος, η οποία ελπίζαμε να βοηθήσει τους χρήστες να χαρτογραφούν τα δημόσια έξοδα από όλο τον κόσμο περίπου, όπως τους βοήθησε το «OpenStreetMap» να χαρτογραφήσουν γεωγραφικά χαρακτηριστικά. Εφαρμόσαμε νέα σχέδια με τη βοήθεια του ταλαντούχου Gregor Aisch, τα οποία βασίζονταν εν μέρει στα πρωτότυπα σχέδια του David McCandless.

[[FIG0310]]
.«OffenerHaushalt», η γερμανική έκδοση του «Where Does My Money Go?» (Open Knowledge Foundation)

image::figs/incoming/03-PP-03.png[float="none"]

Με το πρόγραμμα «OpenSpending», συνεργαστήκαμε εκτενώς με δημοσιογράφους για να συλλέξουμε, αναπαραστήσουμε, ερμηνεύσουμε και να παρουσιάσουμε τα δεδομένα των δαπανών στο κοινό. Το «OpenSpending» είναι η πρώτη και πρωτίστως πιο μεγάλη, με δυνατότητα αναζήτησης βάση δεδομένων δημοσίων δαπανών- τόσο σε πληροφορίες  προϋπολογισμού υψηλών επιπέδων, όσο σε επίπεδο συναλλαγών πραγματικών δαπανών. Στην κορυφή του έχει δημιουργηθεί μια σειρά από «out-of-the-box» οπτικοποιήσεις, όπως «treemaps» και «bubbletrees».  Ο καθένας μπορεί να τοποθετήσει τα δεδομένα του τοπικού συμβουλίου και να δημιουργήσει οπτικοποιήσεις αυτών. 

Αν και αρχικά πιστεύαμε ότι θα υπάρχει μεγαλύτερη ζήτηση για μερικές από τις πιο εξελιγμένες οπτικοποιήσεις μας, μετά τις ομιλίες με ειδησεογραφικούς οργανισμούς συνειδητοποιήσαμε ότι υπήρχαν πιο βασικές ανάγκες, που ήταν απαραίτητο να ικανοποιηθούν αρχικά, όπως η δυνατότητα να ενσωματώνουν δυναμικούς πίνακες δεδομένων στα blogposts τους. Πρόθυμοι να ενθαρρύνουμε τους ειδησεογραφικούς οργανισμούς να δίνουν πρόσβαση στο κοινό σε δεδομένα παράλληλα με τις ιστορίες τους, φτιάξαμε ένα εργαλείο και για αυτό.   

Η πρώτη μας μεγάλη έκδοση ήταν περίπου την περίοδο του πρώτου International Journalism Festival στην Περούτζια. Μια ομάδα προγραμματιστών, δημοσιογράφων και δημοσίων υπαλλήλων συνεργάστηκαν να τοποθετήσουν τα ιταλικά δεδομένα στην πλατφόρμα του «OpenSpending», η οποία έδινε μια πλούσια εικόνα για το πώς οι δαπάνες κατανέμονταν μεταξύ των κεντρικών, περιφερειακών και τοπικών διοικήσεων. Η είδηση καλύφθηκε από την http://bit.ly/ilfatto-spending[Il Fatto Quotidiano], http://bit.ly/ilpost-spending[Il Post], http://bit.ly/lastampa-spending[La Stampa], http://bit.ly/repubblica-spending[Repubblica], και http://bit.ly/wired-italy-spending[Wired Italia], όπως επίσης και την  http://bit.ly/guardian-italy-spending[Guardian].

[[FIG0311]]
.Η ιταλική έκδοση του προγράμματος «Where Does My Money Go?» (La Stampa)
image::figs/incoming/03-PP-04.png[float="none"]

++++
<?dbfo-need height="1in"?>
++++

Το 2011 συνεργαστήκαμε με το http://www.publishwhatyoufund.org/[«Publish What You Fund»] και το http://www.odi.org.uk/[Overseas Development Institute] για να χαρτογραφήσουμε τη χρηματοδοτική ενίσχυση της Ουγκάντα την περίοδο  2003-2006. Αυτό ήταν κάτι καινούριο επειδή για πρώτη φορά θα μπορούσατε να δείτε τις ροές της χρηματοδοτικής ενίσχυσης παράλληλα με τον εθνικό προϋπολογισμό-δίνοντας σε σας τη δυνατότητα να παρατηρήσετε σε ποιο βαθμό οι προτεραιότητες των δωρεών ευθυγραμμίζονται με τις προτεραιότητες των κυβερνήσεων. Υπήρχαν μερικά ενδιαφέροντα συμπεράσματα-για παράδειγμα, τόσο τα προγράμματα αντιμετώπισης του HIV, όσο και ο οικογενειακός προγραμματισμός αναδείχθηκαν σχεδόν εξ ολοκλήρου χρηματοδοτούμενα από τους εξωτερικούς δωρητές. Αυτή η είδηση καλύφθηκε από τη http://bit.ly/guardian-uganda-viz[Guardian].

Συνεργαστήκαμε επίσης με μη κυβερνητικές οργανώσεις και ομάδες υποστήριξης, διασταυρώνοντας στοιχεία με άλλες πηγές πληροφόρησης. Για παράδειγμα,  η «Privacy International» μας προσέγγισε με μια λίστα εταιριών με τεχνολογίες επιτήρησης καθώς και ένα κατάλογο γραφείων που συμμετέχουν σε γνωστή διεθνή έκθεση για συστήματα παρακολούθησης, κοινώς γνωστή ως «wire tappers ball». Με συστηματική διασταύρωση των ονομάτων εταιριών με βάσεις δεδομένων δαπανών, ήταν πιθανό να ταυτοποιηθούν ποιες εταιρίες είχαν συμβάσεις με την κυβέρνηση-οι οποίες θα μπορούσαν αργότερα να παρακολουθούνται με αιτήματα για ελεύθερη πληροφόρηση (Freedom of Information, FOI). Αυτό καλύφθηκε από τη http://bit.ly/guardian-surveillance[Guardian].

Αυτή τη στιγμή εργαζόμαστε στο να αυξήσουμε τη γνώση περί δημοσιονομικών, μεταξύ των δημοσιογράφων και του κοινού, ως κομμάτι http://bit.ly/ss-faq[ενός προγράμματος που ονομάζεται «Spending Stories»], το οποίο επιτρέπει στους χρήστες να συνδέσουν τα δεδομένα δημοσίων δαπανών με θέματα που σχετίζονται με δημόσιες δαπάνες, για να δουν τους αριθμούς πίσω από τις ειδήσεις, και τις ειδήσεις γύρω από τους αριθμούς.

Μέσα από τη δουλειά μας σε αυτό το πεδίο, μάθαμε ότι:

  * Οι δημοσιογράφοι δεν είναι εξοικειωμένοι να δουλεύουν με μη-επεξεργάσιμα δεδομένα, και πολλοί δεν τα θεωρούν απαραίτητη βάση για την είδησή τους. Η προέλευση των θεμάτων τους από ανεπεξέργαστες πληροφορίες είναι ακόμα μια σχετικά νέα ιδέα. 
  * Η ανάλυση και κατανόηση δεδομένων είναι χρονοβόρα διαδικασία, ακόμα και με τις απαραίτητες δεξιότητες. Η τοποθέτηση αυτών σε ένα σύντομο κύκλο ειδήσεων είναι δύσκολη, κι έτσι η δημοσιογραφία δεδομένων χρησιμοποιείται συχνά σε μακροπρόθεσμα έργα έρευνας.
  * Τα δεδομένα που κυκλοφορούν από τις κυβερνήσεις είναι συχνά ελλιπή ή ξεπερασμένα. Πολύ συχνά, οι δημόσιες βάσεις δεδομένων δεν μπορούν να χρησιμοποιηθούν για ερευνητικούς σκοπούς, χωρίς την προσθήκη περισσότερων ειδικών πληροφοριών που ζητούνται μέσω του «FOI». 
  * Ομάδες υποστήριξης, επιστήμονες και ερευνητές συχνά έχουν περισσότερο χρόνο και πόρους για τη διεξαγωγή πιο εκτενούς έρευνας προσανατολισμένη σε δεδομένα από τους δημοσιογράφους. Μπορεί να είναι πιο εποικοδομητική η συνεργασία με αυτούς και η δουλειά σε ομάδες. 

&mdash; _Lucy Chambers and Jonathan Gray, Open Knowledge Foundation_

++++
<?dbfo-need height="2in"?>
++++

=== Κοινοβουλευτικές Εκλογές Φιλανδίας και Χρηματοδότηση Εκστρατείας

Τους τελευταίους μήνες υπήρξαν σε εξέλιξη δοκιμές, σχετικές με τη χρηματοδότηση προεκλογικών εκστρατειών των γενικών φιλανδικών εκλογών του 2007.

Μετά τις εκλογές του 2007, ο Τύπος ανακάλυψε ότι οι νόμοι σχετικά με τη δημοσιοποίηση της χρηματοδότησης της προεκλογικής εκστρατείας δεν επηρέαζαν τους πολιτικούς. Βασικά, η χρηματοδότηση της εκστρατείας χρησιμοποιήθηκε για να εξαγοραστούν χάρες από τους πολιτικούς, οι οποίοι στη συνέχεια απέτυχαν να δηλώσουν τη χρηματοδότησή τους, όπως ορίζει ο φιλανδικός νόμος.

Μετά από αυτά τα γεγονότα, οι νόμοι έγιναν αυστηρότεροι. Μετά τις γενικές εκλογές το Μάρτιο του 2011, ο Helsingin Sanomat αποφάσισε να εξετάσει λεπτομερώς όλα τα διαθέσιμα αρχεία σχετικά με τη χρηματοδότηση της κάθε εκστρατείας. Ο καινούριος νόμος ορίζει ότι η χρηματοδότηση των εκλογών πρέπει να δηλωθεί και μόνο οι δωρεές κάτω από 1.500 ευρώ μπορούν να είναι ανώνυμες.

==== 1. Find data and developers

Ο Helsingin Sanomat οργανώνει το «HS Open hackathons» από το Μάρτιο 2011. Καλέσαμε Φιλανδούς προγραμματιστές, δημοσιογράφους και γραφίστες στο υπόγειο του κτιρίου μας. Οι συμμετέχοντες χωρίζονται σε ομάδες των τριών και παροτρύνονται να αναπτύξουν εφαρμογές και οπτικοποιήσεις. Είχαμε περίπου 60 συμμετέχοντες σε καθεμία από τις τρεις εκδηλώσεις μας, μέχρι τώρα. Αποφασίσαμε ότι  τα δεδομένα από την προεκλογική εκστρατεία θα πρέπει να είναι το επίκεντρο του HS Open#2, Μάιος 2011.

Η Εθνική Ελεγκτική Υπηρεσία της Φιλανδίας είναι η Αρχή που κρατά τα αρχεία χρηματοδότησης της εκστρατείας. Αυτό ήταν το εύκολο μέρος. Ο Διευθυντής Πληροφοριακών Συστημάτων Jaakko Hamunen  δημιούργησε μια ιστοσελίδα η οποία παρείχε σε πραγματικό χρόνο πρόσβαση στη δικιά τους βάση δεδομένων που αφορούσε τη χρηματοδότηση της προεκλογικής εκστρατείας. Η Ελεγκτική Υπηρεσία το έκανε σε μόλις δύο μήνες μετά το αίτημά μας.  

Η ιστοσελίδα http://www.vaalirahoitus.fi/[«Vaalirahoitus.fi»] θα παρέχει στο κοινό και στον Τύπο πληροφορίες για τη χρηματοδότηση που λαμβάνουν οι προεκλογικές εκστρατείες  σε κάθε εκλογές, από τώρα και στο εξής.

[[FIG0312]]
.Χρηματοδότηση προεκλογικής εκστρατείας (Helsingin Sanomat)
image::figs/incoming/03-DD.png[float="0"]


==== 2. Συζήτηση ιδεών (Brainstorm for ideas)

Οι συμμετέχοντες του «HS Open 2» ήρθαν με 20 διαφορετικά πρωτότυπα σχετικά με το τι θα κάνουμε με τα δεδομένα. Μπορείτε να βρείτε όλα τα πρωτότυπα στην http://bit.ly/hs-prototype[ιστοσελίδα μας] (το κείμενο είναι στα φιλανδικά).

Ο Janne Peltola, ερευνητής βιοπληροφορικής,  σημείωσε ότι τα στοιχεία χρηματοδότησης που αφορούν τις προεκλογικές εκστρατείες έμοιαζαν με τα δεδομένα γονιδίων που εξερευνούν, από την άποψη ότι περιέχουν πολλές αλληλοεξαρτήσεις. Στη βιοπληροφορική υπάρχει ένα «open source» εργαλείο που ονομάζεται http://www.cytoscape.org/[«Cytoscape»] και χρησιμοποιείται για τη χαρτογράφηση αυτών των αλληλοεξαρτήσεων. Οπότε τρέξαμε τα δεδομένα στο «Cytoscape», και πήραμε ένα πολύ ενδιαφέρον δείγμα (prototype). 

==== 3. Εφαρμογή της ιδέας στο χαρτί και στο διαδίκτυο

Ο νόμος για τη χρηματοδότηση που αφορά τις προεκλογικές εκστρατείες αναφέρει ότι τα εκλεγμένα μέλη του κοινοβουλίου πρέπει να δηλώνουν τη χρηματοδότηση που έλαβαν, δύο μήνες μετά τις εκλογές. Στην πράξη αυτό σήμαινε ότι πήραμε τα πραγματικά δεδομένα στα μέσα Ιουνίου. Στο «HS Open», είχαμε δεδομένα μόνο από μέλη του κοινοβουλίου που τα είχαν καταθέσει πριν τη λήξη της προθεσμίας.

Υπήρχε επίσης, ένα πρόβλημα με τη μορφή των δεδομένων. Η Εθνική Ελεγκτική Υπηρεσία παρείχε τα δεδομένα σε δύο CSV αρχεία. Το ένα περιείχε το συνολικό προϋπολογισμό από τις εκστρατείες, το άλλο απαριθμούσε τους δωρητές. Έπρεπε να συνδυάσουμε αυτά τα δύο, δημιουργώντας ένα αρχείο που περιείχε τρεις στήλες: δωρητής, αποδέκτης και ποσό. Εάν οι πολιτικοί είχαν χρησιμοποιήσει δικά τους χρήματα, η μορφή των δεδομένων μας ήταν έτσι, Πολιτικός Α δώρισε Χ ευρώ στον Πολιτικό Α. Ίσως ήταν αντιφατικό, αλλά δούλεψε με το Cytoscape. 

Όταν τα δεδομένα μας καθαρίστηκαν και μορφοποιήθηκαν, απλά τρέξαμε το «Cytoscape». Στη συνέχεια το τμήμα γραφικών έκανε ένα ολοσέλιδο γραφικό από αυτά. 

Τέλος, δημιουργήσαμε μια όμορφη απεικόνιση στην http://www.vaaliraha.com/[ιστοσελίδα μας]. Αυτό δεν ήταν μόνο μια διαδικτυακή γραφική ανάλυση. Θέλαμε να δείξουμε στους ανθρώπους ένα εύκολο τρόπο να εξερευνήσουν πόση χρηματοδότηση υπάρχει και από ποιον δίνεται στις προεκλογικές εκστρατείες. Η πρώτη άποψη απεικονίζει την κατανομή της χρηματοδότησης μεταξύ των μελών του κοινοβουλίου. Όταν κάνετε κλικ και επιλέγετε ένα μέλος, μπορείτε να δείτε τη κατανομή χρηματοδότησης που πήρε. Μπορείτε επίσης, να ψηφίσετε για το αν ένας δωρητής είναι καλός ή όχι. Η οπτικοποίηση έγινε από τους Juha Rouvinen και Jukka Kokko, από το διαφημιστικό γραφείο Satumaa. 

Η διαδικτυακή έκδοση της οπτικοποίησης χρηματοδότησης των εκστρατειών χρησιμοποιεί τα ίδια δεδομένα, όπως η διαδικτυακή ανάλυση.


==== 4. Δημοσιοποίηση των δεδομένων

Φυσικά η Εθνική Ελεγκτική Υπηρεσία δημοσιεύει ήδη τα στοιχεία, ώστε να μην υπάρχει ανάγκη αναδημοσίευσης. Ωστόσο, επειδή είχαμε κάνει μία εκκαθάριση των δεδομένων  και ήταν με καλύτερη δομή, αποφασίσαμε να τα δημοσιεύσουμε. Δημοσιεύσαμε τα δεδομένα μας με άδεια «http://creativecommons.org/licenses/by/3.0/[Creative Commons Attribution»]. Μεταγενέστερα αρκετοί ανεξάρτητοι προγραμματιστές έχουν κάνει τις δικές τους οπτικοποιήσεις των δεδομένων, κάποιες από τις οποίες έχουμε δημοσιεύσει.

Τα εργαλεία που χρησιμοποιήσαμε για το έργο ήταν το Excel και το Google Refine για τον καθαρισμό και ανάλυση των δεδομένων. Το  «Cytoscape» χρησιμοποιήθηκε για διαδικτυακή ανάλυση και το Illustrator και το Flash για τις οπτικοποιήσεις. Το Flash θα έπρεπε να ήταν σε HTML5, αλλά δεν είχαμε άλλο χρόνο. Τι μάθαμε; Ίσως το πιο σημαντικό μάθημα ήταν ότι οι δομές των δεδομένων μπορεί να είναι πολύ δύσκολες. Εάν τα αρχικά δεδομένα δεν είναι σε κατάλληλη μορφή, ο επαναϋπολογισμός και η μετατροπή τους θα χρειαστεί πολύ χρόνο.

=== «Electoral Hack» σε πραγματικό χρόνο (Hacks/Hackers Μπουένος Άιρες)
[[FIG0313]]
.Εκλογές 2011 (Hacks/Hackers Buenos Aires)
image::figs/incoming/03-FF.png[float="none"]

Το http://elecciones.hhba.info[Electoral Hack] είναι ένα έργο πολιτικής ανάλυσης που οπτικοποιεί δεδομένα από τα προσωρινά αποτελέσματα των ψηφοδελτίων του Οκτωβρίου 2011 στις εκλογές της Αργεντινής. Το σύστημα επίσης, διαθέτει πληροφορίες από προηγούμενες εκλογές και κοινωνικο-δημογραφικά στατιστικά από όλη τη χώρα. Το έργο ενημερωνόταν σε πραγματικό χρόνο με πληροφορίες από την προσωρινή καταμέτρηση των ψηφοδελτίων στις εθνικές εκλογές του 2011 στην Αργεντινή και έδινε συνόψεις των εκλογικών αποτελεσμάτων. Ήταν μια πρωτοβουλία των Hacks/Hackers του Μπουένος Άιρες με τον πολιτικό αναλυτή Andy Tow και ήταν μία συνεργατική προσπάθεια δημοσιογράφων, σχεδιαστών, αναλυτών, πολιτικών επιστημόνων και άλλων, από το τοπικό τμήμα των Hacks/Hackers.

==== Τι δεδομένα χρησιμοποιήσαμε; 

Όλα τα δεδομένα προήλθαν από επίσημες πηγές: το Εθνικό Εκλογικό Γραφείο (National Electoral Bureau) παρείχε πρόσβαση στα δεδομένα της προσωρινής καταμέτρησης από το Indra. Το Υπουργείο Εσωτερικών παρείχε πληροφορίες σχετικά με τα αιρετά αξιώματα και τους υποψήφιους από διαφορετικά πολιτικά κόμματα. Ένα http://yoquierosaber.org/[πανεπιστημιακό έργο] παρείχε βιογραφικά στοιχεία και το πολιτικό πρόγραμμα κάθε Προέδρου. Οι κοινωνικο-δημογραφικές πληροφορίες προήλθαν από την Εθνική Απογραφή του 2001 του Πληθυσμού και Στέγασης (INDEC), την Απογραφή του 2010 (INDEC) και το Υπουργείο Υγείας.

==== Πώς αναπτύχθηκε;

Η εφαρμογή δημιουργήθηκε κατά τη διάρκεια του «2011 Election Hackathon» από τους Hacks/Hackers του Μπουένος Άιρες, την ημέρα πριν τις εκλογές, στις 23 Οκτωβρίου 2011. Το «hackathon» παρακολούθησε τη συμμετοχή των 30 εθελοντών με μια ποικιλία από διαφορετικά υπόβαθρα.   

Το «Electoral Hack» αναπτύχθηκε ως μια ανοιχτή πλατφόρμα, η οποία θα μπορούσε  να βελτιωθεί με την πάροδο του χρόνου. Για την τεχνολογία, χρησιμοποιήσαμε τα Google Fusion Tables, Google Maps και βιβλιοθήκες γραφικών διανυσμάτων.

Δουλέψαμε για την κατασκευή των πολυγώνων για την εμφάνιση γεωγραφικής χαρτογράφησης και των εκλογικών δημογραφικών στοιχείων. Συνδυάζοντας τα πολύγωνα με λογισμικό GIS και γεωμετρίες από κοινούς πίνακες στο Google Fusion Tables, δημιουργήσαμε πίνακες με πλήκτρα που αντιστοιχούν στην εκλογική βάση δεδομένων του Υπουργείου Εσωτερικών, του Indra, και στα κοινωνικο-δημογραφικά δεδομένα από το INDEC. Από αυτό δημιουργήσαμε οπτικοποιήσεις στο Google Maps.

Χρησιμοποιώντας το Google Maps API, δημοσιοποιήσαμε αρκετούς θεματικούς χάρτες που απεικόνιζαν την χωρική κατανομή της ψηφοφορίας με διαφορετικές αποχρώσεις, όπου η ένταση του χρώματος, που αντιπροσώπευε το ποσοστό των ψήφων από διάφορες προεδρικές αναμετρήσεις, σε διαφορετικά διοικητικά διαμερίσματα και εκλογικά τμήματα, με ιδιαίτερη έμφαση στα μεγάλα αστικά κέντρα: η πόλη του Μπουένος Άιρες, οι 24 περιφέρειες της Μείζονος του Μπουένος Άιρες, η πόλη της Κόρδοβα, και η Ροσάριο. Χρησιμοποιήσαμε τις ίδιες τεχνικές για την παραγωγή θεματικών χαρτών από προηγούμενες εκλογές, δηλαδή τις προεδρικές εκλογές του 2011 και την εκλογή του 2007, όπως επίσης και την κατανομή των κοινωνικο-δημογραφικών στοιχείων, όπως η φτώχεια, η παιδική θνησιμότητα, και οι συνθήκες διαβίωσης, επιτρέποντας την ανάλυση και τη σύγκριση. Το έργο επίσης, έδειξε τις διαφορές, με γεωγραφική κατανομή, στο ποσοστό των ψήφων, που συγκέντρωσε κάθε υποψηφιότητα στις γενικές εκλογές του Οκτωβρίου, σε σύγκριση με τις πρώτες του Αυγούστου.

Αργότερα, χρησιμοποιώντας μερικά στοιχεία από τις προσωρινές καταμετρήσεις, δημιουργήσαμε ένα χάρτη, που αναπαριστούσε την ανατομία της καταμέτρησης, στον οποίο η πρόοδος της καταμέτρησης των ψήφων εμφανιζόταν από το κλείσιμο των τοπικών δημοσκοπήσεων μέχρι το επόμενο πρωί.

==== Πλεονεκτήματα

  * Θέτουμε ως στόχο να βρούμε και να απεικονίσουμε τα δεδομένα και είμαστε ικανοί να το κάνουμε αυτό. Είχαμε τη http://infoargentina.unicef.org.ar/[βάση δεδομένων της UNICEF], των κοινωνικο-δημογραφικών στοιχείων των παιδιών, όπως επίσης τη βάση δεδομένων των υποψήφιων που δημιουργήθηκε από την ομάδα yoquierosaber.org του Πανεπιστημίου Torcuato Di Tella. Κατά τη διάρκεια του hackathon συλλέξαμε ένα μεγάλο αριθμό επιπλέον στοιχείων τα οποία τελικά δεν συμπεριλάβαμε.
  * Ήταν σαφές ότι η δημοσιογραφική και προγραμματιστική δουλειά δεν ενισχύθηκαν από υποτροφία. Χωρίς τη συνεισφορά των Andy Tow και Hilario Moreno Campos, το έργο θα ήταν αδύνατο να επιτευχθεί.

==== Cons

  * The sociodemographic data we could use was not up to date (most was from the 2001 census), and it was not very granular. For example, it did not include detail about local average GDP, main economic activity, education level, number of schools, doctors per capita, and lots of other things that it would have been great to have.

  * Originally the system was intended as a tool that could be used to combine and display any arbitrary data, so that journalists could easily display data that interested them on the Web. But we had to leave this for another time.

  * As the project was built by volunteers in a short time frame, it was impossible to do everything that we wanted to do. Nevertheless, we made a lot of progress in the right direction.

  * For the same reason, all the collaborative work of 30 people ended up condensed into a single programmer when the data offered by the government began to appear, and we ran into some problems importing data in real time. These were solved within hours.

==== Implications

The Electoral Hack platform had a big impact in the media, with television, radio, print and online coverage. Maps from the project were used by several media platforms during the elections and in subsequent days. As the days went by, the maps and visualizations were updated, increasing traffic even more. On Election Day, the site created that very day received about 20 thousand unique visitors and its maps were reproduced on the cover page of the newspaper Página/12 for two consecutive days, as well as in articles in La Nación. Some maps appeared in the print edition of the newspaper Clarín. It was the first time that an interactive display of real-time maps had been used in the history of Argentine journalism. In the central maps one could clearly see the overwhelming victory of Cristina Fernandez de Kirchner by 54 percent of the vote, broken up by color saturation. It also served to help users understand specific cases where local candidates had landslide victories in the provinces.

&mdash; _Mariano Blejman, Mariana Berruezo, Sergio Sorín, Andy Tow, and Martín Sarsale from Hacks/Hackers Buenos Aires_

=== Data in the News: WikiLeaks

It began with one of the investigative reporting team asking, ``You're good with spreadsheets, aren't you?'' And this was one hell of a spreadsheet: 92,201 rows of data, each one containing a detailed breakdown of a military event in Afghanistan. This was the http://bit.ly/guardian-warlogs[WikiLeaks war logs]. Part one, that is. There were to be two more episodes to follow: Iraq and the cables. The official term was SIGACTS: the US military Significant Actions Database.

The Afghanistan war logs--shared with The New York Times and Der Spiegel--was data journalism in action. What we wanted to do was enable our team of specialist reporters to get great human stories from the information--and we wanted to analyze it to get the big picture, to show how the war really is going.

It was central to what we would do quite early on that we would not publish the full database. WikiLeaks was already going to do that and we wanted to make sure that we didn't reveal the names of informants or unnecessarily endanger NATO troops. At the same time, we needed to make the data easier to use for our team of investigative reporters led by David Leigh and Nick Davies (who had negotiated releasing the data with Julian Assange). We also wanted to make it simpler to access key information, out there in the real world, as clear and open as we could make it.

The data came to us as a huge Excel file; over 92,201 rows of data, some with nothing in it at all or poorly formatted. It didn't help reporters trying to trawl through the data for stories and was too big to run meaningful reports on.

Our team built a simple internal database using SQL. Reporters could now search stories for key words or events. Suddenly the dataset became accessible and generating stories became easier.

The data was well structured: each event had the following key data: time, date, a description, casualty figures, and--crucially--detailed latitude and longitude.

[[FIG0314]]
.The WikiLeaks war logs (the Guardian)
image::figs/incoming/03-GG.jpg[float="0"]

We also started filtering the data to help us tell one of the key stories of the war: the rise in IED (improvised explosive device) attacks, homemade roadside bombs which are unpredictable and difficult to fight. This dataset was still massive, but easier to manage. There were around 7,500 IED explosions or ambushes (an ambush is where the attack is combined with, for example, small arms fire or rocket grenades) between 2004 and 2009. There were another 8,000 IEDs which were found and cleared. We wanted to see how they changed over time--and how they compared. This data allowed us to see that the south, where British and Canadian troops were based then, was the worst-hit area--which backed up what our reporters who had covered the war knew.

The Iraq war logs release in October 2010 dumped another 391,000 records of the Iraq war into the public arena.

This was in a different league to the Afghanistan leak; there's a good case for saying this made the war the most documented in history. Every minor detail was now there for us to analyze and break down. But one factor stands out: the sheer volume of deaths, most of which are civilians.

As with Afghanistan, the Guardian decided not to republish the entire database, largely because we couldn't be sure the summary field didn't contain confidential details of informants and so on.

But we did allow our users to download a spreadsheet containing the records of every incident where somebody died, nearly 60,000 in all. We removed the summary field so it was just the basic data: the military heading, numbers of deaths, and the geographic breakdown.

We also took all these incidents where someone had died and http://bit.ly/guardian-iraq-map[put it on a map using Google Fusion tables]. It was not perfect, but a start in trying to map the patterns of destruction that had ravaged Iraq.

December 2010 saw the release of the cables. This was in another league altogether, a huge dataset of official documents: 251,287 dispatches, from more than 250 worldwide US embassies and consulates. It's a unique picture of US diplomatic language--including over 50,000 documents covering the current Obama administration. But what did the data include?

The cables themselves came via the huge Secret Internet Protocol Router Network, or SIPRNet. SIPRNet is the worldwide US military Internet system, kept separate from the ordinary civilian Internet and run by the Department of Defense in Washington. Since
the attacks of September 2001, there had been a move in the US to link up archives of government information, in the hope that key intelligence no longer gets trapped in information silos or "stovepipes." An increasing number of US embassies have become linked to SIPRNet over the past decade, so that military and diplomatic information can be shared. By 2002, 125 embassies were on SIPRNet: by 2005, the number had risen to 180, and by now the vast majority of US missions worldwide are linked to the system--which is why the bulk of these cables are from 2008 and 2009. As David Leigh wrote:

____
An embassy dispatch marked SIPDIS is automatically downloaded onto its embassy classified website. From there, it can be accessed not only by anyone in the state department, but also by anyone in the US military who has a security clearance up to the "Secret" level, a password, and a computer connected to SIPRNet.
____

...which astonishingly covers over 3 million people. There are several layers of data in here; all the way up to _SECRET NOFORN_, which means that they are designed never be shown to non-US citizens. Instead, they are supposed to be read by officials in Washington up to the level of Secretary of State Hillary Clinton. The cables are normally drafted by the local ambassador or subordinates. The ``Top Secret'' and above foreign intelligence documents cannot be accessed from SIPRNet.

Unlike the previous releases, this was predominantly text, not quantified or with identical data. This is what was included:

A source::
  The embassy or body which sent it.

A list of recipients::
  Normally cables were sent to a number of other embassies and bodies.

A subject field::
  A summary of the cable.

Tags::
  Each cable was tagged with a number of keyword abbreviations.

Body text::
  The cable itself. We opted not to publish these in full for obvious security reasons.

One interesting nuance of this story is how the cables have almost created leaks on demand. They led the news for weeks upon being published; now, whenever a story comes up about some corrupt regime or international scandal, access to the cables gives us access to new stories.

Analysis of the cables is an enormous task which may never be entirely finished.

&mdash; _This is an edited version of a chapter first published in Facts are Sacred: The Power of Data by Simon Rogers, the Guardian (published on Kindle)_


===  Mapa76 Hackathon

We opened the http://www.meetup.com/HacksHackersBA/[Buenos Aires chapter of Hacks/Hackers] in April 2011. We hosted two initial meetups to publicize the idea of greater collaboration between journalists and software developers, with between 120 and 150 people at each event. For a third meeting we had a 30-hour hackathon with eight people at a digital journalism conference in the city of Rosario, 300 kilometers from Buenos Aires.

A recurring theme in these meetings was the desire to scrape large volumes of data from the Web, and then to represent it visually. To help with this, a project called Mapa76.info was born, which helps users to extract data and then to display it using maps and timelines. Not an easy task.

[[FIG0315]]
.Mapa76 (Hacks/Hackers Buenos Aires)
image::figs/incoming/03-MM.png[float="none"]

Why Mapa76? On March 24, 1976 there was a coup in Argentina, which lasted until 1983. In that period, there were an estimated 30,000 disappeared people, thousands of deaths, and 500 children born in captivity appropriated for the military dictatorship. Over 30 years later, the number of people in Argentina convicted of crimes against humanity committed during the dictatorship amounts to 262 people (September 2011). Currently there are 14 ongoing trials and 7 with definite starting dates. There are 802 people in various open court cases.

These prosecutions generate large volumes of data that are difficult for researchers, journalists, human rights organizations, judges, prosecutors, and others to process. Data is produced in a distributed manner and investigators often don't take advantage of software tools to assist them with interpreting it. Ultimately this means that facts are often overlooked and hypotheses are often limited. Mapa76 is an investigative tool providing open access to this information for journalistic, legal, juridical, and historical purposes.

To prepare for the hackathon, we created a platform which developers and journalists could use to collaborate on the day of the event. Martin Sarsale developed some basic algorithms to extract structured data from simple text documents. Some libraries were also used from DocumentCloud.org project, but not many. The platform would automatically analyze and extract names, dates and places from the texts--and would enable users to explore key facts about different cases (e.g., date of birth, place of arrest, alleged place of disappearance, and so on).

Our goal was to provide a platform for the automatic extraction of data on the judgments of the military dictatorship in Argentina. We wanted a way to automatically (or at least semi-automatically) display key data related to cases from 1976-1983 based on written evidence, arguments and judgments. The extracted data (names, places and dates) are collected, stored, and can be analyzed and refined by the researcher, as well as being explored using maps, timelines, and network analysis tools.

The project will allow journalists and investigators, prosecutors and witnesses to follow the story of a person's life, including the course of their captivity and subsequent disappearance or release. Where information is absent, users can comb through a vast number of documents for information that could be of possible relevance to the case.

For the hackathon, we made a public announcement through http://www.meetup.com/HacksHackersBA/[Hacks/Hackers Buenos Aires], which then had around 200 members (at the time of writing, there are around 540). We also contacted many human rights associations. The meeting was attended by about forty people, including journalists, advocacy organizations, developers and designers.

During the hackathon, we identified tasks that different types of participants could pursue independently to help things run smoothly. For example, we asked designers to work on an interface that combined maps and timelines, we asked developers to look into ways of extracting structured data and algorithms to disambiguate names, and we asked journalists to look into what happened with specific people, to compare different versions of stories, and to comb through documents to tell stories about particular cases.

Probably the main problem we had after the hackathon was that our project was very ambitious, our short-term objectives were demanding, and it is hard to coordinate a loose-knit network of volunteers. Nearly everyone involved with the project had a busy day job and many also participated in other events and projects. Hacks/Hackers Buenos Aires had 9 meetings in 2011.

The project is currently under active development. There is a core team of four people working with over a dozen collaborators. We have a http://groups.google.com/group/mapa76-dev/[public mailing list] and https://github.com/mapa76/[code repository] through which anyone can get involved with the project.

&mdash; _Mariano Blejman, Hacks/Hackers Buenos Aires_

=== The Guardian Datablog's Coverage of the UK Riots

During the summer of 2011, the UK was hit by a wave of riots. At the time, politicians suggested that these actions were categorically not linked to poverty and those who did the looting were simply criminals. Moreover, the Prime Minister, along with leading conservative politicians, blamed social media for causing the riots, suggesting that incitement had taken place on these platforms and that riots were organized using Facebook, Twitter, and Blackberry Messenger (BBM). There were calls to temporarily shut social media down. Because the government did not launch an inquiry into why the riots happened, the Guardian, in collaboration with the London School of Economics, set up the groundbreaking http://www.guardian.co.uk/uk/series/reading-the-riots[Reading the Riots] project to address these issues.

[[FIG0316]]
.The UK Riots: every verified incident (the Guardian)
image::figs/incoming/03-ZZ.png[float="0"]

The newspaper extensively used data journalism to enable the public to better understand who was doing the looting and why. What is more, they also worked with another team of academics, led by Professor Rob Procter at the University of Manchester, to better understand the role of social media, which the Guardian itself had extensively used in its reporting during the riots. The Reading the Riots team was led by Paul Lewis, the Guardian's Special Projects Editor. During the riots Paul reported on the front line in cities across England (most notably via his Twitter account, @paullewis). This second team worked on 2.6 million riot tweets donated by Twitter. The main aim of this social media work was to see how rumors circulate on Twitter, the function different users/actors have in propagating and spreading information flows, to see whether the platform was used to incite, and to examine other forms of organization.

In terms of the use of data journalism and data visualizations, it is useful to distinguish between two key periods: the period of the riots themselves and the ways in which data helped tell stories as the riots unfolded; and then a second period of much more intense research with two sets of academic teams working with the Guardian, to collect data, analyze it, and write in-depth reports on the findings. The results from the first phase of the Reading the Riots project were published during a week of extensive coverage in early December 2011. Below are some key examples of how data journalism was used during both periods.

==== Phase One: The Riots As They Happened

By using simple maps, the Guardian data team showed the http://bit.ly/guardian-riots-map[locations of confirmed riots spots] and through http://bit.ly/guardian-riots-poverty[mashing up deprivation data with where the riots took place], started debunking the main political narrative that there was no link to poverty. Both of these examples used off-the-shelf mapping tools, and in the second example, combine location data with another dataset to start making other connections and links.

In relation to the use of social media during the riots (in this case, Twitter), the newspaper created a http://bit.ly/guardian-riots-twitter[visualization of riot-related hashtags used during this period], which highlighted that Twitter was mainly used to respond to the riots rather than to organize people to go looting, with _#riotcleanup_, the spontaneous campaign to clean up the streets after the rioting, showing the most significant spike during the riot period.

==== Phase Two: Reading the Riots

When the paper reported its findings from months of intensive research and working closely with two academic teams, two visualizations stand out and have been widely discussed. The first one, http://bit.ly/guardian-riots-commute[a short video], shows the results of combining the known places where people rioted with their home address and showing a so-called "riot commute." Here the paper worked with transport mapping specialist, ITO World, to model the most likely route traveled by the rioters as they made their way to various locations to go looting, highlighting different patterns for different cities, with some traveling long distances.

The second one deals with the ways in which rumors spread on Twitter. In discussion with the academic team, seven rumors were agreed on for analysis. The academic team then collected all data related to each rumor and devised a coding schedule that coded the tweet according to four main codes: people simply repeating the rumor (making a claim), rejecting it (making a counter claim), questioning it (query), or simply commenting (comment). All tweets were coded in triplicate and http://bit.ly/guardian-riots[the results were visualized] by the Guardian Interactive Team. The Guardian team has http://bit.ly/guardian-riots-twitter-interactive[written about how they built the visualization].

++++
<?dbfo-need height="1in"?>
++++

What is so striking about this visualization is that it powerfully shows what is very difficult to describe and that is the viral nature of rumors and the ways in which their life cycle plays out over time. The role of the mainstream media is evident in some of these rumors (for example, outright debunking them, or indeed confirming them quickly as news), as is the corrective nature of Twitter itself in terms of dealing with such rumors. This visualization not only greatly aided the storytelling, but also gave a real insight into how rumors work on Twitter, which provides useful information for dealing with future events.

What is clear from the last example is the powerful synergy between the newspaper and an academic team capable of an in-depth analysis of 2.6 million riot tweets. Although the academic team built a set of bespoke tools to do their analysis, they are now working to http://www.analysingsocialmedia.org/[make these widely available to anyone who wishes to use them] in due course, providing a workbench for their analysis. Combined with the how-to description provided by the Guardian team, it will provide a useful case study of how such social media analysis and visualization can be used by others to tell such important stories.

&mdash; _Farida Vis, University of Leicester_

=== Illinois School Report Cards

Each year, the Illinois State Board of Education releases school "report cards," data on the demographics and performance of all the public schools Illinois. It's a massive dataset--this year's drop was ~9,500 _columns_ wide. The problem with that much data is choosing what to present. (As with any software project, the hard part is not _building_ the software, but building the _right_ software.)

We worked with the reporters and editor from the education team to choose the interesting data. (There's a lot of data out there that seems interesting but which a reporter will tell you is actually flawed or misleading.)

We also surveyed and interviewed folks with school-age kids in our newsroom. We did this because of an empathy gap--nobody on the news apps team has school-age kids. Along the way, we learned much about our users and much about the usability (or lack thereof!) of the previous version of our schools site.

[[FIG0317]]
.2011 Illinois school report cards (Chicago Tribune)
image::figs/incoming/03-EE.png[float="none"]

We aimed to design for a couple of specific users and use cases:

* Parents with a child in school who want to know how their school measures up
* Parents who're trying to sort out where to live, since school quality often has a major impact on that decision.

The first time around, the schools site was about a six-week, two-developer project. Our 2011 update was a four-week, two-developer project. (There were actually three people actively working on the recent project, but none were full-time, so it adds up to about two.)

++++
<?dbfo-need height="1in"?>
++++

A key piece of this project was information design. Although we present far less data than is available, it's still a _lot_ of data, and making it digestible was a challenge. Luckily, we got to borrow someone from our graphics desk--a designer who specializes in presenting complicated information. He taught us much about chart design and, in general, guided us to a presentation that is readable, but does not underestimate the reader's ability or desire to understand the numbers.

The site was built in Python and Django. The data is housed in MongoDB--the schools data is heterogeneous and hierarchical, making it a poor fit for a relational database. (Otherwise we probably would have used PostgreSQL.)

We experimented for the first time with Twitter's Bootstrap user interface framework on this project, and were happy with the results. The charts are drawn with Flot.

The app is also home to the many stories about school performance that we've written. It acts as sort of a portal in that way; when there's a new school performance story, we put it at the top of the app, alongside lists of schools relevant to the story. (And when a new story hits, readers of www.chicagotribune.com are directed to the app, not the story.)

Early reports are that readers love the schools app. The feedback we've received has been largely positive (or at least constructive!), and page views are through the roof. As a bonus, this data will remain interesting for a full year, so although we expect the hits to trail off as the schools stories fade from the homepage, our past experience is that readers have sought out this application year-round.

A few key ideas we took away from this project are:

* The graphics desk is your friend. They're good at making complex information digestible.

* Ask the newsroom for help. This is the second project for which we've conducted a newsroom-wide survey and interviews, and it's a great way to get the opinion of thoughtful people who, like our audience, are diverse in background and generally uncomfortable with computers.

* Show your work! Much of our feedback has been requests for the data that the application used. We've made a lot of the data publicly available via an API, and we will shortly release the stuff that we didn't think to include initially.

&mdash; _Brian Boyer, Chicago Tribune_

=== Hospital Billing 

Investigative reporters at http://californiawatch.org/[CaliforniaWatch] received tips that a large chain of hospitals in California might be systematically gaming the federal Medicare program that pays for the costs of medical treatments of Americans aged 65 or older. The particular scam that was alleged is called _upcoding_, which means reporting patients having more complicated conditions--worth higher reimbursement--than actually existed. But a key source was a union that was fighting with the hospital chain's management, and the CaliforniaWatch team knew that independent verification was necessary for the story to have credibility.

Luckily, California's department of health has public records that give very detailed information about each case treated in all the state's hospitals. The 128 variables include up to 25 diagnosis codes from the "International Statistical Classification of Diseases and Related Health Problems" manual (commonly known as ICD-9) published by the World Health Organization. While patients aren't identified by name in the data, other variables tell the age of the patient, how the costs are paid, and which hospital treated him. The reporters realized that with these records, they could see if the hospitals owned by the chain were reporting certain unusual conditions at significantly higher rates than were being seen at other hospitals.

[[FIG0318]]
.Kwashiorkor (California Watch)
image::figs/incoming/03-AA.png[float="0"]

The datasets were large; nearly 4 million records per year. The reporters wanted to study six years worth of records in order to see how patterns changed over time. They ordered the data from the state agency; it arrived on CD-ROMs that were easily copied into a desktop computer. The reporter doing the actual data analysis used a system called http://www.sas.com/[SAS] to work with the data. SAS is very powerful (allowing analysis of many millions of records) and is used by many government agencies, including the California health department, but it is expensive--the same kind of analysis could have been done using any of a variety of other database tools, such as Microsoft Access or the open-source http://www.mysql.com/[MySQL].

With the data in hand and the programs written to study it, finding suspicious patterns was relatively simple. For example, one allegation was that the chain was reporting various degrees of malnutrition at much higher rates than were seen at other hospitals. Using SAS, the data analyst extracted frequency tables that showed the numbers of malnutrition cases being reported each year by each of California's more than 300 acute care hospitals. The raw frequency tables then were imported into Microsoft Excel for closer inspection of the patterns for each hospital; Excel's ability to sort, filter and calculate rates from the raw numbers made seeing the patterns easy.

Particularly striking were reports of a condition called Kwashiorkor, a protein deficiency syndrome that is almost exclusively seen in starving infants in famine-afflicted developing countries. Yet the chain was reporting its hospitals were diagnosing Kwashiorkor among elderly Californians at rates as much as 70 times higher than http://bit.ly/californiawatch-malnutrition[the state average of all hospitals].

For other stories, the analysis used similar techniques to examine the reported rates http://bit.ly/californiawatch-rare[of conditions like septicemia, encephalopathy, malignant hypertension, and autonomic nerve disorder]. And another analysis looked at allegations that the chain was admitting from its emergency rooms into hospital care http://bit.ly/californiawatch-chains[unusually high percentages of Medicare patients], whose source of payment for hospital care is more certain than is the case for many other emergency room patients.

To summarize, stories like these become possible when you use data to produce evidence to test independently allegations being made by sources who may have their own agendas. These stories also are a good example of the necessity for strong public records laws; the reason the government requires hospitals to report this data is so that these kinds of analyses can be done, whether by government, academics, investigators, or even citizen journalists. The subject of these stories is important because it examines whether millions of dollars of public money is being spent properly.

&mdash; _Steve Doig,  Walter Cronkite School of Journalism, Arizona State University_

=== Care Home Crisis 
// Commented out until clarification on license received
//[[FIG0319]]
//._Private care faces crises_ (Financial Times)
//image::figs/incoming/03-NN.png[float="none"]

A http://on.ft.com/care-home-crisis[Financial Times investigation] into the private care home industry exposed how some private equity investors turned elderly care into a profit machine and highlighted the deadly human costs of a business model that favored investment returns over good care.

The analysis was timely, because the financial problems of Southern Cross, then the country's largest care home operator, were coming to a head. The government had for decades promoted a privatization drive in the care sector and continued to tout the private sector for its astute business practices.

Our inquiry began with analyzing data we obtained from the UK regulator in charge of inspecting care homes. The information was public, but it required a lot of persistence to get the data in a form that was usable.

The data included ratings (now defunct) on individual homes' performance and a breakdown of whether they were private, government-owned, or non-profit. The Care Quality Commission (CQC), up to June 2010, rated care homes on quality (0 stars = poor, to 3 stars = excellent).

The first step required extensive data cleaning, as the data provided by the Care Quality Commission for example contained categorizations that were not uniform. This was primarily done using Excel. We also determined--through desk and phone research--whether particular homes were owned by private-equity groups. Before the financial crisis, the care home sector was a magnet for private equity and property investors, but several--such as Southern Cross--had begun to face serious financial difficulties. We wanted to establish what effect, if any, private equity ownership had on quality of care.

A relatively straightforward set of Excel calculations enabled us to establish that the non-profit and government-run homes, on average, performed significantly better than the private sector. Some private equity-owned care home groups performed well over average, and others well below average.

Paired with on-the-ground reporting, case studies of neglect, an in-depth look at the failures in regulatory policies, as well as other data on levels of pay, turnover rates, etc., our analysis was able to paint a picture of the true state of elderly care.

Some tips:

  * Make sure you keep notes on how you manipulate the original data.
  * Keep a copy of the original data and never change the original.
  * Check and double-check the data. Do the analysis several times (if need be, from scratch).
  * If you mention particular companies or individuals, give them a right to reply.

&mdash; _Cynthia O'Murchu, Financial Times_

=== The Tell-All Telephone

Most people's understanding of what can actually be done with the data provided by our mobile phones is theoretical; there were few real-world examples. That is why Malte Spitz from the German Green party decided to publish his own data. To access the information, he had to file a suit against telecommunications giant Deutsche Telekom. The data, contained in a massive Excel document, was the basis for Zeit Online's pass:[<phrase role='keep-together'>accompanying</phrase>] interactive map. Each of the 35,831 rows of the spreadsheet represent an instance when Spitz's mobile phone transferred information over a half-year period.

Seen individually, the pieces of data are mostly harmless. But taken together they provide what investigators call a profile: a clear picture of a person's habits and preferences, and indeed, of her life. This profile reveals when Spitz walked down the street, when he took a train, when he was in a plane. It shows that he mainly works in Berlin and which cities he visited. It shows when he was awake and when he slept.

[[FIG0320]]
.The Tell-All Telephone (Zeit Online)
image::figs/incoming/03-BB.png[scale="93",float="none"]

Deutsche Telekom’s dataset already kept one part of Spitz's data record private, namely, whom he called and who called him. That kind of information could not only infringe on the privacy of many other people in his life, it would also--even if the numbers were encrypted--reveal much too much about Spitz (but government agents in the real world would have access to this information).

We asked Lorenz Matzat and Michael Kreil from OpenDataCity to explore the data and find a solution for the visual presentation. “At first we used tools like Excel and Fusion Tables to understand the data ourselves. Then we started to develop a map interface to allow the audience to interact with the data in a non-linear way,” said Matzat. To illustrate just how much detail from someone’s life can be mined from this stored data, finally this was augmented with publicly accessible information about his whereabouts (Twitter, blog entries, party information like public calendar entries from his website). It is the kind of process that any good investigator would likely use to profile a person under observation. Together with Zeit Online's in-house graphics and R&D team they finalized a great interface to navigate: by pushing the play button, you’ll set off on a trip through Malte Spitz’s life.

After a very successful launch of the project in Germany, we noticed that we were having very high traffic from outside Germany and decided to create an English version of the app. After earning the German Grimme Online Award, the project was honored with an ONA Award in September 2011, the first time for a German news website.

All of the data is available in a http://bit.ly/zeitonline-data[Google Docs spreadsheet].
Read the story http://www.zeit.de/datenschutz/malte-spitz-data-retention[on Zeit Online].

&mdash; _Sascha Venohr, Zeit Online_

=== Which Car Model? MOT Failure Rates

In January 2010, the BBC obtained data about the MOT pass and fail rates for different makes and models of cars. This is the test that assesses whether a car is safe and roadworthy; any car over three years old has to have an MOT test annually.

We obtained the data under freedom of information following an extended battle with VOSA, the Department for Transport agency that oversees the MOT system. VOSA turned down our FOI request for these figures on the grounds that it would breach commercial confidentiality. It argued that it could be 'commercially damaging' to vehicle manufacturers with high failure rates. However, we then appealed to the Information Commissioner, who ruled that disclosure of the information would be in the public interest. VOSA then released the data, 18 months after we asked for it.

We analyzed the figures, focusing on the most popular models and comparing cars of the same age. This showed wide discrepancies. For example, among three year-old cars, 28% of Renault Méganes failed their MOT, in contrast to only 11% of Toyota Corollas. The figures were reported on television, radio, and online.

[[FIG0321]]
.MOT failure rates released (BBC)
image::figs/incoming/03-CC.png[float="none"]

The data was given to us as a 1,200 page PDF document, which we then had to convert into a spreadsheet to do the analysis. As well as reporting our conclusions, we published this Excel spreadsheet (with over 14,000 lines of data) on the BBC News website http://bbc.in/mot-failure-rates[along with our story]. This gave everyone else access to the data in a usable form.

The result was that others then used this data for their own analyses, which we did not have time to do in the rush to get the story out quickly (and which in some cases would have stretched our technical capabilities at the time). This included examining the failure rates for cars of other ages, comparing the records of manufacturers rather than individual models, and creating searchable databases for looking up the results of individuals models. We added links to these sites to our online news story, so our readers could get the benefit of this work.

This illustrated some advantages of releasing the raw data to accompany a data-driven story. There may be exceptions (for example, if you are planning to use the data for other follow-up stories later and want to keep it to yourself in the meantime), but on the whole publishing the data has several important benefits:

* Your job is to find things out and tell people about them. If you've gone to the trouble of obtaining all the data, it's part of your job to pass it on.

* Other people may spot points of significant interest which you've missed, or simply details that matter to them even if they weren't important enough to feature in your story.

* Others can build on your work with further, more detailed analysis of the data, or different techniques for presenting or visualizing the figures, using their own ideas or technical skills that may probe the data productively in alternative ways.

* It's part of incorporating accountability and transparency into the journalistic process. Others can understand your methods and check your work if they want to.

&mdash; _Martin Rosenbaum, BBC_


=== Bus Subsidies in Argentina

Since 2002, subsidies for the public bus transportation system in Argentina have been growing exponentially, breaking a new record every year. But in 2011, after winning the elections, Argentina's new government announced cuts in subsidies for public services starting December of the same year. At the same time the national government decided to transfer the administration of the local bus lines and metro lines to the City of Buenos Aires government. As the transfer of subsidies to this local government hasn't been clarified and there was a lack of sufficient local funds to guarantee the safety of the transportation system, the government of the City of Buenos Aires rejected this decision.

As this was happening, I and my colleagues at La Nación were meeting for the first time to discuss how to start our own data journalism operation. Our Financial Section Editor suggested that the subsidies data published by the http://www.transporte.gov.ar/[Secretaría de Transporte] (the Department of Transportation) would be a good challenge to start with, as it was very difficult to make sense of due to the format and the terminology.

The poor conditions of the public transportation system impact the life of more than 5,800,000 passengers every day. Delays, strikes, vehicle breakdowns, or even accidents are often happening. We thus decided to look into where the subsidies for the public transportation system in Argentina go and make this data easily accessible to all Argentinian citizens by means of a “Transport Subsidies Explorer,” which is currently in the making.

[[FIG0322]]
.The Transport Subsidies Explorer (La Nación)
image::figs/incoming/03-LL-01.jpg[float="0"]

We started with calculating how much bus companies receive every month from the government. To do this, we looked at the data published on the http://www.transporte.gov.ar/content/subsidios-sistau/[website of the Department of Transportation], where more than 400 PDFs containing monthly cash payments to more than 1,300 companies since 2006 were published.

[[FIG0323]]
.Ranking subsidized transport companies (La Nación)
image::figs/incoming/03-LL-02.jpg[float="0"]

We teamed up with a senior programmer to develop a scraper in order to automate the regular download and conversion of these PDFs into Excel and Database files. We are using the resulting dataset with more than 285,000 records for our investigations and visualizations, in both print and online. Additionally, we are making this data available in machine-readable format for every Argentinian to reuse and share.

The next step was to identify how much the monthly maintenance of a public transport vehicle costed the government on average. To find this out we went to another government website, that of the http://www.cnrt.gov.ar/index2.htm[Comisión Nacional de Regulación del Transporte] (CNRT, or The National Commission for the Regulation of Transport), responsible for regulating transportation in Argentina. On this website, we found a list of bus companies that owned 9000 vehicles altogether. We developed a normalizer to allow us to reconcile bus company names and cross-reference the two datasets.

To proceed, we needed the registration number of each vehicle. On the CNRT website, we found a list of vehicles per bus line per company with their license plates. Vehicle registration numbers in Argentina are composed of letters and numbers that correspond to the vehicle's age. For example, my car has the registration number IDF234, and the “I” corresponds to March-April 2011. We reverse engineered the license plates for buses belonging to all listed companies to find the average age of buses per company, in order to show how much money goes to each company and compare the amounts based on the average age of their vehicles.

In the middle of this process, the content of the government-released PDFs containing the data we needed mysteriously changed, although the URLs and names of the files remained the same. Some PDFs were now missing the vertical "totals," making it impossible to cross-check totals across all the entire investigated time period, 2002-2011.

We took this case to a hackathon organized by Hacks/Hackers in Boston, where developer Matt Perry generously created what we call the “PDF Spy.” This application won the  "Most Intriguing” category in that event. The http://gristlabs.com/2011/09/24/pdfspy/[PDF Spy] points at a web page full of PDFs and checks if the content within the PDFs has changed. “Never be fooled by ‘government transparency' again,” writes Matt Perry.

[[FIG0324]]
.Comparing age of fleets to the amount of money they receive from government (La Nación)
image::figs/incoming/03-LL-03.jpg[float="0"]


==== Who Worked on the Project?

A team of seven journalists, programmers and an interactive designer were working on this investigation for 13 months.

The skills we needed for this project were:
 
  * Journalists with knowledge of how the subsidies for the public transportation system work and what the risks were; knowledge of the bus companies market.
  * A programmer skilled in Web scraping, parsing and normalizing data, and extracting data from PDFs into Excel spreadsheets.
  * A statistician for conducting the data analysis and the different calculations.
  * A designer for producing the interactive data visualizations.

==== What Tools Did We Use?

We used VBasic for applications, Excel Macros, Tableau Public, and the Junar Open Data Platform, as well as Ruby on Rails, the Google charts API, and Mysql for the Subsidies Explorer.

The project had a great impact. We've had tens of thousands of views and the investigation was featured on the front page of La Nación's print edition. 

The success of this first data journalism project helped us internally to make the case for establishing a data operation that would cover investigative reporting and provide service to the public. This resulted in Data.lanacion.com.ar, a platform where we publish data on various topics of public interest in machine-readable format.

&mdash; _Angélica Peralta Ramos, La Nación (Argentina)_

=== Citizen Data Reporters

Large newsrooms are not the only ones that can work on data-powered stories. The same skills that are useful for data journalists can also help citizens reporters access data about their locality, and turn them into stories.

This was the primary motivation of the citizen media project http://amigosdejanuaria.wordpress.com/[Friends of Januária], in Brazil, which received a grant from http://rising.globalvoicesonline.org/[Rising Voices], the outreach arm of http://globalvoicesonline.org/[Global Voices Online], and additional support from the organization http://www.article19.org/[Article 19]. Between September and October 2011, a group of young residents of a small town located in north of the state of Minas Gerais, which is one of the poorest regions of Brazil, were trained in basic journalism techniques and budget monitoring. They also learned how to make Freedom of Information requests and access publicly available information from official databases on the Internet.

Januária, a town of approximately 65,000 residents, is also renowned for the failure of its local politicians. In three four-year terms, it had seven different mayors. Almost all of them were removed from office due to wrongdoing in their public administrations, including charges of corruption.

Small towns like Januária often fail to attract attention from the Brazilian media, which tends to focus on larger cities and state capitals. However, there is an opportunity for residents of small towns to become a potential ally in the monitoring of the public administration because they know the daily challenges facing their local communities better than anyone. With the Internet as another important ally, residents can now better access information such as budget and other local data.

[[FIG0325]]
.The Friends of Januária citizen media project teaches key skills to citizens to turn them into data journalists
image::figs/incoming/03-XX.jpg[float="0"]

After taking part in twelve workshops, some of the new citizen reporters from Januária began to demonstrate how this concept of accessing publicly available data in small towns can be put into practice. For example, Soraia Amorim, a 22 year-old citizen journalist, wrote a story about the number of doctors that are on the city payroll according to Federal Government data. However, she found that the official number did not correspond with the situation in the town. To write this piece, Soraia had access to health data, which is available online at the http://bit.ly/tabnet-datasus[website of the SUS (Sistema Único de Saúde or Unique Health System)], a federal program that provides free medical assistance to the Brazilian population. According to SUS data, Januária should have 71 doctors in various health specialities.

The number of doctors indicated by SUS data did not match what Soraia knew about doctors in the area: residents were always complaining about the lack of doctors and some patients had to travel to neighboring towns to see one. Later, she interviewed a woman that had recently been in a motorcycle accident and could not find medical assistance at Januária's hospital because no doctor was available. She also talked to the town's Health Secretary, who admitted that there were less doctors in town than the number published by SUS.

These initial findings raise many questions about reasons for this difference between the official information published online and the town's reality. One of them is that the federal data may be wrong, which would mean that there is an important lack of health information in Brazil. Another possibility may be that Januária is incorrectly reporting the information to SUS. Both of these possibilities should lead to a deeper investigation to find the definitive answer. However, Soraia's story is an important part of this chain because it highlights an inconsistency and may also encourage others to look more closely at this issue.

"I used to live in the countryside, and finished high school with a lot of difficulty," says Soraia. "When people asked me what I wanted to do with my life, I always told them that I wanted to be a journalist. But I imagined that it was almost impossible due to the world I lived in." After taking part in the Friends of Januária training, Soraia believes that access to data is an important tool to change the reality of her town. "I feel able to help to change my town, my country, the world," she adds.

Another citizen journalist from the project is 20 year-old Alysson Montiériton, who also used data for an article. It was during the project's first class, when the citizen reporters walked around the city to look for subjects that could become stories, that Alysson decided to write about a broken traffic light located in a very important intersection, which had remained broken since the beginning of the year. After learning how to look for data on the Internet, he searched for the number of vehicles that exists in town and the amount of taxes paid by those who own cars. He wrote:

____
The situation in Januária gets worse because of the high number of vehicles in town. According to IBGE (the most important statistics research institute in Brazil), Januária had 13,771 vehicles (among which 7,979 were motorcycles) in 2010. … The town's residents believe that the delay in fixing the traffic light is not a result of lack of resources. According to the Treasury Secretary of Minas Gerais state, the town received 470 thousand reais in vehicle taxes in 2010.
____

By having access to data, Alysson was able to show that Januária has many vehicles (almost one for every five residents), and that a broken traffic light could put a lot of people in danger. Furthermore, he was able to tell his audience the amount of funds received by the town from taxes paid by vehicle owners and, based on that, to question whether this money would not be enough to repair the traffic light to provide safe conditions to drivers and pedestrians.

Although the two stories written by Soraia and Alysson are very simple, they show that data can be used by citizen reporters. You don't need to be in a large newsroom with a lot of specialists to use data in your articles. After twelve workshops, Soraia and Alysson, neither of whom have a background in journalism, were able to work on data-powered stories and write interesting pieces about their local situation. In addition, their articles show that data itself can be useful even on a small scale. In other words, that there is also valuable information in small datasets and tables--not only in huge databases.

&mdash; _Amanda Rossi, Friends of Januária_

=== The Big Board for Election Results

Election results provide great visual storytelling opportunities for any news organization, but for many years this was an opportunity missed for us. In 2008, we and the graphics desk set out to change that.

We wanted to find a way to display results that told a story and didn't feel like just a jumble of numbers in a table or on a map. In previous elections, that's exactly http://nyti.ms/senate-1[what] http://nyti.ms/senate-2[we] http://nyti.ms/senate-3[did].

Not that there is necessarily anything wrong with a big bag of numbers, or what I call the ``CNN model'' of tables, tables, and more tables. It works because it gives the reader pretty much exactly what she wants to know: who won?

And the danger in messing with something that isn't fundamentally broken is significant. By doing something radically different and stepping away from what people expect, we could have made things more confusing, not less.

In the end, it was Shan Carter of the graphics desk who came up with the right answer, what we eventually ended up calling the http://nyti.ms/board-elections[``big board'']. When I saw the mockups for the first time, it was quite literally a head-slap moment.

It was exactly right.

[[FIG0326]]
.The big board for election results (New York Times)
image::figs/incoming/03-ZZ-ZZ.png[float="none"]

What makes this a great piece of visual journalism? To begin with, the reader's eye is immediately drawn to the big bar showing the electoral college votes at the top, what we might in the journalism context call the _lede_. It tells the reader exactly what she wants to know, and it does so quickly, simply and without any visual noise.

Next, the reader is drawn to is the five-column grouping of states below, organized by how likely The Times felt a given state was to go for one candidate or the other. There in the middle column is what we might call in the journalism context our _nut graph_, where we explain why Obama won. The interactive makes that crystal clear: Obama took all the states he was expected to and four of the five toss-up states.

++++
<?dbfo-need height="1in"?>
++++

To me, this five-column construct is an example of how visual journalism differs from other forms of design. Ideally, a great piece of visual journalism will be both beautiful and informative. But when deciding between story or aesthetics, the journalist must err on the side of story. And while this layout may not be the way a pure designer might choose to present the data, it does tell the story very, very well.

And finally, like any good web interactive, this one invites the reader to go deeper still. There are details like state-by-state vote percentages, the number of electoral votes and percent reporting deliberately played down so as not to compete with the main points of the story.

All of this makes the ``big board'' a great piece of visual journalism that maps almost perfectly to the tried-and-true inverted pyramid.

&mdash; _Aron Pilhofer, New York Times_

=== Crowdsourcing the Price of Water

Since March 2011, information about the price of tap water throughout France is gathered through a crowdsourcing experiment. In just 4 months, over 5,000 people fed up with corporate control of the water market took the time to look for their water utility bill, scan it, and upload it on http://www.prixdeleau.fr/[Prix de l'Eau] ("price of water") project. The result is an unprecedented investigation that brought together geeks, NGO, and traditional media to improve transparency around water projects.

[[FIG0327]]
.The Price of Water (Fondation France Liberté)
image::figs/incoming/03-WW.jpg[float="none"]


The French water utility market consists in over 10,000 customers (cities buying water to distribute to their taxpayers) and just a handful of utility companies. The balance of power on this oligopoly is distorted in favor of the corporations, which sometimes charge different prices to neighboring towns!

++++
<?dbfo-need height="1in"?>
++++

The French NGO France Libertés has been dealing with water issues worldwide for the past 25 years. It now focuses on improving transparency on the French market and empowering citizens and mayors, who negotiate water utility deals. The French government decided to tackle the problem 2 years ago with a nationwide census of water price and quality. So far, only 3% of the data has been collected. To go faster, http://www.france-libertes.org/[France Libertés] wanted to get citizens directly involved.

++++
<?dbfo-need height="2in"?>
++++

Together with the OWNI team, I designed a crowdsourcing interface where users would scan their water utility bill and enter the price they paid for tap water on http://www.prixdeleau.fr/[prixdeleau.fr]. In the past 4 months, 8,500 signed up and over 5,000 bills have been uploaded and validated.

While this does not allow for a perfect assessment of the market situation, it showed stakeholders such as national water-overseeing bodies that there was a genuine, grassroots concern about the price of tap water. They were skeptical at first about transparency, but changed their minds over the course of the operation, progressively joining France Libertés in its fight against opacity and corporate malpractice. What can media organizations learn from this?

Partner with NGOs::
  NGOs need large amount of data to design policy papers. They will be more willing to pay for a data collection operation than a newspaper executive.

Users can provide raw data::
  Crowdsourcing works best when users do a data collection or data-refining task.

Ask for the source::
  We pondered whether to ask users for a scan of the original bill, thinking it would deter some of them (especially as our target audience was older than average). While it might have put off some, it increased the credibility of the data.

Set up a validation mechanism::
  We designed a point system and a http://www.prixdeleau.fr/valider[peer-review mechanism] to vet user contributions. This proved too convoluted for users, who had little incentive to make repeated visits to the website. It was used by the France Libertés team, however, whose 10 or so employees did feel motivated by the points system.

Keep it simple::
  We built an automated mailing mechanism so that users could file a Freedom of Information request regarding water pricing in just a few clicks. Though innovative and well-designed, this feature did not provide substantial ROI (only 100 requests have been sent).

Target your audience::
  France Libertés partnered with consumers' rights news magazine _60 Millions de Consommateurs_, who got their community involved in a big way. It was the perfect match for such an operation.

Choose your key performance indicators carefully::
  The project gathered only 45,000 visitors in 4 months, equivalent to 15 minutes worth of traffic on http://www.nytimes.com/[nytimes.com]. What’s really important is that 1 in 5 signed up and 1 in 10 took the time to scan and upload his or her utility bill.

&mdash; _Nicolas Kayser-Bril, Journalism++_
