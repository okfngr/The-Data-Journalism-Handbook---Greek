:chapnum: 05
:figure-number: 00

== Κατανοώντας τα δεδομένα

image::figs/incoming/05-00-cover.png[float="none",role="informal"]

++++
<?dbfo-need height="1in"?>
++++

Από την στιγμή που έχετε τα δεδομένα σας, τι θα κάνετε με αυτά; Τι θα πρέπει να ψάξετε; Τι εργαλεία πρέπει να χρησιμοποιήσετε; Αυτή η ενότητα ξεκινά με μερικές ιδέες για την βελτίωση του αλφαβητισμού των δεδομένων σας, συμβουλές για την επεξεργασία αριθμών και στατιστικών και σημεία που θα πρέπει να έχετε υπόψη όταν δουλεύετε με  ανοργάνωτα, ελλιπή  και πολλές φορές ατεκμηρίωτα δεδομένα. Στην συνέχεια θα μάθουμε πως θα εξάγουμε ιστορίες από τα δεδομένα, περιλαμβανομένου τα εργαλεία που χρησιμοποιούν οι δημοσιογράφοι που ασχολούνται με τα δεδομένα και πώς να χρησιμοποιούμε την απεικόνιση των δεδομένων ώστε να αποκτούμε επίγνωση του θέματος που μελετούμε. 

=== Αποκτήστε αλφαβητισμό των δεδομένων σε τρία απλά βήματα

Όπως o αλφαβητισμός αναφέρεται «στην ικανότητα να διαβάζουμε για την γνώση, να γράφουμε συνεκτικά και να σκεφτόμαστε κριτικά σχετικά με το τυπωμένο υλικό», o αλφαβητισμός των δεδομένων είναι η ικανότητα να καταναλώνουμε για την γνώση, να παράγουμε με συνοχή και να σκεφτόμαστε με κριτικό πνεύμα για τα δεδομένα. Ο αλφαβητισμός των δεδομένων περιλαμβάνει τον στατιστικό αλφαβητισμό αλλά και την κατανόηση πως δουλεύουμε με μεγάλα σύνολα δεδομένων, πως παράχθηκαν, πως μπορούμε να συνδέσουμε διάφορα σύνολα δεδομένων και πως τα ερμηνεύουμε. 

[[FIG051]]
.http://www.flickr.com/photos/jdhancock/3386035827/[Digging into data] (photo by JDHancock)
image::figs/incoming/05-MM.jpg[float="none"]

++++
<?dbfo-need height="1in"?>
++++

Το πανεπιστήμιο του Poynter’s News προσφέρει μαθήματα μαθηματικών για δημοσιογράφους στα οποία οι ρεπόρτερ λαμβάνουν υποστήριξη σχετικά με έννοιες όπως οι ποσοστιαίες μεταβολές και οι μέσοι όροι. Ενδιαφέρον είναι το γεγονός ότι αυτές οι έννοιες διδάσκονται ταυτόχρονα δίπλα στα γραφεία του Poynter στα σχολεία της Φλόριντα σε μαθητές της πέμπτης τάξης (ηλικίας 10-11),  όπως επιβεβαιώνει το σχολικό πρόγραμμα. 

Το γεγονός ότι οι δημοσιογράφοι χρειάζονται βοήθεια σε μαθηματικά θέματα που καλύπτονται πριν το λύκειο δείχνει πόσο οι αίθουσες τύπου απέχουν από τον αλφαβητισμό των δεδομένων. Αυτό αποτελεί πρόβλημα. Πώς μπορεί ένα δημοσιογράφος που ασχολείται με δεδομένα να χρησιμοποιήσει ένα σύνολο δεδομένων για τις καιρικές αλλαγές ένα δεν γνωρίζει τι σημαίνει η τυπική απόκλιση; Πώς μπορεί ένας ρεπόρτερ δεδομένων να γράψει μια ιστορία σχετικά με την κατανομή των εισοδημάτων εάν δεν μπορεί να διακρίνει την διαφορά του μέσου όρου από την ενδιάμεση τιμή; 

Ένας ρεπόρτερ σίγουρα δεν χρειάζεται ένα πτυχίο στην στατιστική ώστε να γίνει πιο αποτελεσματικός στην ενασχόλησή του με τα δεδομένα. Όταν αντιμετωπίζει αριθμούς, κάποια μικρά απλά τεχνάσματα μπορούν να τον βοηθήσουν να διηγηθεί καλύτερες ιστορίες. Όπως αναφέρει και ο Gerd Gigerenzer, καθηγητής στο Max Planck Institute, τα καλύτερα εργαλεία δεν οδηγούν σε καλύτερη δημοσιογραφία εάν δεν χρησιμοποιούνται με οξυδέρκεια.

Ακόμα μια αν έχετε έλλειψη γνώσεων στα μαθηματικά ή την στατιστική μπορείτε εύκολα να γίνετε ένα έμπειρος δημοσιογράφος δεδομένων ρωτώντας τρεις απλές ερωτήσεις.

==== 1.	Πως συλλέχθηκαν τα δεδομένα;

===== Εκπληκτική άνοδος του ΑΕΠ

Ο ευκολότερος τρόπος να επιδειχθεί κανείς με εντυπωσιακά δεδομένα είναι να τα κατασκευάσει. Ακούγεται προφανές, όμως τα δεδομένα που σχολιάζονται συχνά ως γραφήματα του ΑΕΠ μπορεί να είναι ψευδή.  Ένας προηγούμενος βρετανός πρέσβης, ο Craig Murray αναφέρει στο βιβλίο του, Murder in Samarkand, ότι οι ρυθμοί ανάπτυξης στο Ουζμπεκιστάν υπόκεινται σε έντονες διαπραγματεύσεις μεταξύ της τοπικής κυβέρνησης  και των διεθνών φορέων. Με άλλα λόγια , δεν σχετίζεται καθόλου με την τοπική κοινωνία.

Το ΑΕΠ χρησιμοποιείται ως ο νούμερο ένα δείκτης επειδή οι κυβερνήσεις τον χρειάζονται ώστε να ελέγχουν την κύρια πηγή εσόδων τους το ΦΠΑ. Όταν μια κυβέρνηση δεν χρηματοδοτείται από το ΦΠΑ ή όταν δεν δημοσιοποιεί τον προϋπολογισμό του, δεν έχει λόγο να συλλέγει δεδομένα που σχετίζονται με το ΑΕΠ και είναι καλύτερο για αυτήν να τα κατασκευάζει. 

===== Η εγκληματικότητα βρίσκεται πάντα σε άνοδο

«Η εγκληματικότητα στην Ισπανία αυξήθηκε κατά 3%» http://bit.ly/elpais-numeracy[γράφει το  El Pais]. Οι Βρυξέλλες θίγονται από την αυξημένη εγκληματικότητα  από παράνομους μετανάστες και ναρκομανείς http://bit.ly/rtl-numeracy[αναφέρει το RTL]. Αυτός ο τύπος  αναφοράς είναι κοινός και βασίζεται στις στατιστικές της αστυνομίας αλλά δεν μας λέει πολλά για την βία. 

Μπορούμε να εμπιστευόμαστε το γεγονός ότι μέσα στην Ευρωπαϊκή ένωση τα δεδομένα δεν αλλοιώνονται. Αλλά το προσωπικό της αστυνομίας ανταποκρίνεται σε κίνητρα. Όταν η υπόθεση σχετίζεται με ποσοστό διαλεύκανσης για παράδειγμα οι αστυνομικοί έχουν κίνητρο να αναφέρονται όσο το δυνατόν περισσότερο σε περιστατικά που δεν απαιτούν διερεύνηση. Ένα τέτοιο έγκλημα είναι το κάπνισα ναρκωτικών. Αυτό εξηγεί γιατί η εγκληματικότητα που σχετίζεται με ναρκωτικά  στην Γαλλία αυξήθηκαν στα τετραπλάσιο τα τελευταία χρόνια ενώ η κατανάλωση παρέμεινε η ίδια. 

===== Τι μπορείτε να κάνετε

Όταν η αξιοπιστία ενός αριθμού είναι αμφίβολη, πάντα πρέπει να ελέγχετε διπλά, όπως  στην περίπτωση ενός αποσπάσματος από πολιτικό. Στην περίπτωση του Ουζμπεκιστάν, ένα τηλεφώνημα σε κάποιον που έχει ζήσει εκεί κάποιον καιρό αρκεί («Αισθάνεστε ότι η χώρα είναι κατά τρεις φορές πιο πλούσια όπως δείχνουν τα επίσημα στοιχεία;»)

Για τα δεδομένα της αστυνομίας, οι κοινωνιολόγοι συχνά   πραγματοποιούν μελέτες θυματοποίησης ρωτώντας τους ανθρώπους εάν υπόκεινται στο έγκλημα. Αυτές οι μελέτες είναι περισσότερο σταθερές από ότι τα δεδομένα της αστυνομίας. Ίσως γι αυτό δεν αποτελούν  πρωτοσέλιδα. 

Άλλα τεστ σας επιτρέπουν να αξιολογείτε με ακρίβεια την αξιοπιστία των δεδομένων, όπως ο νόμος του Benford, αλλά τίποτα δεν μπορεί να αντικαταστήσει την δική σας κριτική σκέψη. 

==== 2. Τι υπάρχει εκεί για να μάθουμε;

===== Ο κίνδυνος  πολλαπλής σκλήρυνσης διπλασιάζεται όταν δουλεύουμε το βράδυ

Σίγουρα κάθε γερμανός που έχει τα λογικά του θα σταματήσει να εργάζεται βραδινές βάρδιες ύστερα από http://bit.ly/dmsg-numeracy[αυτό το πρωτοσέλιδο.] Αλλά το άρθρο δεν αναφέρει ποιος είναι ο κίνδυνος πραγματικά.  

Πάρτε 1.000 γερμανούς. Ένας από αυτούς θα αποκτήσει πολλαπλή σκλήρυνση κατά την διάρκεια της ζωής του. Τώρα εάν κάθε ένας από αυτούς τους 1.000 γερμανούς δουλεύει σε βραδινή βάρδια ο αριθμός αυτών που  υπάρχουν από πολλαπλή σκλήρυνση ανεβαίνει στο δυο. Ο επιπρόσθετος κίνδυνος να αποκτήσει κάποιος πολλαπλή σκλήρυνση σε βραδινές βάρδιες είναι 1 προς 1.000, όχι 100%. Σίγουρα αυτή η πληροφορία είναι πιο χρήσιμη για κάποιον που σκέφτεται να πάρει την δουλειά.

===== Κατά μέσο όρο, 1 στους 15 ευρωπαίους είναι τελείως αναλφάβητος

Το παραπάνω πρωτοσέλιδο φαίνεται τρομαχτικό. Επίσης είναι απολύτως αληθές. Ανάμεσα στα 500 εκατομμύρια ευρωπαίους, τα 36 εκατομμύρια πιθανόν δεν ξέρουν να διαβάζουν.  Επιπλέον, 36 εκατομμύρια είναι κάτω των 7 ετών (δεδομένα από Eurostat,http://bit.ly/eurostat-numeracy).

Όταν γράφουμε για τον μέσο όρο, πρέπει να αναρωτιόμαστε «ο μέσος όρος από τι;» Είναι ο πληθυσμός αναφοράς ομογενής; Άνισα πρότυπα κατανομών εξηγούν γιατί οι περισσότεροι άνθρωποι τα καταφέρνουν καλύτερα από τον μέσο όρο για παράδειγμα. Στους περισσότερους ανθρώπους έχει συμβεί  μηδέν ή ένα ατύχημα κατά την διάρκεια της ζωής τους. Λίγοι απρόσεκτοι οδηγοί έχουν πολλά περισσότερα, ωθώντας το μέσο όρο των ατυχημάτων πολύ υψηλότερα από αυτό που έχουν οι περισσότεροι άνθρωποι. Το ίδιο συμβαίνει και με την κατανομή των εισοδημάτων: οι περισσότεροι άνθρωποι κερδίζουν λιγότερο από τον μέσο όρο.  

===== Τι μπορείς να κάνεις

Πάντα να λαμβάνετε υπόψην την κατανομή και το βασικό ποσοστό. Ο έλεγχος του μέσου όρου και της μεσαίας τιμής καθώς και της επικρατούσαν τιμής (η πιο συχνή τιμή στην κατανομή) μας βοηθά να αποκτούμε γνώση των δεδομένων. Γνωρίζοντας την τάξη μεγέθους  βοηθά στην παροχή πλαισίου όπως στο παράδειγμα με την πολλαπλή σκλήρυνση. Τέλος η αναφορά σε συχνότητες (1 στα 100) είναι ευκολότερο στην κατανόηση από τα ποσοστά (1%).  

==== 3. Πόσο αξιόπιστη είναι η πληροφορία

===== Το πρόβλημα του μεγέθους του δείγματος

«Το 80% δεν είναι ευχαριστημένοι με το σύστημα δικαιοσύνης» http://bit.ly/diariodenavarra[αναφέρει μια έρευνα στη Σαραγόσα στο Diaro de Navarra]. Πως μπορεί κανείς να βγάλει συμπεράσματα από 800 ερωτηθέντες για τα 46 εκατομμύρια των Ισπανών; Κάτι τέτοιο δεν μπορεί να είναι έγκυρο.

Όταν ερευνάτε έναν μεγάλο πληθυσμό (πάνω από μερικες χιλιάδες), συνήθως δεν χρειάζεστε πάνω από χίλιους ερωτηθέντες ώστε να έχετε ποσοστό σφάλματος μικρότερο από 3%. Αυτό σημαίνει ότι εάν ξανακάνατε την έρευνα με τελείως διαφορετικό δείγμα, 19 φορές από τις 20 οι απαντήσεις που θα παίρνατε θα ήταν σε διάστημα μεταξύ τριών ποσοστιαίων μονάδων  από την τιμή που θα είχατε λάβει ένα ρωτούσατε κάθε άτομο.

===== Το τσάι μειώνει την πιθανότητα εγκεφαλικού

Άρθρα για τις ευεργετικές ιδιότητες του τσαγιού είναι συνήθη. H http://bit.ly/welt-tea[αναφορά της Die Welt] ότι το τσάι μειώνει τον κίνδυνο  εμφράγματος μου μυοκαρδίου δεν αποτελεί εξαίρεση. Παρόλου που οι επιπτώσεις του τσαγιού μελετούνται από επιστήμονες, πολλές έρευνες δεν λαμβάνουν υπόψη  τον τρόπο ζωής, όπως η δίαιτα, το επάγγελμα ή η ενασχόληση με τον αθλητισμό. 

Στις περισσότερες χώρες, το τσάι αποτελεί αναψυκτικό για την υψηλή τάξη που είναι ενημερωμένη σχετικά με θέματα υγείας. Σε περίπτωση που οι ερευνητές δεν ελέγχουν τον τρόπο ζωής των υποκειμένων στις μελέτες για το τσάι, το μόνο που μπορούν να εξάγουν είναι ότι οι «πλούσιοι είναι πιο υγιείς και πιθανόν πίνουν τσάι». 

===== Τι μπορείτε να κάνετε

Τα μαθηματικά πίσω από τις συσχετίσεις και τα περιθώρια λαθών είναι σωστά χωρίς αμφιβολία τις περισσότερες φορές. Όμως εάν οι ερευνητές δεν εξετάζουν τις συν-συσχετίσεις (αυτοί που πίνουν τσάι ασχολούνται με τον αθλητισμό), τα αποτελέσματα τους δεν έχουν αξία. 

Όντως δημοσιογράφος, δεν έχει νόημα να αμφισβητείτε τα αριθμητικά αποτελέσματα της μελέτης, όπως το δείγμα του πληθυσμού, εκτός εάν υπάρχουν σοβαρές αμφιβολίες. Παρόλα αυτά, είναι εύκολο να διαπιστώσει κάποιος εάν οι δημοσιογράφοι έχουν λάβει υπόψη τους όλες τις σχετικές πληροφορίες. 

&mdash; _Nicolas Kayser-Bril, Journalism++_

=== Συμβουλές για την επεξεργασία αριθμών στα νέα

* Η πιο σημαντική συμβουλή στην επεξεργασία δεδομένων είναι να το διασκεδάζετε. Τα δεδομένα μπορεί να φαίνονται απαγορευτικά. Αλλά αν τους επιτρέψετε να σας φοβίσουν δεν θα σας οδηγήσουν πουθενά. Αντιμετωπίστε τα σαν παιχνίδι, ανακαλύψτε τα και θα σας αποδώσουν μυστικά και ιστορίες με απίστευτη ευκολία. Να τα αντιμετωπίζετε όπως θα αντιμετωπίζατε κάθε άλλου είδους στοιχεία χωρίς φόβο ή εύνοια. Συγκεκριμένα, σκεφτείτε τα σαν μια άσκηση της φαντασίας σας. Να είστε δημιουργικοί σκεπτόμενοι κάποιες εναλλακτικές ιστορίες που μπορεί να είναι συμβατές με τα δεδομένα και να τα εξηγούν καλύτερα και ελέγξετε τες για πιο ισχυρές αποδείξεις. «Ποια άλλη ιστορία μπορεί να το εξηγήσει αυτό;», είναι μια προτροπή να σκεφτείτε πώς αυτός ο αριθμός, εμφανώς μεγάλος ή κακός, αυτή η σαφής απόδειξη από αυτό ή το άλλο, μπορεί να μην ανταποκρίνονται στην πραγματικότητα. 

* Μην συγχέετε τον σκεπτικισμό για τα δεδομένα με τον κυνισμό. Ο σκεπτικισμός είναι καλός, ο κυνισμός απλά σηκώνει τα χέρια και παραιτείται. Εάν πιστεύετε στην δημοσιογραφία δεδομένων (και προφανώς το πιστεύετε αλλιώς δεν θα διαβάζατε αυτό το βιβλίο), τότε θα πρέπει να πιστεύετε ότι τα δεδομένα έχουν κάτι πολύ καλύτερο να προσφέρουν από τα ψέματα της γελοιογραφίας ή τα δολοφονικά γεγονότα των επικεφαλίδων. Τα δεδομένα δίνουν προφανή γνώση εάν χρησιμοποιηθούν κατάλληλα.

* Εάν σας πω ότι η κατανάλωση τσαγιού έχει αυξηθεί κατά την διάρκεια της ύφεσης, θα μου πείτε ότι αυτό συμβαίνει γιατί όλοι έχουν κατάθλιψη. Ένα σας πω ότι η κατανάλωση τσαγιού μειώθηκε θα μου πείτε ότι αυτό συνέβη γιατί κανείς δεν έχει αρκετά χρήματα. Με άλλα λόγια η ερμηνεία σας για τα δεδομένα είναι ανεξάρτητη από αυτό που πραγματικά σημαίνουν τα δεδομένα, δηλαδή τα πράγματα είναι πολύ άσχημα με τον έναν τρόπο ή τον άλλο.  Εάν ένας παράγοντας αυξάνεται αυτό είναι κακό, εάν μειώνεται είναι κακό επίσης. Είναι σημαντικό, εάν πιστεύετε στα δεδομένα, να τα αφήστε να μιλήσουν πριν τα επηρεάσετε από την δική σας διάθεση, πεποιθήσεις ή προσδοκίες.  Υπάρχουν τόσα πολλά δεδομένα εάν ψάξετε τριγύρω ώστε να μπορείτε να επιβεβαιώσετε τις αντιλήψεις ς σας. Με άλλα λόγια η δημοσιογραφία των δεδομένων προσθέτει λίγη αξία εάν εσείς δεν είστε ανοιχτόμυαλοι. Είναι τόσο αντικειμενική όσο παλεύετε εσείς να την κάνετε και όχι λόγω του γεγονότος ότι βασίζεται σε αριθμούς.

* Η αβεβαιότητα είναι αποδεκτή. Συσχετίζουμε αριθμούς με την αυθεντία και την βεβαιότητα. Όμως αυτό δεν ισχύει στην  πραγματικότητα, καθώς η απάντηση μπορεί να είναι ότι  δεν υπάρχει απάντηση ή η απάντηση μπορεί να είναι η καλύτερη που έχουμε παρόλα αυτά δεν είναι τελείως ακριβής. Νομίζω πως πρέπει να αναφέρουμε  αυτά τα γεγονότα. Εάν ακούγεται σαν ένας καλός τρόπος για να σκοτώνουμε τις ιστορίες, θα υποστήριζα ότι είναι ένας πολύ καλός τρόπος για να θέτουμε νέα ερωτήματα. Επίσης υπάρχουν πολλοί αποδεκτοί τρόποι μείωσης των δεδομένων. Οι αριθμοί δεν χρειάζεται να είναι σωστοί ή λάθος.

* Η έρευνα είναι μια ιστορία. Η ιστορία της προσπάθειας που καταβάλλατε μπορεί να δημιουργήσει πολύ καλή δημοσιογραφία, καθώς προχωράτε από το ένα αποδεικτικό στοιχείο στο άλλο. Η ιστορία αυτή αποτελεί πηγάζει χωρίς αμφιβολία από τα δεδομένα ενώ αυτό συμβαίνει σπάνια με τους αριθμούς. Διαφορετικές πηγές παρέχουν καινούργιες οπτικές γωνίες, καινούργιες ιδέες και μεγαλύτερη κατανόηση. Αναρωτιέμαι εάν θέλουμε να είμαστε η αυθεντία και να αποκαλύπτουμε την απάντηση, και έτσι  παραλείπουμε να δείξουμε την διαδικασία διερεύνησης. 

++++
<?dbfo-need height="1in"?>
++++

* Η καλύτερη ερώτηση από τις πιο κλασσικές αποτελεί: Είναι όντως ένας μεγάλος αριθμός; Από που προέρχεται; Είστε σίγουροι ότι μετρά αυτό που νομίζετε ότι μετρά; Αυτές αποτελούν προτροπές ώστε να σκέφτεστε γύρω από τα δεδομένα, και όλες τις λεπτομέρειες που παραμελήθηκαν με την επικέντρωση σε έναν αριθμό, τις επιπλοκές της πραγματικής ζωής, το μεγάλο εύρος άλλων πιθανών συγκρίσεων στην διάρκεια του χρόνου, με λίγα λόγια το πλαίσιο.

&mdash; _Michael Blastland, freelance journalist_

=== Τα βασικά βήματα στην επεξεργασία δεδομένων

Υπάρχουν το λιγότερο τρεις έννοιες κλειδιά που χρειάζεται να κατανοήσετε όταν αρχίσετε ένα έργο με δεδομένα:

* Οι αιτήσεις για τα δεδομένα πρέπει να ξεκινούν όταν με μια λίστα ερωτήσεων που θέλετε να απαντήσετε.
* Τα δεδομένα είναι ακατάστατα και χρειάζονται εκκαθάρηση.
* Τα δεδομένα μπορεί να έχουν χαρακτηριστικά που δεν έχουν τεκμηριωθεί.

[[FIG052]]
.Messy data
image::figs/incoming/05-MM.png[scale="89",float="none"]

==== Να γνωρίζετε τις ερωτήσεις που θέλετε να απαντήσετε

Κατά πολλούς τρόπους, η εργασία με τα δεδομένα είναι σαν συνέντευξη με μια ζωντανή πηγή. Θέτετε ερωτήσεις στα δεδομένα και αυτά σας αποκαλύπτουν τις απαντήσεις. Αλλά όπως η πηγή σας δίνει απαντήσεις για τις οποίες έχει πληροφορία, ένα σύνολο δεδομένων μπορεί να απαντήσει μόνο ερωτήσεις για τις οποίες έχει τα σωστά στοιχεία και τις κατάλληλες μεταβλητές. Αυτό σημαίνει ότι θα πρέπει να αναλογιστείτε προσεκτικά ποιες ρωτήσεις θα πρέπει να απαντήσετε ακόμα  και πριν αποκτήσετε τα δεδομένα σας. Βασικά, πρέπει να δουλεύετε προς τα πίσω. Πρώτα κάντε μια λίστα με τις δηλώσεις που θέλετε να εξάγετε από τα δεδομένα στην ιστορία σας. Έπειτα αποφασίστε ποιες μεταβλητές και στοιχεία θα πρέπει να αποκτήσετε και να αναλύσετε ώστε να μπορείτε να κάνετε τις δηλώσεις που είχατε αναφέρει.

Αναλογιστείτε ένα παράδειγμα που περιέχει τοπικές αναφορές σχετικά με την εγκληματικότητα.  Ας πούμε ότι θέλετε να δημιουργήσετε μια ιστορία κοιτώντας στα πρότυπα εγκληματικότητας στην πόλη σας και οι δηλώσεις που θέλετε να κάνετε περιλαμβάνουν τις ώρες τις ημέρας και τις ημέρες της εβδομάδας που οι διαφορετικοί τύποι εγκληματικότητας είναι πιο πιθανόν να συμβούν καθώς επίσης και ποια σημεία της πόλης είναι πιο επιρρεπής στις διάφορες κατηγορίες εγκλημάτων. 

Θα συνειδητοποιήσετε ότι τα δεδομένα που σχετίζονται με το αίτημά σας θα πρέπει να περιλαμβάνουν την ημερομηνία και την ώρα που καταγράφηκε το κάθε έγκλημα, το είδος του εγκλήματος (φόνος, κλοπή, διάρρηξη) καθώς και την διεύθυνση του τόπου εγκλήματος. Έτσι ο χρόνος, η κατηγορία του εγκλήματος και η διεύθυνση  είναι οι ελάχιστες μεταβλητές που θα χρειαστείτε.

Όμως προσέξτε ότι υπάρχει ένας αριθμός από πιθανές ενδιαφέρουσες ερωτήσεις που αυτό το σύνολο των τεσσάρων μεταβλητών δεν μπορεί να απαντήσει, όπως η εθνικότητα και το γένος ή η συνολική αξία της κλοπιμαίας περιουσίας ή ποιοι αστυνομικοί είναι πιο αποτελεσματικοί στις συλλήψεις. Επίσης υπάρχει η περίπτωση να μπορείτε να συλλέξετε στοιχεία μόνο για κάποια περιορισμένη περίοδο. Αυτές οι ερωτήσεις μπορεί να είναι έξω από την προγραμματισμένη έρευνά σας αλλά δεν πειράζει. Παρόλα αυτά δεν θα συνιστούσα να προχωρήσετε στην ανάλυση των δεδομένων σας και ξαφνικά να αποφασίσετε ότι χρειάζεται να ξέρετε το ποσοστό των εγκλημάτων σε διαφορετικές περιοχές της πόλης που καταλήγουν σε σύλληψη. 

Μια καλή συμβουλή είναι να ζητάτε όλες τις μεταβλητές και τα στοιχεία στην βάση δεδομένων, και όχι ένα υποσύνολο που θα μπορούσε να απαντήσει την ιστορία. (Στην πραγματικότητα η ανάκτηση όλων των δεδομένων μπορεί να είναι πιο οικονομική από το υποσύνολο καθώς ίσως χρειαστεί να πληρώσετε κάποιον προγραμματιστή να εξάγει το υποσύνολο). Μπορείτε πάντα να εξάγετε το υποσύνολο που ζητάτε μόνοι σας, η πρόσβαση σε όλο το σύνολο των δεδομένων σας επιτρέπει να απαντήσετε σε καινούργιες ερωτήσεις που μπορεί να δημιουργηθούν την στιγμή που γράφετε το ρεπορτάζ σας  και να γεννηθούν καινούργιες ιδέες για ακόλουθες ιστορίες. Πολλές φορές κάποιες μεταβλητές όπως η ταυτότητα των θυμάτων δεν μπορούν να κοινοποιηθούν λόγο της νομοθεσίας υπέρ της ιδιωτικότητας ή άλλων πολιτικών. Αλλά ακόμη και ένα υποσύνολο της βάσης δεδομένων είναι καλύτερο από το τίποτα εφόσον ξέρε ποιες ερωτήσεις μπορεί να απαντήσει και ποιες όχι.

==== Εκκαθαρίζοντας ακατάστατα δεδομένα

Ένα από τα μεγαλύτερα προβλήματα στην επεξεργασία βάσεων δεδομένων είναι ότι τα δεδομένα που θα χρησιμοποιήσετε για ανάλυση έχουν συλλεχθεί για γραφειοκρατικούς σκοπούς. Το πρόβλημα είναι ότι το επίπεδο ακρίβειας για αυτούς τους δυο σκοπούς είναι αρκετά διαφορετικό.

Για παράδειγμα, μια βασική λειτουργία της ποινικής βάση δεδομένων του συστήματος είναι να βεβαιωθεί ότι η κατηγορούμενη Τζόουνς οδηγείται στον δικαστή Σμιθ κατά την διάρκεια της ακρόασής της. Για αυτόν τον σκοπό, δεν έχει σημασία εάν η ημερομηνία γέννησης της Τζόουνς είναι εσφαλμένη ή εάν η διεύθυνση της έχει ορθογραφικά λάθη, ακόμα και αν το αρχικό του μεσαίου ονόματός της είναι λάθος. Γενικά, το σύστημα μπορεί να χρησιμοποιήσει την ατελή καταγραφή ώστε να ώστε να οδηγήσει την Τζόουνς ενώπιον του Σμιθ στο δικαστήριο σε μια καθορισμένα ώρα.

Όμως τέτοια λάθη μπορεί να αποπλανήσουν τις προσπάθειες ενός δημοσιογράφου για να ανακαλύψει πρότυπα στην βάση δεδομένων. Για αυτόν τον λόγο, η πρώτη μεγάλη εργασία όταν αποκτήσετε ένα νέο σύνολο δεδομένων είναι να εξετάσετε πόσο ακατάστατο είναι και έπειτα να το καθαρίσετε. Ένας καλός και γρήγορος τρόπος για να ανιχνεύσετε την ακαταστασία είναι να δημιουργήσετε πίνακες συχνοτήτων από τιμές που ανήκουν σε διάφορες κατηγορίες, και που αναμένεται να έχουν σχετικά μικρή διαφορά στις τιμές τους. (Όταν χρησιμοποιείτε το Excel για παράδειγμα μπορείτε να το κάνετε με την χρήση φίλτρου ή με πίνακες pivot  για κάθε μεταβλητή της κατηγορίας).

Χρησιμοποιείστε το «Φύλλο» σαν ένα εύκολο παράδειγμα. Μπορεί να ανακαλύψετε ότι το πεδίο του Φύλλου περιλαμβάνει ένα μείγμα μεταβλητών όπως: Αρσενικό, Θηλυκό, Α, Θ, 1, 0, ΑΡΣΕΝΙΚΟ, ΘΗΛΥΚΟ κτλ., συμπεριλαμβανομένου ανορθογραφίες όπως «Θηλυκ». Για να κάνετε μια σωστή ανάλυση του φύλλου, θα πρέπει να είστε συνεκτικοί - να αποφασίσετε ίσως στο «Α» και «Θ» και έπειτα αλλάξτε όλους τους πιθανούς συνδυασμούς ανάλογα με το πρότυπό σας. Μια κοινή βάση δεδομένων με προβλήματα αυτού του τύπου είναι η Αμερικανική εκστρατεία οικονομικών αρχείων όπου το πεδίο της απασχόλησης μπορεί να περιέχει τους όρους: «Δικηγόρος», «Σύμβουλος», «Δοκιμαστικός Δικηγόρος» με πολλές παραλλαγές και ανορθογραφίες. Το τέχνασμα είναι να προτυποποιήσετε τους τίτλους επαγγελμάτων σε έναν μικρότερο κατάλογο επιλογών.

Η εκκαθάριση των δεδομένων γίνεται ακόμη πιο προβληματικό όταν δουλεύετε με ονόματα. Είναι ο “Joseph T.Smith”, “Joseph Smith,” “J.T. Smith,” “Jos. Smith,” και “Joe Smith” το ίδιο άτομο; Μπορεί να χρειαστεί να κοιτάξετε σε άλλες μεταβλητές όπως διεύθυνση ή ημερομηνία γέννησης ή και σε άλλα αρχεία ώστε να δώσετε μια απάντηση. Όμως εργαλεία όπως το «Google Refine» μπορούν να επιταχύνουν και να καθιστούν λιγότερο κουραστική την εκκαθάριση των δεδομένων και την προτυποποίηση.

.Ακάθαρτα Δεδομένα
****
Χάρη στους ισχυρούς νόμους σχετικά με τα δημόσια αρχεία στις Ηνωμένες Πολιτείες, η πρόσβαση στα δεδομένα δεν αποτελεί πρόβλημα όπως στις άλλες χώρες. Παρόλα αυτά αντιμετωπίζουμε το πρόβλημα ότι πρέπει να δουλέψουμε με δεδομένα που έχουν συλλεχθεί για γραφειοκρατικούς σκοπούς και όχι για αναλυτικούς. Τα δεδομένα είναι συχνά ακάθαρτα με τιμές που δεν είναι προτυποποιημένες.  Πολλές φορές λαμβάνω δεδομένα που δεν συμβαδίζουν με την υποτιθέμενη διάταξη του αρχείου και το λεξικό των δεδομένων που το συνοδεύει.  Πολλές υπηρεσίες επιμένουν στο να δίνουν δεδομένα με δύσκολη μορφή όπως .pdf που πρέπει να μετατραπούν σε άλλη μορφή. Προβλήματα σαν και αυτό σας κάνουν να εκτιμάτε ένα σύνολο δεδομένων χωρίς προβλήματα.

&mdash; _Steve Doig, Walter Cronkite School of Journalism, Arizona State University_
****

==== Τα δεδομένα μπορεί να έχουν ατεκμηρίωτα χαρακτηριστικά

Η πέτρα της Ροζέτας για κάθε βάση δεδομένων είναι το επονομαζόμενο λεξικό των δεδομένων. Συνήθως, αυτό το αρχείο (μπορεί να σε μορφή κειμένου ή pdf ή ακόμα και σε υπολογιστικό φύλλο) θα σας υποδείξει πως είναι δομημένα τα φύλλα των δεδομένων (οριοθετημένο κείμενο, κείμενο σταθερού πλάτους, Excel, dBase, etc.), την σειρά των μεταβλητών, τα ονόματα κάθε μεταβλητής, και τον τύπο δεδομένων κάθε μεταβλητής (αλφαριθμητικό, ακέραιος, δεκαδικός κτλ.). Θα χρησιμοποιήσετε αυτήν την πληροφορία ώστε να σας βοηθήσει να εισάγετε κατάλληλα τα δεδομένα στο λογισμικό που χρησιμοποιείτε  (Excel, Access, SPSS, Πίνακες σύντηξης, διάφορα ήδη SQL, etc.)

Το άλλο χαρακτηριστικό – κλειδί του λεξικού των δεδομένων είναι η εξήγηση των κωδικών που χρησιμοποιούνται για συγκεκριμένες μεταβλητές. Για παράδειγμα το Γένος μπορεί να κωδικοποιηθεί ως: «1=Αρσενικό» και «1=Θηλυκό». Τα εγκλήματα μπορεί να κωδικοποιούνται με τον αριθμό του καταστατικού την νομοθεσίας για κάθε είδους έγκλημα. Τα αρχεία των νοσοκομειακών θεραπειών μπορεί να χρησιμοποιούν κωδικούς πέντε ψηφίων για την διάγνωση των συμπτωμάτων του ασθενή, για τα οποία θεραπεύεται. Χωρίς το λεξικό των δεδομένων, αυτά τα σύνολα δεδομένων μπορεί να είναι δύσκολο ή αδύνατον να αναλυθούν κατάλληλα. Όμως ακόμη και με την ύπαρξη ενός λεξικού δεδομένων, μπορεί να υπάρχουν άλλα προβλήματα. Για παράδειγμα, οι δημοσιογράφοι στο Miami Herald στην Florida πριν από μερικά χρόνια έκαναν μια ανάλυση σχετικά με τις διαφορετικές κυρώσεις που λαμβάνουν οι άνθρωποι που οδηγούν σε κατάσταση μέθης από διαφορετικούς δικαστές. Οι δημοσιογράφοι έλαβαν τα αρχεία της καταδίκης από το δικαστικό σύστημα και ανέλυσαν τους αριθμούς από τις τρεις διαφορετικές μεταβλητές  από το λεξικό των δεδομένων: τον χρόνο φυλάκισης που επιβλήθηκε, τον χρόνο της κράτησης  και το ποσό του προστίμου που δόθηκε.  Αυτοί οι αριθμοί ποικίλουν αρκετά ανάμεσα στους δικαστές, δίνοντας στους δημοσιογράφους ένδειξη για μια ιστορία ότι κάποιο δικαστές είναι ιδιαίτερα σκληροί και κάποιοι ιδιαίτερα επιεικείς.  

Αλλά για κάθε δικαστή, περίπου 1-2 % των περιπτώσεων έδειξαν καθόλου φυλάκιση, κράτηση ή πρόστιμο. Έτσι, το διάγραμμα που παρουσιάζει τα πρότυπα των καταδικών  για κάθε δικαστή περιλάμβανε ένα μικρό ποσό των περιπτώσεων ως «Καμιά τιμωρία," σαν πρώτη σκέψη.  Όταν η ιστορία και το γράφημα τυπώθηκαν, οι δικαστές αντέδρασαν έντονα , λέγοντας ότι το Herald τους κατηγορούσε για αθέτηση ενός κρατικού νόμου που απαιτεί η οδήγηση σε κατάσταση μέθης να τιμωρείται. 

‘Έτσι οι δημοσιογράφοι γύρισαν πίσω στο γραφείο του υπαλλήλου του Ελεγκτικού Συνεδρίου που είχε προσκομίσει τα στοιχεία και ρώτησαν ποια ήταν η αιτία του σφάλματος. Τους ειπώθηκε ότι οι συγκεκριμένες περιπτώσεις αφορούσαν άπορους κατηγορούμενους που συλλαμβάνονταν για πρώτη φορά. Κανονικά τους δόθηκε ένα πρόστιμο αλλά δεν είχαν χρήματα. Έτσι οι δικαστές τους καταδίκασαν σε κοινωνική εργασία όπως την συγκομιδή απορριμμάτων από τους δρόμους. Όπως αποδείχθηκε, ο νόμος για την υποχρεωτική τιμωρία επιβλήθηκε μετά την δημιουργία της δομής της βάσης δεδομένων. Έτσι οι δικαστές γνώριζαν ότι το μηδέν στις μεταβλητές της ποινής σημαίνει κοινωνική εργασία. Παρόλα αυτά αυτό δεν ήταν καταγεγραμμένο στο λεξικό των δεδομένων και έγινε διόρθωση εκ των υστέρων. 

Το δίδαγμα είναι σε αυτήν την περίπτωση να ρωτάτε την υπηρεσία που σας δίνει τα δεδομένα εάν υπάρχουν ατεκμηρίωτα στοιχεία στα δεδομένα ή εάν υπάρχουν καινούργιοι κωδικοί που δεν έχουν συμπεριληφθεί στο λεξικό των δεδομένων, αλλαγές στην διάταξη των αρχείων ή οτιδήποτε άλλο. Επίσης να εξετάζετε πάντα τα αποτελέσματα της  έρευνάς σας και κάντε την εξής ερώτηση «Τα συμπεράσματα είναι λογικά;» Οι Herald δημοσιογράφοι είχαν προθεσμία να δημιουργήσουν το διάγραμμα και ήτα τόσο απασχολημένοι με το μέσο όρο των επιπέδων της ποινής του κάθε δικαστή που δεν έδωσαν σημασία σε κάποιες περιπτώσεις που φαινομενικά δεν είχαν καμία ποινή. Θα έπρεπε να αναρωτηθούν εάν είναι λογικό όλοι οι δικαστές να παραβιάζουν τον νόμο, ακόμα και αν πρόκειται κατά ένα πολύ μικρό ποσοστό.

&mdash; _Steve Doig,  Walter Cronkite School of Journalism, Arizona State University_

++++
<?dbfo-need height="2in"?>
++++

.Ακατάστατα, Κρυμμένα και απόντα δεδομένα
****
Θυμάμαι μια αστεία ιστορία όπου προσπαθήσαμε να αποκτήσουμε πρόσβαση στα Ουγγρικά  δεδομένα από τις γεωργικές επιδοτήσεις: ήταν όλα εκεί αλλά υπήρχε ένα υπερβολικά βαρύ PDFαρχείο και το οποίο περιείχε επίσης δεδομένα και από κρατικές επιδοτήσεις. Οι προγραμματιστές μας έπρεπε να δουλέψουν πολλές ώρες προτού τα δεδομένα να είναι χρήσιμα. 

Επίσης ενδιαφέρουσα ήταν η περίπτωση των δεδομένων για τις ευρωπαϊκές αλιευτικές επιδοτήσεις, τις οποίες τις οποίες τα 27 κράτη μέλη υποχρεούνται να αποκαλύψουν. Παρατίθεται  http://bit.ly/alfter-eu27[ένα απόσπασμα από μία έκθεση που γράψαμε σχετικά με το θέμα]: «Στο Ηνωμένο Βασίλειο, για παράδειγμα, η μορφή των δεδομένων ποικίλλει από τις  πολύ φιλικές προς το χρήστη HTML σελίδες αναζήτησης, σε μορφή PDF  ή ακόμα και λίστες παραληπτών σε ποικίλες μορφές κρυμμένες στο κάτω μέρος του δελτίου τύπου. Όλα αυτά ισχύουν για ένα μόνο κράτος μέλος. Στη Γερμανία και τη Βουλγαρία, εν τω μεταξύ, δημοσιεύονται άδειες λίστες. Οι κατάλληλες επικεφαλίδες  υπάρχουν, αλλά χωρίς δεδομένα. »

&mdash; _Brigitte Alfter, Journalismfund.eu_
****


=== Το καρβέλι ψωμί των £ 32 

Μια ιστορία για την Ουαλία στο On Sunday σχετικά με το πόσο η ουαλική κυβέρνηση δαπανά για τις συνταγές για προϊόντα χωρίς γλουτένη, περιείχε την http://bit.ly/walesonline-gluten-free[επικεφαλίδα] ότι κατέβαλλε £ 32 για ένα καρβέλι ψωμί. Ωστόσο, ο αριθμός αυτός αφορούσε στην πραγματικότητα 11 καρβέλια με κόστος £ 2,82 το καθένα. 

Τα στοιχεία, από μια Welsh Assembly γραπτή απάντηση και από τα ουαλικά NHS στατιστικά στοιχεία, ανέφεραν τον αριθμό και το κόστος ανά συνταγή. Ωστόσο, δεν έδωσαν κανένα πρόσθετο ορισμό στο λεξικό των δεδομένων σχετικά με την συνταγή ή πώς μια ξεχωριστή ποσοτική στήλη μπορεί να το ορίσει. 

Η υπόθεση που έγινε αναφερόταν σε ένα μεμονωμένο στοιχείο, π.χ., ένα καρβέλι ψωμί-και όχι σε αυτό που ίσχυε στην πραγματικότητα δηλαδή ένα πακέτο με πολλές φραντζόλες.

Ούτε αυτοί που σύνταξαν την γραπτή απάντηση, ούτε το γραφείο Τύπου όταν τέθηκε σε αυτούς, έθιξαν το θέμα της ποσότητας μέχρι τη Δευτέρα που η ιστορία δημοσιεύτηκε.

Επομένως, μην υποθέτετε ότι οι σημειώσεις  για τα δεδομένα της κυβέρνησης θα σας βοηθήσουν να εξηγήσετε τις πληροφορίες που παρουσιάζονται ή ότι οι υπεύθυνοι των δεδομένων θασυνειδητοποιούν ότι τα δεδομένα είναι εσφαλμένα ακόμα και όταν τους αναφέρετε την  λανθασμένη υπόθεση σας.

Γενικά οι εφημερίδες αναζητούν θέματα  που κάνουν καλό πρωτοσέλιδο, οπότε αν κάτι δεν έρχεται σε προφανή αντίθεση με κάποια ερμηνεία, είναι συνήθως πιο εύκολο να προτιμήσουν δημιουργήσουν καλό πρωτοσέλιδο, και να μην ελέγξουν τις λεπτομέρειες  διακινδυνεύοντας  την κατάρρευση της ιστορίας, ιδιαίτερα εάν πιέζονται από κάποια προθεσμία.

[[FIG053]]
.Prescriptions for gluten-free bread costing Welsh taxpayers £32 (WalesOnline)
image::figs/incoming/05-AA.png[float="none"]

Αλλά οι δημοσιογράφοι έχουν την ευθύνη να ελέγχουν γελοίους ισχυρισμούς, ακόμη και αν αυτό σημαίνει ότι η ιστορία μένει κάτω στη λίστα ειδήσεων.

&mdash; _Claire Miller, WalesOnline_

=== Ξεκινήστε με τα δεδομένα, τελειώστε με μια ιστορία

Για να κεντρίσετε το ενδιαφέρον στους αναγνώστες σας, θα πρέπει να είστε σε θέση να δημιουργήσετε έναν αριθμό για πρωτοσέλιδο που θα τους κάνει να τον προσέξουν. Θα πρέπει να μπορείτε να διαβάζετε την ιστορία χωρίς να χρειάζεται να γνωρίζετε ότι προέρχεται από ένα σύνολο δεδομένων. Κάντε την συναρπαστική και να θυμάστε πάντα ποιο είναι το κοινό σας ενώ συνεχίζετε.

Για παράδειγμα βρίσκεται σε ένα έργο που πραγματοποιείται από το Γραφείο Ερευνητικής Δημοσιογραφίας, χρησιμοποιώντας το http://bit.ly/ec-fts[σύστημα δημοσιονομικής διαφάνειας] της Επιτροπής της ΕΕ. Η ιστορία κατασκευάστηκε με την προσέγγιση του συνόλου δεδομένων με συγκεκριμένα ερωτήματα. 

Αναζητήσαμε  στα στοιχεία για όρους κλειδιά όπως «κοκτέιλ», «γκολφ» και «μακρινές ημέρες."

Η αναζήτηση αυτή μας επέτρεψε να καθορίσουμε το ποσό που η Επιτροπή (Commission) είχε δαπανήσει σε αυτά τα στοιχεία και έθεσε πολλές ερωτήσεις και πιθανά σενάρια. 

Αλλά οι όροι κλειδιά δεν σας δίνουν πάντα ό, τι θέλετε, μερικές φορές θα πρέπει να σκεφτείτε τι πραγματικά ζητάτε. Κατά τη διάρκεια αυτού του έργου, θέλαμε επίσης να μάθουμε το ποσό που οι επίτροποι σπαταλούν για ένα ταξίδι με ιδιωτικό τζετ, αλλά καθώς το σύνολο δεδομένων δεν περιείχε τη φράση "ιδιωτικό τζετ" θα έπρεπε να αναζητήσουμε το όνομα των ταξιδιωτικών παρόχων με άλλα μέσα. Μόλις ανακτήσαμε το όνομα των ταξιδιωτικών  παρόχων της Επιτροπής, «Abelag," ήμασταν σε θέση να διερευνήσουμε τα δεδομένα ,ώστε να μάθουμε το  ποσό που δαπανάται για τις υπηρεσίες που παρέχονται από την Abelag.

Με την προσέγγιση αυτή, είχαμε έναν καθορισμένο στόχο στην αναζήτηση των δεδομένων  -  να βρούμε έναν αριθμό που θα γίνει πρωτοσέλιδο,  ακολούθησε η επιλογή του χρώματος.

Μια άλλη προσέγγιση είναι να ξεκινήσετε με μια μαύρη λίστα και να αναζητήσετε εξαιρέσεις. Ένας εύκολος τρόπος για να εξάγετε ιστορίες από τα δεδομένα είναι να γνωρίζετε τι δεν πρέπει να βρείτε εκεί! Ένα καλό παράδειγμα για την λειτουργία αυτής της προσέγγισης, απεικονίζεται από το συνεργατικό έργο των διαρθρωτικών ταμείων της ΕΕ μεταξύ των Financial Times και το Γραφείο Ερευνητικής Δημοσιογραφίας.

Θέσαμε ερωτήματα στα δεδομένα, με βάση τους κανόνες της Επιτροπής, σχετικά με το είδος των εταιριών και συλλόγων που απαγορεύεται να λαμβάνουν  διαρθρωτικούς πόρους. Ένα παράδειγμα ήταν οι δαπάνες στον τομέα του καπνού και προϊόντων καπνού.

Θέτοντας ερωτήματα στα δεδομένα σχετικά με τα ονόματα των εταιρειών καπνού, τους παραγωγούς και τους καλλιεργητές, βρήκαμε στοιχεία που αποκάλυπταν ότι η British American Tobacco λάμβανε € 1,5 εκατ. για ένα εργοστάσιο στη Γερμανία.

Δεδομένου ότι η χρηματοδότηση ήταν έξω από τους κανόνες των δαπανών της Επιτροπής, ανακαλύψαμε γρήγορα μια ιστορία για τα δεδομένα.

Ποτέ δεν ξέρετε τι μπορείτε να βρείτε σε ένα σύνολο δεδομένων, οπότε ρίξτε μια ματιά. Θα πρέπει να είστε αρκετά τολμηροί και αυτή η προσέγγιση λειτουργεί γενικά καλύτερα όταν προσπαθείτε να εντοπίσετε προφανή χαρακτηριστικά που θα εμφανιστούν μέσα από φιλτράρισμα (η μεγαλύτερη τιμή, ακραίες τιμές, οι πιο κοινές τιμές, κ.λπ.).

&mdash; _Caelainn Barr, Citywire_

=== Ιστορίες δεδομένων

Η δημοσιογραφία των δεδομένων μπορεί να δώσει μερικές φορές την εντύπωση ότι αφορά κυρίως την παρουσίαση των δεδομένων, όπως απεικόνιση των δεδομένων που γρήγορα και δυναμικά μεταφέρει την κατανόηση μιας πτυχής των στοιχείων, ή τις διαδραστικές βάσεις δεδομένων που επιτρέπουν στους χρήστες να αναζητούν τον τοπικό τους δρόμο ή νοσοκομείο. Όλα αυτά μπορεί να είναι πολύτιμα, αλλά όπως και στις άλλες μορφές δημοσιογραφίας, η δημοσιογραφία των δεδομένων πρέπει να αφορά ιστορίες. Λοιπόν ποια είναι  τα είδη των ιστοριών που μπορείτε να βρείτε στα δεδομένα; Με βάση την εμπειρία μου στο BBC, έχω συντάξει έναν κατάλογο, ή «τυπολογία» των διαφόρων ειδών ιστοριών που αφορούν δεδομένα.

Νομίζω ότι βοηθάει να έχετε κατά νου την παρακάτω λίστα, όχι μόνο όταν αναλύετε τα δεδομένα, αλλά και στο προηγούμενο στάδιο, όταν συλλέγετε τα δεδομένα (είτε ψάχνετε για δημόσια διαθέσιμα σύνολα δεδομένων ή συμπληρώνετε αιτήματα πληροφοριών προς την δημόσια διοίκηση. 

Μέτρηση::
Η πιο απλή ιστορία, καταμέτρηση ή περίληψη: «Τα τοπικά συμβούλια σε όλη την χώρα δαπάνησαν συνολικά £ x δισ. ευρώ για συνδετήρες τον προηγούμενο χρόνο . "Αλλά είναι δύσκολο να γνωρίζετε αν αυτό είναι πολύ ή λίγο. Γι 'αυτό, θα πρέπει να έχετε πλαίσιο, το οποίο περιλαμβάνει:

Την αναλογία;;
"Πέρυσι τα τοπικά συμβούλια δαπάνησαν τα δύο τρίτα του προϋπολογισμού της γραφικής ύλης σε συνδετήρες."

Εσωτερική σύγκριση;;
"Τα τοπικά συμβούλια δαπάνησαν  περισσότερους πόρους για συνδετήρες από ό, τι για την παροχή γευμάτων σε ηλικιωμένους που βρίσκονται σε αναπηρικό καρότσι."

Εξωτερικές σύγκριση;;
"Οι δαπάνες του Συμβουλίου για συνδετήρες πέρυσι ήταν διπλάσια του προϋπολογισμού  εξωτερικής βοήθειας του κράτους."

Υπάρχουν επίσης και άλλοι τρόποι για να εξερευνήσετε τα δεδομένα με βάση τα συμφραζόμενα ή με έναν συγκριτικό τρόπο:

Αλλαγή με την πάροδο του χρόνου::
  "Συμβούλιο των δαπανών για συνδετήρες έχει τριπλασιαστεί τα τελευταία τέσσερα χρόνια."

"Πίνακες League"::
Τα δεδομένα αυτά είναι συχνά γεωγραφικά ή από κάποιο θεσμικό όργανο, και θα πρέπει να βεβαιωθείτε ότι η βάση σύγκρισης είναι δίκαιη (π.χ., λαμβάνοντας υπόψη το μέγεθος του τοπικού πληθυσμού). "Το συμβούλιο Borsetshire δαπανά περισσότερα για συνδετήρες για κάθε μέλος του προσωπικού από οποιαδήποτε άλλη τοπική αρχή, με ρυθμό τέσσερις φορές τον εθνικό μέσο όρο. "

Ή μπορείτε να χωρίσετε τα υποκείμενα των δεδομένων σε ομάδες:

Ανάλυση ανά κατηγορίες::
"Τα συμβούλια που διοικούνται από το Purple Κόμμα δαπανούν 50% περισσότερα για συνδετήρες από εκείνα που ελέγχονται από το κίτρινο μέρος."

Ή μπορείτε να συσχετίσετε παράγοντες αριθμητικά:

Συσχέτιση::
"Τα συμβούλια διοικούνται από πολιτικούς, οι οποίοι έχουν λάβει δωρεές από εταιρίες χαρτικών δαπανούν περισσότερα για συνδετήρες, με αύξηση των δαπανών £ 100 κατά μέσο όρο για κάθε λίρα δωρεάς."

Αλλά, φυσικά, να θυμάστε πάντα ότι η συσχέτιση και της αιτιώδης σχέση δεν είναι το ίδιο πράγμα.

++++
<?dbfo-need height="1in"?>
++++

Έτσι, εαν ερευνάτε τις δαπάνες των συνδετήρων, αναλύετε τα ακόλουθα στοιχεία;
* Τις συνολικές δαπάνες για την παροχή πλαισίου;
* Γεωγραφικές / ιστορικές / λοιπές αναλύσεις ώστε να παρέχετε συγκριτικά στοιχεία;
* Τα επιπλέον στοιχεία που διασφαλίζουν ότι η σύγριση είναι σημαντική, όπως είναι το μέγεθος του πληθυσμού;
* Άλλα στοιχεία που θα μπορούσαν να παρέχουν ενδιαφέρουσα ανάλυση για την σύγκριγη ή την συσχέτιση της δαπάνης?

&mdash; _Martin Rosenbaum, BBC_

=== Data Journalists Discuss Their Tools of Choice ===

Psssss. That is the sound of your data decompressing from its airtight wrapper. Now what? What do you look for? And what tools do you use to get stuck in? We asked data journalists to tell us a bit about how they work with data. Here is what they said:

[quote, Lisa Evans, the Guardian]
____
At the Guardian Datablog, we really like to interact with our readers and allowing them to replicate our data journalism quickly means they can build on the work we do and sometimes spot things we haven't. So the more intuitive the data tools, the better. We try to pick tools that anyone could get the hang of without learning a programming language or having special training and without a hefty fee attached.

We're currently using Google products quite heavily for this reason. All the datasets we tidy and release are available as a Google Spreadsheet, which means people with a Google account can download the data, import it into their own account and make their own charts, sort the data and create pivot tables, or they can import the data into a tool of their choice.

To map data, we use Google Fusion tables. When we create heat maps in Fusion, we share our KML shape files so that readers can download and build their own heat maps--maybe adding extra layers of data onto the Datablog's original map. The other nice feature of these Google tools is that they work on the many platforms our readers use to access the blog, such as their desktop, their mobile, and tablets.

In addition to Google Spreadsheets and Fusion, we use two other tools in our daily work. The first is Tableau, to visualize multi-dimensional datasets; and the second is ManyEyes, for quick analysis of data. None of these tools are perfect, so we continue to look for better visualization tools that our readers will enjoy.
____


[quote, Cynthia O'Murchu, Financial Times]
____
Am I ever going to be a coder? Very unlikely! I certainly don't think that all reporters need to know how to code. But I do think it is very valuable for them to have a more general awareness of what is possible and know how to talk to coders.

If you're starting out, walk, don't run. You need to persuade your colleagues and editors that working with data can get you stories that you wouldn't otherwise get and that it's well worth doing. Once they see the value of this approach, you can expand into doing more complex stories and projects.

My advice is to learn Excel and do some simple stories first. Start out small and work your way up to database analysis and mapping. You can do so much in Excel--it's an extremely powerful tool and most people don't even use a fraction of its functionality. If you can, go on a course on Excel for journalists, such as the one offered by the Centre for Investigative Journalism.

With respect to interpreting data: don't take this lightly. You have to be conscientious. Pay attention to detail and question your results. Keep notes on how you're processing the data and keep a copy of the original data. It is easy to make a mistake. I always do my analysis two or three times practically from scratch. Even better would be to get your editor or someone else to analyze the data separately and compare the results.
____

[quote, Scott Klein, ProPublica]
____
The ability to write and deploy complex software as quickly as a reporter can write a story is a pretty new thing. It used to take a lot longer. Things changed thanks to the development of two free/open source rapid development frameworks: Django and Ruby on Rails, both of which were first released in the mid-2000s.

Django, which is built on top of the Python programming language, was developed by Adrian Holovaty and a team working in a newsroom--the Lawrence Journal-World in Lawrence, Kansas. Ruby on Rails was developed in Chicago by by David Heinemeier Hansson and 37Signals, a web application company.

Though the two frameworks take different approaches to the ``MVC pattern,'' they're both excellent and make it possible to build even very complex web applications very quickly. They take away some of the rudimentary work of building an app. Things like creating and fetching items from the database, and matching URLs to specific code in an app are built into the frameworks, so developers don't need to write code to do basic things like that.

While there hasn't been a formal survey of news app teams in the U.S., it is generally understood that most teams use one of these two frameworks for database-backed news apps. At ProPublica, we use Ruby on Rails.

The development of rapid web server ``slice'' provisioning services like Amazon Web Services also took away some of what used to make deploying a web app a slow process.

Apart from that, we use pretty standard tools to work with data: Google Refine and Microsoft Excel to clean data; SPSS and R to do statistics; ArcGIS and QGIS to do GIS; Git for source code management; TextMate, Vim and Sublime Text for writing code; and a mix of MySQL, PostgreSQL and SQL Server for databases. We built our own JavaScript framework called ``Glass'' that helps us build front-end heavy apps in JavaScript very quickly.
____

[quote, Cheryl Phillips, The Seattle Times]
____
Sometimes the best tool can be the simplest tool--the power of a spreadsheet is easy to underestimate. But using a spreadsheet back when everything was in DOS enabled me to understand a complex formula for the partnership agreement for the owners of The Texas Rangers--back when George W. Bush was one of the key owners. A spreadsheet can help me flag outliers or mistakes in calculations. I can write clean-up scripts and more. It is a basic in the toolbox for a data journalist.

That said, my favorite tools have even more power--SPSS for statistical analysis and mapping programs that enable me to see patterns geographically.
____


[quote, Gregor Aisch, Open Knowledge Foundation]
____
I'm a big fan of Python. Python is a wonderful open source programming language that is easy to read and write (e.g., you don't have to type a semi-colon after each line). More importantly, Python has a tremendous user base and therefore has plugins (called packages) for literally everything you need.

I would consider Django as something rarely needed by data journalists. It is a Python web application framework--that is, a tool to create big, database-driven web applications. It is definitely too heavyweight for small interactive infographics.

I also use QGis, which is an open source toolkit providing a wide range of GIS functionality needed by data journalists who deal with geodata every now and then. If you need to convert geospatial data from one format into another, then QGis is what you need. It can handle nearly every geodata format out there (Shapefiles, KML, GeoJSON, etc.). If you need to cut out a few regions, QGis can do this as well. Plus there is a huge community around QGis, so you find tons of resources like http://bit.ly/goettingen-tutorial[tutorials] out in the web.

R was created mainly as a scientific visualization tool. It is hard to find any visualization method or data wrangling technique that is not already built into R. R is a universe in its own, the mecca of visual data analysis. One drawback is that you need to learn (yet another) programming language, as R has its own language. But once you have taken the initial climb on the learning curve, there's no tool more powerful than R. Trained data journalists can use R to analyze huge datasets that extend the limits of Excel (for instance, if you have a table with a million rows).

What's really nice about R is that you're able to keep an exact "protocol" of what you're doing with the data throughout the entire process--from reading a CSV file to generating charts. If the data changes, you can regenerate the chart using one click. If someone is curious about the integrity of your chart, you can show the exact source, which allows everyone to recreate the exact chart on their own (or maybe find the mistakes you made).

NumPy + MatPlotLib is kind of a way of doing the same thing in Python. It's an option if you're already well trained in Python. In fact, NumPy and MatPlotLib are two examples of Python packages. They can be used for data analysis and data visualization, and are both limited to static visualizations. They cannot be used to create interactive charts with tooltips and more advanced stuff.

I'm not using MapBox, but I've heard it is a great tool if you want to provide more sophisticated maps based on OpenStreetMap. It allows you, for instance, to customize the map styles (colors, labels, etc). There's also a companion of MapBox, called Leaflet. Leaflet is basically a higher level JavaScript library for mapping that allows you to easily switch between map providers (OSM, MapBox, Google Maps, Bing, etc.).

RaphaelJS is a rather low-level visualization library that allows you to work with basic primitives (like circles, lines, text), and to animate them, add interactions, etc. There's nothing like a ready-to-use bar chart in it, so you have to draw a set of rectangles yourself.

However, the good thing about Raphael is that everything you create will also work in Internet Explorer. That's not the case with many other (amazing) visualization libraries like d3. Sadly, so many users are still using IE and no newsroom can afford to ignore 30% of their users.

Besides RaphaelJS, there's also the option of creating a Flash fallback for IE. That is basically what The New York Times is doing. This means that you have to develop each application twice.

I'm still not convinced about the ``best'' process of shipping visualization for IE and modern browsers. Often I find that RaphaelJS applications can run horribly slow on IE, around ten times slower than they run in Flash using modern browsers. So Flash fallbacks might be a better option if you want to provide high-quality animated visualizations for all users.
____

[quote, Steve Doig, Walter Cronkite School of Journalism, Arizona State University]
____
My go-to tool is Excel, which can handle the majority of CAR problems and has the advantages of being easy to learn and available to most reporters. When I need to merge tables, I typically use Access, but then export the merged table back into Excel for further work. I use ESRI’s ArcMap for geographic analyses; it’s powerful and is used by the agencies that gather geocoded data. TextWrangler is great for examining text data with quirky layouts and delimiters, and can do sophisticated search-and-replace with regular expressions. When statistical techniques like linear regression are needed, I use SPSS; it has a friendly point-and-click menu. For really heavy lifting, like working with datasets that have millions of records that may need serious filtering and programmed variable transformations, I use SAS software.
____

[quote, Brian Boyer, Chicago Tribune]
____
Our tools of choice include Python and Django for hacking, scraping, and playing with data; and PostGIS, QGIS, and the MapBox toolkit for building crazy web maps. R and NumPy + MatPlotLib are currently battling for supremacy as our kit of choice for exploratory data analysis, though our favorite data tool of late is homegrown: CSVKit. More or less everything we do is deployed in the cloud.
____

[quote, Angélica Peralta Ramos, La Nacion (Argentina)]
____
At La Nacion we use:

* Excel for cleaning, organizing and analyzing data;
* Google Spreadsheets for publishing and connecting with services such as Google Fusion Tables and the Junar Open Data Platform;
* Junar for sharing our data and embedding it in our articles and blog posts;
* Tableau Public for our interactive data visualizations;
* Qlikview, a very fast business intelligence tool to analyze and filter large datasets;
* NitroPDF for converting PDFs to text and Excel files; and
* Google Fusion Tables for map visualizations.
____

[quote, Pedro Markun, Transparência Hacker]
____
As a grassroots community without any technical bias, we at Transparency Hackers use a lot of different tools and programming languages. Every member has it's own set of preferences and this great variety is both our strength and our weakness. Some of us are actually building a "Transparency Hacker Linux Distribution," which we could live-boot anywhere and start hacking data. This toolkit has some interesting tools and libraries for handling data like Refine, RStudio and OpenOffice Calc (usually an overlooked tool by savvy people, but really useful for quick/small stuff). Also, we've been using Scraperwiki quite a lot to quickly prototype and save data results online.

For data visualization and graphs, there are a lot of tools we like. Python and NumPy are pretty powerful. A few people in the community have been playing with R, but at the end of the day I still think Javascript plotting graph libs like d3, Flot, and RaphaelJS end up being used in the majority of our projects. Finally, we've been experimenting a lot with mapping, and Tilemill has been a really interesting tool to work with.
____

=== Using Data Visualization to Find Insights in Data

[quote, William S. Cleveland (from Visualizing Data, Hobart Press)]
____
Visualization is critical to data analysis. It provides a front line of attack, revealing intricate structure in data that cannot be absorbed in any other way. We discover unimagined effects, and we challenge imagined ones.
____

Data by itself, consisting of bits and bytes stored in a file on a computer hard drive, is invisible. In order to be able to see and make any sense of data, we need to visualize it. In this section I'm going to use a broader understanding of the term _visualizing_, that includes even pure textual representations of data. For instance, just loading a dataset into a spreadsheet software can be considered as data visualization. The invisible data suddenly turns into a visible "picture" on our screen. Thus, the question should not be whether journalists need to visualize data or not, but which kind of visualization may be the most useful in which situation.

In other words: when does it makes sense to go beyond the table visualization? The short answer is: _almost always_. Tables alone are definitely not sufficient to give us an overview of a dataset. And tables alone don't allow us to immediately identify patterns within the data. The most common example here are geographical patterns that can only be observed after visualizing data on a map. But there are also other kinds of patterns, which we will see later in this section.

==== Using Visualization to Discover Insights

It is unrealistic to expect that data visualization tools and techniques will unleash a barrage of ready-made stories from datasets. There are no rules, no "protocol" that will guarantee us a story. Instead, I think it makes more sense to look for "insights," which can be artfully woven into stories in the hands of a good journalist.

Every new visualization is likely to give us some insights into our data. Some of those insights might be already known (but perhaps not yet proven), while other insights might be completely new or even surprising to us. Some new insights might mean the beginning of a story, while others could just be the result of errors in the data, which are most likely to be found by visualizing the data.

In order to make finding insights in data more effective, I find the process discussed in <<FIG054>> (and the rest of this section) to be very helpful.

[[FIG054]]
.Data insights: a visualization (Gregor Aisch)
image::figs/incoming/05-BB.png[float="none"]

===== Learn how to visualize data

Visualization provides a unique perspective on the dataset. You can visualize data in lots of different ways. 

Tables are very powerful when you are dealing with a relatively small number of data points. They show labels and amounts in the most structured and organized fashion and reveal their full potential when combined with the ability to sort and filter the data. Additionally, Edward Tufte suggested including small chart pieces within table columns--for instance, one bar per row or a small line chart (since then also known as a sparkline). But still, as mentioned earlier, tables clearly have their limitations. They are great to show you one-dimensional outliers like the top 10, but they are poor when it comes to comparing multiple dimensions at the same time (for instance, population per country over time).

[[FIG055]]
.Tips from Tufte: sparklines (Gregor Aisch)
image::figs/incoming/05-BC-graphical-table.png[float="none"]

Charts, in general, allow you to map dimensions in your data to visual properties of geometric shapes. There's much written about the effectiveness of individual visual properties, and the short version is this: color is difficult, position is everything. In a scatterplot, for instance, two dimensions are mapped to the to the x- and y-position. You can even display a third dimension to the color or size of the displayed symbols. Line charts are especially suited for showing temporal evolutions, while bar charts are perfect for comparing categorical data. You can stack chart elements on top of each other. If you want to compare a small number of groups in your data, displaying multiple instances of the same chart is a very powerful way (also referred to as small multiples). In all charts you can use different kinds of scales to explore different aspects in your data (e.g., linear or log scale).

In fact, most of the data we're dealing with is somehow related to actual people. The power of maps is to reconnect the data to our very physical world. Imagine a dataset of geolocated crime incidents. Crucially, you want to see _where_ the crimes happen. Also maps can reveal geographic relations within the data (e.g., a trend from North to South, or from urban to rural areas).

[[FIG056]]
.Choropleth map (Gregor Aisch)
image::figs/incoming/05-BD-choropleth.png[float="none"]

Speaking of relations, the fourth most important type of visualization is a graph. Graphs are all about showing the interconnections (edges) in your data points (nodes). The position of the nodes is then calculated by more or less complex graph layout algorithms which allow us to immediately see the structure within the network. The trick of graph visualization in general is to find a proper way to model the network itself. Not all datasets already include relations, and even if they do, it might not be the most interesting aspect to look at. Sometimes it's up to the journalist to define edges between nodes. A perfect example of this is the http://slate.me/senate-social[U.S. Senate Social Graph], whose edges connect senators that voted the same in more than 65% of the votes.

===== Analyze and interpret what you see

Once you have visualized your data, the next step is to learn something from the picture you created. You could ask yourself:

  * What can I see in this image? Is it what I expected?
  * Are there any interesting patterns?
  * What does this mean in the context of the data?

Sometimes you might end up with a visualization that, in spite of its beauty, might seem to tell you nothing of interest about your data. But there is almost always _something_ that you can learn from any visualization, however trivial.

===== Document your insights and steps

If you think of this process as a journey through the dataset, the documentation is your travel diary. It will tell you where you have traveled to, what you have seen there, and how you made your decisions for your next steps. You can even start your documentation before taking your first look at the data.

In most cases when we start to work with a previously unseen dataset, we are already full of expectations and assumptions about the data. Usually there is a reason why we are interested in that dataset that we are looking at. It's a good idea to start the documentation by writing down these initial thoughts. This helps us to identify our bias and reduces the risk of misinterpretation of the data by just finding what we originally wanted to find.

I really think that the documentation is the most important step of the process--and it is also the one we're most likely to tend to skip. As you will see in the example below, the described process involves a lot of plotting and data wrangling. Looking at a set of 15 charts you created might be very confusing, especially after some time has passed. In fact, those charts are only valuable (to you or any other person you want to communicate your findings) if presented in the context in which they have been created. Hence you should take the time to make some notes on things like:

  * Why have I created this chart?
  * What have I done to the data to create it?
  * What does this chart tell me?

===== Transform data

Naturally, with the insights that you have gathered from the last visualization, you might have an idea of what you want to see next. You might have found some interesting pattern in the dataset which you now want to inspect in more detail.

Possible transformations are:

Zooming::
  To have look at a certain detail in the visualization
Aggregation::
  To combine many data points into a single group
Filtering::
  To (temporarily) remove data points that are not in our major focus
Outlier removal::
  To get rid of single points that are not representative for 99% of the dataset.

Let's consider that you have visualized a graph, and what came out of this was nothing but a mess of nodes connected through hundreds of edges (a very common result when visualizing so-called 'densely connected networks'). One common transformation step would be to filter some of the edges. If, for instance, the edges represent money flows from donor countries to recipient countries, we could remove all flows below a certain amount.

==== Which Tools to Use

The question of tools is not an easy one. Every data visualization tool available is good at something. Visualization and data wrangling should be easy and cheap. If changing parameters of the visualizations takes you hours, you won't experiment that much. That doesn't necessarily mean that you don't need to learn how to use the tool. But once you learned it, it should be really efficient.

It often makes a lot of sense to choose a tool that covers both the data wrangling and the data visualization issues. Separating the tasks in different tools means that you have to import and export your data very often. Here's a short list of some data visualization and wrangling tools:

  * Spreadsheets like LibreOffice, Excel or Google Docs
  * Statistical programming frameworks like R (r-project.org) or Pandas (pandas.pydata.org)
  * Geographic Information Systems (GIS) like Quantum GIS, ArcGIS, or GRASS
  * Visualization Libraries like d3.js (mbostock.github.com/d3), Prefuse (prefuse.org), or Flare (flare.prefuse.org)
  * Data wrangling tools like Google Refine or Datawrangler
  * Non-programming visualization software like ManyEyes or Tableau Public (tableausoftware.com/products/public)

The sample visualizations in the next section were created using R, which is kind of a Swiss Army knife of (scientific) data visualization.

==== An Example: Making Sense of US Election Contribution Data

Let us have look at the US Presidential Campaign Finance database, which contains about 450,000 contributions to US presidential candidates. The CSV file is 60 megabytes and way too big to handle easily in a program like Excel.

In the first step I will explicitly write down my initial assumptions on the FEC contributions dataset:

  * Obama gets the most contributions (since he is the president and has the greatest popularity).
  * The number of donations increases as the time moves closer to election date.
  * Obama gets more small donations than Republican candidates.

To answer the first question, we need to _transform_ the data. Instead of each single contribution, we need to sum the total amounts contributed to each candidate. After _visualizing_ the results in a sorted table, we can confirm our assumption that Obama would raise the most money:

[options="header"]
|=======================
|Candidate | Amount ($)
|Obama, Barack | 72,453,620.39
|Romney, Mitt | 50,372,334.87
|Perry, Rick | 18,529,490.47
|Paul, Ron | 11,844,361.96
|Cain, Herman | 7,010,445.99
|Gingrich, Newt | 6,311,193.03
|Pawlenty, Timothy | 4,202,769.03
|Huntsman, Jon | 2,955,726.98
|Bachmann, Michelle | 2,607,916.06
|Santorum, Rick | 1,413,552.45
|Johnson, Gary Earl | 413,276.89
|Roemer, Charles E. 'Buddy' III | 291,218.80
|McCotter, Thaddeus G | 37,030.00
|=======================

Even though this table shows  the minimum and maximum amounts and the order, it does not tell very much about the underlying patterns in candidate ranking. <<FIG059>> is another view on the data, a chart type that is called a "dot chart," in which we can see everything that is shown in the table _plus_ the patterns within the field. For instance, the dot chart allows us to immediately compare the distance between Obama and Romney, and Romney and Perry, without needing to subtract values. (Note: the dot chart was created using R. You can find links to the source code at the end of this chapter).

[[FIG059]]
.Visualizations to spot underlying patterns (Gregor Aisch)
image::figs/incoming/05-CC.png[float="0"]

Now, let us proceed with a bigger picture of the dataset. As a first step, I _visualized_ all contributed amounts over time in a simple plot. We can see that almost all donations are very, very small compared to three really big outliers. Further investigation reveals that these huge contributions are coming from the ``Obama Victory Fund 2012'' (also known as Super PAC) and were made on June 29th ($450k), September 29th ($1.5mio), and December 30th ($1.9mio).

[[FIG0510]]
.Three clear outliers (Gregor Aisch)
image::figs/incoming/05-DD.png[float="none"]

While the contributions by Super PACs alone is undoubtedly the biggest story in the data, it might be also interesting to look beyond it. The point now is that these big contributions disturb our view on the smaller contributions coming from individuals, so we're going to remove them from the data. This transform is commonly known as outlier removal. After visualizing again, we can see that most of the donations are within the range of $10k and -$5k.

[[FIG0511]]
.Removing the outliers (Gregor Aisch)
image::figs/incoming/05-EE.png[float="none"]

According to the contribution limits placed by the FECA, individuals are not allowed to donate more than $2500 to each candidate. As we see in the plot, there are numerous donations made above that limit. In particular, two big contributions in May attract our attention. It seems that they are 'mirrored' in negative amounts (refunds) in June and July. Further investigation in the data reveals the following transactions:

  * On May 10, _Stephen James Davis_, San Francisco, employed at Banneker Partners (attorney), has donated *$25,800* to Obama.
  * On May 25, _Cynthia Murphy_, Little Rock, employed at the Murphy Group (public relations), has donated *$33,300* to Obama.
  * On June 15, the amount of *$30,800* was refunded to _Cynthia Murphy_, which reduced the donated amount to *$2500*.
  * On July 8, the amount *$25,800* was refunded to _Stephen James Davis_, which reduced the donated amount to $0.

What's interesting about these numbers? The $30,800 refunded to Cynthia Murphy equals the maximum amount individuals may give to national party committees per year. Maybe she just wanted to combine both donations in one transaction, which was rejected. The $25,800 refunded to Stephen James Davis possibly equals the $30,800 minus $5000 (the contribution limit to any other political committee).

Another interesting finding in the last plot is a horizontal line pattern for contributions to Republican candidates at $5000 and -$2500. To see them in more detail, I visualized just the Republican donations. The resulting graphic is one great example of patterns in data that would be invisible without data visualization.

[[FIG0512]]
.Removing outliers 2 (Gregor Aisch)
image::figs/incoming/05-FF.png[float="none"]

What we can see is that there are many $5000 donations to Republican candidates. In fact, a look up in the data returns that these are 1243 donations, which is only 0.3% of the total number of donations, but since those donations are evenly spread across time, the line appears. The interesting thing about the line is that donations by individuals were limited to $2500. Consequently, every dollar above that limit was refunded to the donors, which results in the second line pattern at -$2500. In contrast, the contributions to Barack Obama don't show a similar pattern.

[[FIG0513]]
.Removing outliers 3 (Gregor Aisch)
image::figs/incoming/05-GG.png[scale="86",float="none"]

So, it might be interesting to find out why thousands of Republican donors did not notice the donation limit for individuals. To further analyze this topic, we can have a look at the total number of $5k donations per candidate.

[[FIG0514]]
.Donations per candidate (Gregor Aisch)
image::figs/incoming/05-HH.png[scale="86",float="none"]

Of course, this is a rather distorted view since it does not consider the total amounts of donations received by each candidate. The next plot shows the percentage of $5k donations per candidate.

[[FIG0515]]
.Where does the senator's money come from?: donations per candidate (Gregor Aisch)
image::figs/incoming/05-II.png[scale="88",float="none"]

==== What To Learn From This

Often, such a visual analysis of a new dataset feels like an exciting journey to an unknown country. You start as a foreigner with just the data and your assumptions, but with every step you make, with every chart you render, you get new insights about the topic. Based on those insights, you make decisions for your next steps and what issues are worth further investigation. As you might have seen in this chapter, this process of visualizing, analyzing and transformation of data could be repeated nearly infinitely.

==== Get the Source Code

All of the charts shown in this chapter were created using the wonderful and powerful software R. Created mainly as a scientific visualization tool, it is hard to find any visualization or data wrangling technique that is not already built into R. For those who are interested in how to visualize and wrangle data using R, here's the source code of the charts generated in this chapter:

  * https://gist.github.com/1769733[dotchart: contributions per candidate]
  * https://gist.github.com/1816161[plot: all contributions over time]
  * https://gist.github.com/1816169[plot: contributions by authorized committees]

There is also a wide range of books and tutorials available.

&mdash; _Gregor Aisch, Open Knowledge Foundation_
