:chapnum: 04
:figure-number: 00

[[getting_data]]
== Απόκτηση δεδομένων ==

image::figs/incoming/04-00-cover.png[float="none",role="informal"]

++++
<?dbfo-need height="1in"?>
++++

Επομένως, είστε έτοιμοι να ξεκινήσετε για πρώτη φορά την εργασία για τη δημοσιογραφία και τη χρήση των δεδομένων. Και τώρα τι; Πρώτα απ’ όλα χρειάζεστε μερικά δεδομένα. Το κεφάλαιο αυτό μελετά το από πού να τα αποκτήσετε. Μαθαίνουμε πώς να βρούμε δεδομένα στον Ιστό, πώς να τα ζητήσουμε κάνοντας χρήση νόμων περί ελευθερίας της πληροφορίας, πώς να χρησιμοποιήσουμε σαρωτές οθόνης για να συλλέξουμε δεδομένα από μη διαρθρωμένες πηγές και πώς να αξιοποιήσουμε την καταλογογράφηση του πλήθους για τη συλλογή των προσωπικών σας βάσεων δεδομένων από τους αναγνώστες σας.  Τέλος, προσέχουμε τι λέει ο νόμος σχετικά με τις επανεκδιδόμενες βάσεις δεδομένων και πώς να αξιοποιήσουμε με απλά και νόμιμα εργαλεία που επιτρέπουν σε τρίτους την επαναξιοποίηση των δεδομένων σας.

=== Ένας σύντομος οδηγός

Αναζητάτε δεδομένα για έναν συγκεκριμένο ή κάποιο θέμα; Είστε αβέβαιοι για το τι υπάρχει ή που να βρείτε κάτι; Δεν ξέρετε από πού να αρχίσετε; Σε αυτό το μέρος εξερευνούμε πώς να αρχίσουμε την ανεύρεση δημόσιων πηγών δεδομένων στον ιστό. 

==== Διευκολύνοντας την έρευνα σας

Ενώ δεν είναι πάντα εύκολο να βρεθούν, πολλές βάσεις δεδομένων στον ιστό καταλογογραφούνται από τις μηχανές αναζήτησης ανεξάρτητα από το εάν ήταν πρόθεση του εκδότη ή όχι. Ορίστε μερικές μικρές συμβουλές: 

  * Κατά την αναζήτηση δεδομένων, διασφαλίστε ότι συμπεριλαμβάνετε τόσο τους όρους αναζήτησης που σχετίζονται με το περιεχόμενο των δεδομένων που επιχειρείτε να βρείτε όσο και μερικές πληροφορίες πάνω στον τύπο ή την πηγή που θα περιμένατε να το βρείτε. Το google καθώς και άλλες μηχανές αναζήτησης επιτρέπουν την αναζήτηση με βάση τον τύπο του αρχείου. Για παράδειγμα, μπορείτε να ψάχνετε μόνο για υπολογιστικά φύλλα (με προσάρτηση στην αναζήτηση όρων όπως: “filetype:XLS filetype:CSV”), γεωδεδομένα (“filetype:shp”), ή αποσπάσματα από βάσεις δεδομένων (“filetype:MDB, filetype:SQL, filetype:DB”). Αν δε είστε περισσότερο πρόθυμοι μπορείτε να ψάχνετε και για αρχεία pdf (“filetype PDF”).
  * Επίσης μπορείτε να αναζητήσετε με μέρος του URL. Αναζητώντας στο google “inurl:downloads filetype:xls” θα επιχειρηθεί η αναζήτηση αρχείων excel που έχουν «λήψεις» στην ιστοσελίδα τους (αν βρείτε μια μόνη λήψη συχνά αξίζει να εξετάσετε τι άλλα αποτελέσματα υπάρχουν στον ίδιο φάκελο του δικτυακού διακομιστή). Μπορείτε επίσης να περιορίσετε την αναζήτηση σε ένα μοναδικό όνομα τομέα  , με το να αναζητάτε “site:agency.gov” για παράδειγμα.
  * •	Ένα άλλο κοινό μυστικό είναι να μην ψάχνετε ευθέως την βάση δεδομένων αλλά τα μέρη που μπορεί να είναι διαθέσιμα συγκεντρωμένα στοιχεία. Για παράδειγμα το “site:agency.gov Directory Listing” ενδέχεται να σας δώσει κατηγοριοποιήσεις δημιουργημένες από τον διακομιστή web με εύκολη πρόσβαση σε μη επεξεργασμένα αρχεία ενόσω το “site:agency.gov Λήψη Βάσης Δεδομένων” θα αναζητά για ηθελημένα δημιουργημένες κατηγοριοποιήσεις.
  
++++
<?dbfo-need height="2in"?>
++++

.Πηγαίνοντας κατευθείαν στην πηγή
****
Το πρώτο κόλπο που κάνω στη διαδικασία δέσμευσης ψηφιακών δεδομένων που δημοσιεύονται από ένα δημόσιο φορέα είναι το να πηγαίνω απευθείας στον κάτοχο των δεδομένων και όχι στον υπεύθυνο δημόσιων σχέσεων ή μέσω ενός αιτήματος για την ελευθερία της πληροφορίας. Θα μπορούσα να κάνω ένα τέτοιο αίτημα ή ένα αίτημα για τα δημόσια στοιχεία αλλά θα ήταν οι ρυθμοί πολύ αργοί. Είναι πιθανό δε ότι στην απάντηση που θα πάρω τα δεδομένα δεν θα έχουν τη μορφή που ζήτησα ή (όπως έχει συμβεί σε άλλες περιπτώσεις) το κυβερνητικό σώμα χρησιμοποιεί ένα προνομιακό λογισμικό και δεν μπορώ να εξάγω τα δεδομένα στην μορφή που ζήτησα. Ωστόσο, αν εξαρχής καταφέρω επιτυχημένα να φτάσω στον υπεύθυνο διαχείρισης των δεδομένων μπορώ έπειτα να ρωτήσω σχετικά με το τι είδους δεδομένα υπάρχουν πάνω στο θέμα και πως τα διατηρούν. Μπορώ να ανακαλύψω έπειτα την μορφή. Μπορώ να μιλήσω τη γλώσσα των δεδομένων και να βρω ότι χρειάζεται να ξέρω για να ζητήσω επιτυχημένα τα δεδομένα. Ποια είναι τα εμπόδια σε αυτή την προσέγγιση; Συχνά δεν μπορείς να φτάσεις σε αυτά τα άτομα. Ο αξιωματούχος δημόσιων πληροφοριών θα με θέλει να ανακατευτώ με αυτούς. Κατάλαβα πως σε αυτές τις περιπτώσεις είναι καλύτερο να προσπαθήσεις να κάνεις μια τηλεδιάσκεψη ή ακόμη καλύτερα μια προσωπική συνάντηση με αυτόν τον αξιωματούχο, τον γκουρού για τα δεδομένα και εμένα. Και μπορώ να το στήσω έτσι το θέμα που θα είναι δύσκολο για αυτούς να αρνηθούν. «Δεν θέλω να προκαλέσω δουλειά σ’αυτούς», λέω. «Δε θέλω να κάνω ένα αχρείαστο κουραστικό ή πολύ γενικό αίτημα οπότε μια συνάντηση θα με βοηθήσει να καταλάβω ακριβώς τι έχουν και πως μπορώ να ζητήσω ότι χρειάζεται.»

Αν η μέθοδος αυτή αποτύχει, η εναλλακτική μου είναι να ζητήσω πρώτα τη μορφή του αρχείου και έπειτα με αίτημα ένα λεξικό δεδομένων. Στην πραγματικότητα τότε ζητώ τα δεδομένα. Μερικές φορές θα ρωτήσω επίσης πως κρατάνε τα δεδομένα και με τι σύστημα. Με αυτό τον τρόπο ερευνώ τους τρόπους με τους οποίους τα δεδομένα μπορούν να εξαχθούν πριν κάνω το αίτημα. 

Τέλος η μεγαλύτερη επιτυχία μου έρχεται από όταν δούλευα σε μια μικρή εφημερίδα στην Μοντάνα. Χρειαζόμουν κάποια δεδομένα της επαρχίας που από ότι έμαθα δεν μπορούσαν να βγουν εκτός του κεντρικού υπολογιστή. Έκανα μια μικρή έρευνα και προσφέρθηκα να μπω και να βοηθήσω. Δούλεψα με το άτομο που ήταν υπεύθυνο για τα δεδομένα, χτίσαμε ένα μικρό κείμενο και εκτυπώσαμε τα δεδομένα σε μια δισκέτα-ήταν πολύ καιρό πριν. Είχα τα δεδομένα και η επαρχία ήταν εφοδιασμένη να παρέχει δεδομένα σε οποιονδήποτε τα ζητούσε. Δεν ήταν αυτός ο σκοπός τους αλλά χρειάζονταν να εξάγουν τα δεδομένα κατά περιστάσεις και οι ίδιοι και δεν καταλάβαιναν πλήρως το σύστημα οπότε όλοι βοηθηθήκαμε. 

&mdash; _Cheryl Philips, The Seattle Times_
****

==== Περιήγηση σε σελίδες και υπηρεσίες δεδομένων

Τα τελευταία χρόνια μερικές αφοσιωμένες πύλες ή και κόμβοι δεδομένων, καθώς και άλλοι σχετικοί με τα δεδομένα ιστότοποι έχουν εμφανιστεί στον ιστό. Αποτελούν καλές τοποθεσίες για να εξοικειωθείτε με τα είδη των δεδομένων που βρίσκονται εκεί. Για αρχή μπορεί να θέλετε να κοιτάξετε σε:

[[FIG042]]
.datacatalogs.org (Open Knowledge Foundation)
image::figs/incoming/04-01.png[float="0"]

Επίσημες πύλες δεδομένων::
  The government's willingness to release a given dataset will vary from country to country. A growing number of countries are launching data portals (inspired by the U.S.'s data.gov and the U.K.'s data.gov.uk) to promote the civic and commercial reuse of government information. An up-to-date, global index of such sites can be found at http://datacatalogs.org/[datacatalogs.org]. Another handy site is the http://www.guardian.co.uk/world-government-data[Guardian World Government Data], a meta search engine that includes many international government data catalogues.

http://thedatahub.org/[The Data Hub]::
  Μια καθοδηγούμενη από την κοινότητα πηγή που τρέχει από το Ίδρυμα Ανοιχτής Γνώσης (Open Knowledge Foundation) που καθιστά εύκολη την ανοιχτή ανεύρεση, την διανομή και επαναχρησιμοποίηση διαθέσιμων πηγών δεδομένων, ειδικά με τρόπους που είναι αυτοματοποιημένοι.
  
https://scraperwiki.com/[ScraperWiki]::
  Ένα online εργαλείο που βοηθάει στη διαδικασία εξαγωγής «χρήσιμων κομματιών δεδομένων με ευκολότερο τρόπο έτσι ώστε να μπορούν να επαναχρησιμοποιηθούν σε άλλες εφαρμογές ή να εξετάζονται διαρκώς από δημοσιογράφους και ερευνητές.» Οι περισσότεροι από τους καθαριστές και τις βάσεις δεδομένων αυτών είναι δημόσιες και μπορούν να επαναχρησιμοποιηθούν.
  
Κόμβοι δεδομένων της http://data.worldbank.org/[Παγκόσμιας Τράπεζας] και των http://data.un.org/[Ηνωμένων Εθνών]::
  Αυτές οι υπηρεσίες παρέχουν υψηλού επιπέδου για όλες τις χώρες και συχνά αναδρομικά για πολλά χρόνια.

http://buzzdata.com/[Buzzdata], http://www.infochimps.com/[Infochimps], και http://datamarket.com/[DataMarket]::
  Αναδυόμενα περιβάλλοντα εκκίνησης που αποσκοπούν στην δημιουργία κοινοτήτων σχετικά με την διανομή και επαναπώληση δεδομένων.

http://datacouch.com/[DataCouch]::
  Χώρος για να ανεβάσεις, εκκαθαρίσεις, μοιραστείς και οπτικοποιήσεις τα δεδομένα σου.

http://www.freebase.com/[Freebase]::
  Μια ενδιαφέρουσα θυγατρική της Google που παρέχει ένα οντολογικό γράφημα ανθρώπων, τοποθεσιών και πραγμάτων, δημιουργημένο από μια κοινότητα ανθρώπων που αγαπούν τα ανοιχτά δεδομένα.
  
Δεδομένα για έρευνα::
  Υπάρχουν πολυάριθμοι κρατικές και πειθαρχικές τροχοπέδες κατά την έρευνα των δεδομένων όπως το http://www.data-archive.ac.uk/[Αρχείο Δεδομένων του Ηνωμένου Βασιλείου]. Ενώ εκεί θα υπάρξουν πολλά δεδομένα που είναι ελεύθερα σε βαθμό πρόσβασης, θα υπάρχουν επίσης πολλά δεδομένα που θα απαιτούν μια εγγραφή ή κάποια που δεν μπορούν να επαναχρησιμοποιηθούν ή να αναδιανεμηθούν άνευ πρότερης αδείας.

.Παίρνοντας δεδομένα από Αρχεία εγγράφων
****
Αμέσως μετά την δημοσιοποίηση εγγράφων του Αμερικανικού στρατού σε Αφγανιστάν και Ιράκ από τη wikileaks, αποφασίσαμε να προσαρμόσουμε την ιδέα του εορτασμού της 50ης επετείου από τον Αλγερινό πόλεμο, δημοσιεύοντας τα Ημερολόγια Πολέμου από την Αλγερία. Ξεκινήσαμε να συλλέγουμε και να ψηφιοποιούμε τα αρχεία του γαλλικού στρατού στην Αλγερία. Τα αρχεία αυτά είναι διαθέσιμα στο αρχείο του Υπουργείου πολεμικών επιχειρήσεων στη Γαλλία, στο Παρίσι αν και βρίσκονται σε έντυπη μορφή. Στείλαμε δημοσιογράφους και φοιτητές να τραβήξουν φωτογραφίες των εγγράφων. Προσπαθήσαμε να κάνουμε σάρωση με έναν φορητό σαρωτή Canon P-150 αλλά δεν είχε αποτέλεσμα καθώς πολλά από τα αρχεία είναι συρραμμένα.

Εντέλει περίπου 10.000 σελίδες συλλέγησαν σε μερικές εβδομάδες. Τρέξαμε ένα λογισμικό αναγνώρισης κειμένου πάνω τους (ABBYY FineReader) το οποίο όμως απέδωσε ελάχιστα. Επιπλέον το υπουργείο συμπτωματικά αρνήθηκε την πρόσβαση στα πιο ενδιαφέροντα κουτιά αρχείων. Κυρίως όμως, το υπουργείο απαγορεύει σε οποιονδήποτε να αναδημοσιεύσει έγγραφα τα οποία μπορούν να φωτογραφηθούν στο μέρος που βρίσκονται, επομένως αποφασίσαμε ότι δεν άξιζε το ρίσκο και το έργο θα έμπαινε σε αναμονή.

&mdash; _Nicolas Kayser-Bril, Journalism++_
****

==== Απευθυνθείτε σε ένα φόρουμ

Αναζητήστε για υπάρχουσες απαντήσεις ή ρωτήστε στο http://getthedata.org/[Get the Data] ή στο http://www.quora.com/[Quora]. To Get the Data είναι μια ιστοσελίδα ερωτήσεων και απαντήσεων όπου μπορείς να ρωτήσεις ερωτήσεις σχετικά με τα δεδομένα συμπεριλαμβάνοντας το που να βρεις δεδομένα σχετικά με ένα συγκεκριμένο θέμα, πώς να ψάξεις ή πώς να ανακτήσεις μια συγκεκριμένη πηγή δεδομένων, τι εργαλεία να χρησιμοποιήσεις για να εξερευνήσεις ένα σύνολο δεδομένων με οπτικό τρόπο, πώς να καθαρίσεις τα δεδομένα ή να τα πάρεις με μια μορφή στην οποία μπορείς να τα επεξεργαστείς.

==== Ρωτήστε μια λίστα ταχυδρομείου

Οι λίστες ταχυδρομείου συνδυάζουν τη σοφία μιας ολόκληρης κοινότητας σε ένα συγκεκριμένο θέμα. Για δημοσιογράφους που ασχολούνται με τα δεδομένα, οι λίστες http:/bit.ly/ddj-list[Data-Driven Journalism] και http://bit.ly/nicar-subscribe/[NICAR-L] είναι εξαιρετικές αφετηρίες. Και οι δύο λίστες είναι γεμάτες με δημοσιογράφους στο θέμα των δεδομένων και ειδικούς στο ρεπορτάζ με τη βοήθεια υπολογιστή που δουλεύουν σε κάθε είδος εργασιών. Είναι πιθανό κάποιος να έχει εξερευνήσει μια ιστορία σαν τη δική σου και να ξέρει από πού να ξεκινήσει-αν όχι έναν σύνδεσμο που οδηγεί κατευθείαν στα δεδομένα. Μπορείς επίσης να δοκιμάσεις το http://project-wombat.org[Project Wombat] («μια λίστα συζήτησης για δύσκολες ερωτήσεις παραπομπών), τις πολλές the http://lists.okfn.org/mailman/listinfo[λίστες ταχυδρομείου του Open Knowledge Foundation], λίστες ταχυδρομείου στο http://theinfo.org/[theInfo] ή να αναζητήσεις για λίστες ταχυδρομείου στο θέμα ή την περιοχή που σε ενδιαφέρει.

==== Γίνετε μέλος στους Hacks/Hackers

Οι http://hackshackers.com/[Hacks/Hackers] είναι μια ταχέως επεκτεινόμενη διεθνής λαϊκή δημοσιογραφική οργάνωση με δεκάδες τμήματα και χιλιάδες μέλη σε τέσσερις ηπείρους. Η αποστολή του είναι να δημιουργήσει ένα δίκτυο δημοσιογράφων (Hacks) και τεχνολόγων (Hackers) που επανεξετάζουν το μέλλον των ειδήσεων και των πληροφοριών. Με ένα ευρύ πεδίο σαν και αυτό, υπάρχει σοβαρή πιθανότητα να ξέρει κάποιος που να ψάξετε για ότι αναζητάτε.

==== Ρωτήστε έναν ειδικό

Καθηγητές, δημόσιοι υπάλληλοι και άτομα σχετιζόμενα με τη βιομηχανία συχνά ξέρουν που να απευθυνθούν. Παρ’τους τηλέφωνο, στείλ’τους mail, πιάσ’τους την κουβέντα σε μια εκδήλωση ή εμφανίσου στο γραφείο που δουλεύουν. Ρώτα ευγενικά: «Ετοιμάζω μια ιστορία για το τάδε θέμα. Που θα μπορούσα να απευθυνθώ; Ξέρετε μήπως ποιος μπορεί να βοηθήσει;»

==== Μάθετε για την τεχνολογία πληροφοριών της Κυβέρνησης

Αντιλαμβανόμενος το τεχνικό και το διοικητικό πλαίσιο στο οποίο οι κυβερνήσεις διατηρούν τις πληροφορίες τους είναι συχνά βοηθητικό όταν επιχειρείτε την πρόσβαση σε δεδομένα. Είτε είναι CORDIS, είτε COINS, είτε THOMAS, οι βάσεις δεδομένων με μεγάλα ακρωνύμια γίνονται συχνά πιο χρήσιμες όταν έχετε καταλάβει λίγο ποιος είναι ο στόχος τους. 

Εντοπίστε διαγράμματα κυβερνητικών οργανισμών και ψάξτε για τμήματα με μια αλληλουχία στη λειτουργία τους, όπως για παράδειγμα την τεχνολογία πληροφοριών ή τις αναφορές, και έπειτα εξερευνήστε τις ιστοσελίδες τους. Πολλά από τα δεδομένα διατηρούνται σε πολλαπλά τμήματα, και μπορεί σε ένα μια βάση δεδομένων να θεωρείται η πολυτιμότερή τους αλλά σε ένα άλλο να έχετε ελεύθερη πρόσβαση.

Ψάξτε επίσης για δυναμικά πληροφοριακά γραφήματα σε ιστοσελίδες της κυβέρνησης. Συχνά τρέχουν από δομημένες πηγές δεδομένων/API πηγές που μπορούν να χρησιμοποιηθούν ανεξάρτητα, για παράδειγμα εφαρμογίδια για εντοπισμό πτήσεων εφαρμογές Java για την πρόβλεψη του καιρού. 

.Ψάχνοντας τα τηλεφωνικά αρχεία
****
Λίγους μήνες πριν, ήθελα να αναλύσω τα τηλεφωνικά αρχεία του κυβερνήτη στο Τέξας και έπειτα υποψήφιου προέδρου των ΗΠΑ, Rick Perry. Ήταν το αποτέλεσμα ενός πολυαναμενόμενου αιτήματος προς το δημόσια αρχεία. Τα δεδομένα τελικά ήρθαν σε μορφή 120 και πλέον σελίδων ποιότητας fax. Ήταν ένας κόπος που απαιτούσε εισαγωγή και εκκαθάριση δεδομένων ακολουθούμενος από μια εφαρμογή Χρυσού Οδηγού ώστε να ψάξω από την αντίστροφη τηλεφωνικούς αριθμούς.

++++
<?dbfo-need height="1in"?>
++++

Συμπυκνώνοντας τα ονόματα με τα εκλογικά δεδομένα της πολιτείας και της χώρας ανακαλύψαμε πως ο Perry επιχειρούσε να κάνει καμπάνια και έκανε δωρεές από επιτροπές πολιτικής δράσης από http://bo.st/perry-phone[υπηρεσιακά τηλέφωνα της πολιτείας], μια πρακτική που αντιμετωπίστηκε συνοφρυωμένα καθώς επέφερε ερωτήσεις τι είδους δεσμοί υπάρχουν μεταξύ αυτού και των επιτροπών πολιτικής δράσης να δουλεύουν υπέρ του.

&mdash; _Jack Gillum, Associated Press_
****

==== Αναζητώντας εκ νέου

Όταν ξέρετε περισσότερο τι ψάχνετε, ξανααναζητήστε φράσεις και γενικώς αδύναμους λεκτικούς συνδυασμούς, διαφορετικούς από αυτούς που εντοπίσατε την τελευταία φορά. Μπορεί να φανείτε περισσότερο τυχεροί με τις μηχανές αναζήτησης.

==== Στέλνοντας ένα αίτημα για την ελευθερία της πληροφόρησης

Αν πιστεύετε πως ένα τμήμα της κυβέρνησης έχει τα δεδομένα που χρειάζεστε, μπορεί το καλύτερο σας εργαλείο να είναι ένα αίτημα για την ελευθερία της πληροφόρησης. Δες στην επόμενη ενότητα για το πώς να αρχειοθετήσετε ένα. 

&mdash; _Brian Boyer (Chicago Tribune), John Keefe (WNYC), Friedrich Lindenberg (Open Knowledge Foundation), Jane Park (Creative Commons), Chrys Wu (Hacks/Hackers)_

.Όταν ο νόμος αποτυχαίνει
****
Κατόπιν ανάγνωσης ενός http://bit.ly/hygiene-inspections[ακαδημαϊκού άρθρου], που εξηγούσε πως η δημοσίευση των αποτελεσμάτων των επιθεωρήσεων υγιεινής στα εστιατόρια μείωσαν τον αριθμό των ασθενειών που είχαν να κάνουν με τη διατροφή στο Λος Άντζελες. Ρώτησα τις υπηρεσίες υγιεινής στο Παρίσι για την λίστα των επιθεωρήσεων. Ακολουθώντας την διαδικασία που προβλεπόταν για το αίτημα της ελευθερίας της πληροφορίας στη Γαλλία, περίμενα 30 μέρες για να μου αρνηθούν και μετά πήγα στην Επιτροπή για την Πρόσβαση σε Δημόσια Δεδομένα (CADA στα γαλλικά, το οποίο βασίζεται στη νομοθεσία για τα αιτήματα περί ελευθερίας της πληροφορίας. Η εν λόγω επιτροπή υποστήριξε το αίτημα μου και έστειλε εντολή στην διεύθυνση να αποδεσμεύσουν τα δεδομένα. Η διεύθυνση στη συνέχεια ζήτησε για δυο μήνες επιπλέον χρόνο, πράγμα που αποδέχθηκε η Επιτροπή. Δύο μήνες αργότερα η διεύθυνση δεν είχε κάνει τίποτα ακόμη.

Προσπάθησα να αποκτήσω κάποιους επώνυμους και ιδιαιτέρους ακριβούς συνηγόρους για τα ανοιχτά δεδομένα προκειμένου να πάμε στα δικαστήρια, υπόθεση κόστους 5000€ και με σίγουρη νίκη με την υποστήριξη της CADA, αλλά φοβήθηκαν να συμβιβάσουν τις συνδέσεις τους με επίσημα προγράμματα για τα ανοιχτά δεδομένα. Αυτό το παράδειγμα είναι ένα μεταξύ αρκετών όπου η γαλλική διοίκηση απλά αγνοεί τον νόμο και οι τοπικές πρωτοβουλίες δεν κάνουν τίποτα να υποστηρίξουν τις κοινές επικλήσεις για δεδομένα.

&mdash; _Nicolas Kayser-Bril, Journalism++_
****

++++
<?dbfo-need height="2in"?>
++++

=== Τα δικαιώματά σας ως προς τα δεδομένα

Πριν απευθύνετε ένα αίτημα για την ελευθερία της πληροφορίας πρέπει να ελέγξετε αν τα δεδομένα που ψάχνετε είναι ήδη διαθέσιμα, ή αν έχουν ήδη ζητηθεί από άλλους. Στο προηγούμενο κεφάλαιο υπάρχουν κάποιες προτάσεις για το που να κοιτάξετε. Αν έχετε κοιτάξει γύρω και ακόμη δεν έχετε πρόσβαση στα δεδομένα που χρειάζεστε, τότε ίσως να επιθυμείτε να απευθύνετε ένα επίσημο αίτημα. Ορίστε κάποιες συμβουλές που μπορεί να βοηθήσουν να γίνει το αίτημα σας πιο αποτελεσματικό.

Προνοήστε για να σώσετε χρόνο::
  Σκεφτείτε να υποβάλλετε ένα επίσημο αίτημα πρόσβασης οποτεδήποτε ξεκινάτε να ψάχνετε πληροφορίες. Είναι καλύτερα να μην περιμένετε μέχρι να εξαντληθούν όλες οι πιθανότητες. Θα κερδίσετε χρόνο με το να αποστέλλετε ένα αίτημα στην αρχή της έρευνας σας και να διεξάγετε παράλληλα τις υπόλοιπες έρευνές σας. Προετοιμαστείτε για καθυστερήσεις, μερικές φορές ο δημόσιος τομέας θέλει λίγο χρόνο για την επεξεργασία αιτημάτων, για αυτό και καλό είναι να το αναμένετε. 

Ελέγξτε τους κανονισμούς για τα κόστη::
  Προτού ξεκινήσετε να υποβάλλετε ένα αίτημα, ελέγξτε τους κανόνες για υποβολή αιτημάτων ή λήψη πληροφοριών. Με αυτόν τον τρόπο, αν ένας δημόσιος ιθύνων ξαφνικά ζητήσει χρήματα θα ξέρετε ποια είναι τα δικαιώματά σας. Μπορείτε να ζητήσετε ηλεκτρονικά έγγραφα για να αποφύγετε κόστη αντιγραφής και ανάρτησης, αναφέροντας στα αιτήματά σας ότι θα προτιμούσατε τις πληροφορίες σε ψηφιακή μορφή. Με αυτόν τον τρόπο θα αποφύγετε την καταβολή αντιτίμου εκτός φυσικά αν τα δεδομένα δεν είναι διαθέσιμα σε ψηφιακή μορφή, αν και πλέον συνηθίζεται να σαρώνονται έγγραφα που δεν έχουν ψηφιοποιηθεί ακόμα και έπειτα να αποστέλλονται ως επισύναψη στο e-mail.
  
Μάθετε τα δικαιώματά σας::
  Βρείτε ποια είναι τα δικαιώματά σας πριν ξεκινήσετε ώστε να ξέρετε ποια είναι η θέση σας και τι υποχρεούνται ή όχι να κάνουν οι δημόσιες αρχές. Για παράδειγμα οι περισσότεροι νόμοι για την ελευθερία της πληροφόρησης δίνουν ένα χρονικό διάστημα μέχρι να απαντήσουν στο αίτημα σας οι αρχές. Παγκοσμίως, το εύρος στους περισσότερους νόμους κυμαίνεται από μερικές μέρες μέχρι έναν μήνα. Βεβαιωθείτε ότι το γνωρίζετε πριν ξεκινήσετε και σημειώστε πότε υποβάλλατε το αίτημά σας.
  
Οι κυβερνήσεις δεν είναι υποχρεωμένες να επεξεργαστούν δεδομένα για σας, αλλά καλό είναι να σας δώσουν όλα τους τα δεδομένα και αν αφορά δεδομένα τα οποία οφείλουν να κατέχουν για να εκτελέσουν τις νομικές αρμοδιότητες τους, πρέπει σίγουρα να τα παράγουν για σας.

Δηλώστε πως γνωρίζετε τα δικαιώματά σας::
  Συνήθως ο νόμος δεν απαιτεί να αναφέρετε την πρόσβαση στους νόμους για τις πληροφορίες ή στην πράξη περί της ελευθερίας της πληροφορίας αλλά συνίσταται επειδή ότι έχετε επίγνωση των νομικών δικαιωμάτων σας και είναι πιθανό να ενισχύσετε την σωστή επεξεργασία των σύννομων αιτημάτων σας. Να σημειωθεί εδώ ότι για αιτήματα στην Ευρωπαϊκή Ένωση, είναι σημαντικό να αναφερθεί πως είναι αίτημα για πρόσβαση σε έγγραφα και είναι το καλύτερο να κάνετε ειδική αναφορά στον Κανονισμό 1049/2001.
  
Απλουστεύστε τη διαδικασία::
  Σε όλες τις χώρες, είναι καλύτερα να αρχίσετε με ένα απλό αίτημα για πληροφορίες και έπειτα να προσθέσετε μερικές ερωτήσεις αφότου πάρετε τις αρχικές πληροφορίες. Με αυτό τον τρόπο δεν διακινδυνεύετε ο δημόσιος θεσμός να κάνει μια μικρή προσθήκη καθώς ζητάτε κάτι «περίπλοκο».
  
Κρατήστε το στοχευμένο::
  Ένα αίτημα για πληροφορίες που εξαρτάται μόνο από ένα κομμάτι της δημόσιας αρχής θα απαντηθεί πιθανώς γρηγορότερα από ότι ένα που απαιτεί έρευνα σε όλη την αρχή. Ένα αίτημα, το οποίο εμπλέκει την αρχή σε τρίτα μέρη όπως για παράδειγμα μια ιδιωτική εταιρεία η οποία παρείχε την πληροφορία ή μια άλλη κυβέρνηση που επηρεάζεται μπορεί να πάρει ιδιαίτερα πολύ χρόνο. Εφοδιαστείτε με επιμονή.
  
Σκεφτείτε μέσα στο αρχείο αρχειοθέτησης::
  Προσπαθήστε να βρείτε τι δεδομένα συλλέγονται. Για παράδειγμα, αν σας δοθεί ένα λευκό αντίγραφο από την φόρμα που συμπληρώνει η τροχαία μετά από τροχαία ατυχήματα θα μπορέσετε έπειτα να καταλάβετε καταγράφονται ή όχι.
  
Γίνετε συγκεκριμένοι::
  Πριν υποβάλλετε το αίτημά σας, σκεφτείτε: Είναι με κάποιον τρόπο ασαφές; Αυτό είναι ιδιαίτερα σημαντικό αν σχεδιάζετε να συγκρίνετε δεδομένα από διάφορες δημόσιες αρχές. Για παράδειγμα, αν αναζητάς για στοιχεία όπως «τα περασμένα τρία χρόνια» κάποιες αρχές θα σου στείλουν πληροφορίες για τα τρία προηγούμενα ημερολογιακά χρόνια και άλλες για τα τρία προηγούμενα οικονομικά έτη, τα οποία και δεν θα είστε σε θέση να συγκρίνετε άμεσα. Αν αποφασίζετε να κρύψετε το πραγματικό σας αίτημα σε ένα πιο γενικό τότε πρέπει να διευρύνετε το αίτημά σας τόσο ώστε να περιέχει τις πληροφορίες που θέλετε αλλά όχι τόσο ευρύ ώστε να είναι ασαφές ή να αποτρέπει κάποια απάντηση. Τα ξεκάθαρα και τα καθαρά αιτήματα είθισται να λαμβάνουν γρηγορότερες και καλύτερες απαντήσεις.
  
Υποβάλλετε πολλαπλά αιτήματα::
  Αν είστε αβέβαιοι που να υποβάλλετε το αίτημά σας, δεν υπάρχει κάτι να σας σταματήσει από το να υποβάλλετε το αίτημά σας σε δύο, τρεις ή περισσότερους τομείς, την ίδια στιγμή. Σε κάποιες περιπτώσεις, οι διάφοροι τομείς θα σας δώσουν διαφορετικές απαντήσεις αλλά αυτό μπορεί και να αποβεί χρήσιμο στο να σας δώσει μια πιο καθαρή εικόνα για τις διαθέσιμες πληροφορίες στο θέμα που ερευνάτε.
  
Υποβάλλετε διεθνή αιτήματα::
  Ολοένα και αυξανόμενα, τα αιτήματα μπορούν να υποβάλλονται ηλεκτρονικά οπότε δεν έχει σημασία που ζείτε. Εναλλακτικά, αν δεν ζείτε στη χώρα εκεί όπου θέλετε να υποβάλλετε το αίτημα, μπορείτε μερικές φορές να αποστείλετε αίτημα στην πρεσβεία και από εκεί πρέπει να το μεταφέρουν στον αντίστοιχο δημόσιο τομέα. Θα χρειαστεί να ελέγξετε αν η αρμόδια πρεσβεία είναι κατ’αρχήν έτοιμη να το διεκπεραιώσει, μερικές φορές το προσωπικό τους δεν είναι εκπαιδευμένο στα δικαιώματα για τις πληροφορίες και αν είναι τέτοια υπόθεση, είναι ασφαλέστερο να υποβάλλετε το αίτημα απευθείας στον σχετικό δημόσιο τομέα.
  
Κάντε μια δοκιμή::
  Αν σχεδιάζετε να αποστείλετε το ίδιο αίτημα σε πολλούς δημόσιους τομείς, ξεκινήστε από το να αποστείλετε ένα αρχικό προσχέδιο του αιτήματος σε μερικές αρχές ως δοκιμαστική εξάσκηση. Αυτή η κίνηση θα σας δείξει αν χρησιμοποιείτε την σωστή ορολογία για να αποκτήσετε το υλικό που θέλετε και αν είναι εφικτό να απαντηθούν οι ερωτήσεις σας έτσι ώστε να τις επαναδιατυπώσετε αν χρειαστεί πριν τις στείλετε παντού. 
 
Περιμένετε τις εξαιρέσεις::
  Αν πιστεύετε πως υπάρχουν εξαιρέσεις στο αίτημά σας, τότε, όταν προετοιμάζετε τις ερωτήσεις σας, χωρίστε την ερώτηση στο μέρος που αφορά τις πιθανώς ευαίσθητες πληροφορίες από τις άλλες πληροφορίες που η κοινή λογική θα έλεγε ότι δεν είναι μέρος μιας εξαίρεσης. Τότε χωρίστε την ερώτηση σε δύο μέρη και υποβάλλετε τα δύο αιτήματα ξέχωρα.
  
Ζητήστε πρόσβαση στα αρχεία::
  Αν μένετε κοντά στο μέρος, όπου βρίσκονται οι πληροφορίες π.χ. στην πρωτεύουσα στην οποία τα έγγραφα φυλάσσονται, μπορείτε επίσης να επιθεωρήσετε τα πρωτότυπα έγγραφα, πράγμα ιδιαιτέρως εξυπηρετικό όταν αναζητάτε πληροφορίες οι οποίες βρίσκονται σε μεγάλο αριθμό εγγράφων που θα θέλατε να ρίξετε μια ματιά. Μια εξέταση τέτοιου είδους πρέπει να είναι δωρεάν και να κανονιστεί σε εύλογο και βολικό για σας χρονικό διάστημα.
  
Κρατήστε αρχείο!::
  Κάντε το αίτημά σας εγγράφως και κρατήστε ένα αντίγραφο ώστε στο μέλλον να μπορείτε να δείξετε ότι το αίτημα όντως εστάλη, σε περίπτωση που ασκήσετε έφεση για το ότι δεν πήρατε ποτέ απάντηση. Επίσης δίνει απόδειξη ότι υποβάλλετε το αίτημά σας 	αν σχεδιάζετε να το κυνηγήσετε περαιτέρω.
  
Κοινοποιήστε το::
  Επιταχύνετε τις απαντήσεις με το να κοινοποιήσετε ότι υποβάλλατε αίτημα: Αν γράψετε ή μεταδώσετε μια ιστορία ότι το αίτημα έχει αποσταλεί, ασκείτε πίεση στον δημόσιο φορέα να προχωρήσει το αίτημα και να απαντήσει. Μπορείτε να ανανεώσετε τις πληροφορίες για το πότε λάβατε απάντηση στο αίτημα ή αν παρήλθε η προθεσμία και δεν υπάρχει απάντηση να γίνει θέμα είδησης. Κάνοντας το, κερδίζετε επιπλέον την ενημέρωση του κοινού σχετικά με το δικαίωμα του στην απόκτηση πληροφοριών και πως δουλεύει στην πράξη.
  
[NOTE]
====
Υπάρχουν επίσης εξαιρετικές υπηρεσίες που μπορείτε να χρησιμοποιήσετε για να κάνετε το αίτημά σας ή να δώσετε τυχόν ακόλουθες, προβαλλόμενες σε δημόσιο χώρο στον Ιστό, όπως η http://www.whatdotheyknow.com/[What Do They Know?] στους δημόσιους τομείς στο Ηνωμένο Βασίλειο, το https://fragdenstaat.de/[Frag den Staat] για τους Γερμανικούς δημόσιους τομείς, και το http://www.asktheeu.org/[Ask the EU] για τους θεσμούς της Ευρωπαϊκής Ένωσης. Η υπηρεσία http://www.alaveteli.org/[Alaveteli] βοηθάει να φέρει παρόμοιες υπηρεσίες σε δεκάδες χώρες σε όλο τον κόσμο.
====

[[FIG043]]
.What Do They Know? (My Society)
image::figs/incoming/04-AA.png[float="none"]

Εμπλέξτε συναδέλφους::
  Αν οι συνάδελφοί σας είναι σκεπτικοί σχετικά με την αξία της πρόσβασης σε αιτήματα για πληροφορίες, ένας από τους καλύτερους τρόπους για να τους πείσετε είναι να γράψετε μια ιστορία βασισμένη σε πληροφορίες που αποκτήσατε έχοντας πρόσβαση σε νόμους περί της πληροφορίας. Αναφέροντας στο τελικό άρθρο ή την τελική μετάδοση ότι χρησιμοποιήσατε τον νόμο συνίσταται ως τρόπος ενίσχυσης της αξίας του και εφιστώντας την δημόσια επίγνωση αυτού του δικαιώματος. 
  
Ζητήστε για ακαθάριστα δεδομένα::
  Αν θέλετε να αναλύσετε, ανακαλύψετε, ή να χειριστείτε δεδομένα μέσω ενός υπολογιστή, τότε πρέπει να ζητήσετε ρητά για δεδομένα σε ηλεκτρονική και ψηφιακά αναγνώσιμη μορφή. Ενδέχεται να ζητήσετε να το ξεκαθαρίσετε, για παράδειγμα, με το να συγκεκριμενοποιήσετε για παράδειγμα ότι απαιτείτε πληροφορίες σχετικά με τον προϋπολογισμό σε μα μορφή κατάλληλη για αναλύσεις με υπολογιστικό λογισμικό». Μπορεί επίσης να επιθυμείτε να ζητήσετε με σαφή τρόπο για πληροφορίες σε διαμοιρασμένη ή «κοκκιώδη» μορφή. Μπορείτε να διαβάσετε περισσότερα για αυτό σε αυτή την http://bit.ly/access-report[αναφορά].

++++
<?dbfo-need height="1in"?>
++++

Ρωτώντας για οργανισμούς εξαιρούμενους των νόμων για την ελευθερία της Πληροφορίας::
  Μπορεί να θέλετε να ανακαλύψετε μη κυβερνητικές ομάδες, ιδιωτικές εταιρείες, θρησκευτικές οργανώσεις, και/ή άλλες οργανώσεις που δεν απαιτείται να απελευθερώσετε έγγραφα με τη χρήση νόμων για την ελευθερία της Πληροφορίας. Ωστόσο, είναι πιθανό να βρείτε πληροφορίες για αυτές με το να ρωτήσετε δημόσιους τομείς που καλύπτονται από νόμους για την ελευθερία της Πληροφορίας. Για παράδειγμα, θα μπορούσατε να ρωτήσετε ένα τμήμα της κυβέρνησης ή ένα υπουργείο αν έχουν χρηματοδοτήσει ή ασχοληθεί με κάποια συγκεκριμένη ιδιωτική εταιρεία ή μη κυβερνητική ομάδα και να ζητήσετε αποδεικτικά έγγραφα. Αν χρειαστείτε περαιτέρω βοήθεια με το να κάνετε αίτημα για την ελευθερία της Πληροφορίας μπορείτε να συμβουλευτείτε το http://www.legalleaks.info/toolkit.html[Νομικό Κουτί βοήθειας των Leaks για δημοσιογράφους]. 

&mdash; _Helen Darbishire (Access Info Europe), Djordje Padejski (Knight Journalism Fellow, Stanford University), Martin Rosenbaum (BBC), and Fabrizio Scrollini (London School of Economics and Political Science)_

.Χρησιμοποιώντας (τα αιτήματα για) την ελευθερία της Πληροφορίας για να κατανοήσετε τις δαπάνες
[[foi-spending]]
****
Έχοντας χρησιμοποιήσει τα αιτήματα για την ελευθερία της Πληροφορίας σε αρκετούς διαφορετικούς τρόπους για να καλύψω την COINS, την μεγαλύτερη βάση δεδομένων του Ηνωμένου Βασιλείου, πάνω στις δαπάνες, τον προϋπολογισμό και τις οικονομικές πληροφορίες. Στις αρχές του 2010, υπήρχε μια ομιλία του George Osborne πως αν γινόταν καγκελάριος θα απελευθέρωνε την COINS για να διευκολύνει την διαφάνεια του δημόσιου θησαυροφυλακίου. Τότε έμοιαζε με καλή ιδέα να ανακαλύψω τα δεδομένα τόσο μέσα στη βάση δεδομένων όσο και στη δομή της οπότε έστειλα μερικά αιτήματα για την ελευθερία της Πληροφορίας, το ένα για το http://bit.ly/wdtk-coins-1[σχήμα της βάσης δεδομένων], το άλλο για την καθοδήγηση που έχουν οι εργαζόμενοι στο δημόσιο θησαυροφυλάκιο όταν http://bit.ly/wdtk-coins-2[δουλεύουν με την COINS] και ένα για τη σύμβαση του θησαυροφυλακίου με τον http://bit.ly/wdtk-coins-3[πάροχο της βάσης δεδομένων]. Όλα είχαν ως αποτέλεσμα την δημοσίευση χρήσιμων δεδομένων. Επίσης ζήτησα όλους τους κωδικούς δαπανών στη βάση δεδομένων, http://bit.ly/wdtk-coins-4[πράγμα που επίσης δημοσιεύτηκε]. Όλο αυτό βοήθησε στο να καταλάβω την COINS όταν έγινε ο Osborne καγκελάριος τον Μάιο του 2010 και δημοσίευσε την COINS τον Ιούνιο του 2010. Τα δεδομένα της COINS χρησιμοποιήθηκαν σε αρκετές ιστοσελίδες που ενθάρρυναν το κοινό να εξερευνήσει τα δεδομένα-συμπεριλαμβανομένου του http://openspending.org/[OpenSpending.org] και το http://coins.guardian.co.uk/coins-explorer/search[Coins Data Explorer] της Guardian.

Μετά από περαιτέρω έρευνα φάνηκε να λείπει ένα μεγάλο κομμάτι της βάσης δεδομένων. Το Σύνολο των κυβερνητικών λογαριασμών (WGA), το οποίο και είναι 1500 σύνολα λογαριασμών. Έστειλα αίτημα για την ελευθερία της πληροφορίας για να http://bit.ly/wdtk-coins-5[ζητήσω τα δεδομένα του για το 2008/2009] αλλά μάταια. Ζήτησα επίσης την αναφορά από την Ελεγκτική Υπηρεσία για το WGA, το οποίο και ήλπιζα να εξηγούσε γιατί δεν ήταν το WGA στην κατάσταση να δημοσιευτεί. Αίτημα το οποίο http://bit.ly/wdtk-coins-6[απορρίφθηκε επίσης].

Τον Δεκέμβριο του 2011, το σύνολο των κυβερνητικών λογαριασμών δημοσιεύτηκε στα αρχεία του COINS. Ωστόσο, ήθελα να επιβεβαιώσω ότι υπήρχε αρκετή καθοδήγηση ώστε να δημιουργήσω το σύνολο των λογαριασμών για τον καθένα από τους 1500 τομείς που περιλαμβάνει το εγχείρημα του WGA. Αυτό με φέρνει στον δεύτερο τρόπο που χρησιμοποίησα το αίτημα για την ελευθερία της πληροφορίας- για να βεβαιώσω ότι τα δεδομένα που κυκλοφόρησαν από την Βρετανική επιτροπή διαφάνειας είναι σαφή και περιέχει ότι θα έπρεπε. Έστειλα λοιπόν το http://bit.ly/wdtk-coins-7[αίτημα για το πλήρες σύνολο των λογαριασμών για κάθε δημόσιο τομέα στο WGA].

&mdash; _Lisa Evans, the Guardian_
****

=== To wobbing αποδίδει. Χρησιμοποιήστε το!!

H χρήση της νομοθεσίας για τις πληροφορίες-ή το Wobbing όπως λέγεται μερικές φορές- είναι ένα δυνατό εργαλείο. Αλλά χρειάζεται μέθοδο και συχνά επιμονή. Εδώ παρουσιάζονται τώρα τρία παραδείγματα που παρουσιάζουν τη δύναμη και τις προκλήσεις του wobbing, από την δουλειά μου ως ερευνητής-δημοσιογράφος.

==== Παράδειγμα 1: Αγροτικές επιχορηγήσεις

Κάθε χρόνο η Ε.Ε. πληρώνει σχεδόν 60 δις ευρώ στους αγρότες και τον πρωτογενή τομέα κάθε χρόνο. Αυτό γίνεται από τα τέλη της δεκαετίας του ’50 και η πολιτική οδηγία ήταν ότι η χρηματοδότηση βοηθάει τους φτωχότερους γεωργούς. Ωστόσο σε ένα ξέσπασμα της ελευθερίας της πληροφόρησης στη Δανία το 2004 έδειξε πως ήταν μια οδηγία και μόνο. Οι μικροκαλλιεργητές αγωνίζονταν-όπως παραπονιούνταν κατ’ιδίαν και δημόσια, και στην πραγματικότητα το μεγαλύτερο ποσό πήγαινε σε ορισμένους κραταιούς γαιοκτήμονες και στον πρωτογενή τομέα. Επομένως, προφανώς, ήθελα να μάθω αν υπάρχει κάποιο σχέδιο στην Ευρώπη.

Το καλοκαίρι του 2004, ρώτησα την Ευρωπαϊκή επιτροπή για τα δεδομένα. Κάθε χρόνο τον Φεβρουάριο, η ΕΕ λαμβάνει δεδομένα από τα κράτη-μέλη. Τα δεδομένα δείχνουν ποιος αιτείται χρηματοδότησης από την ΕΕ, πόσοι δικαιούχοι το λαμβάνουν και αν το παίρνουν για να καλλιεργήσουν γη, να αναπτύξουν την έκταση τους ή να εξάγουν γάλα-σκόνη. Σε εκείνο το χρονικό σημείο, η Επιτροπή έλαβε τα στοιχεία ως αρχεία CSV σε έναν δίσκο. Πολλά δεδομένα αλλά κατ’αρχήν εύκολα για να τα δουλέψεις. Αν μπορούσες να τα εξάγεις, αυτό ήταν. 

To 2004, η Επιτροπή αρνήθηκε να δημοσιοποιήσει τα δεδομένα. Το βασικό επιχείρημα ήταν πως τα δεδομένα αναρτήθηκαν σε μια βάση δεδομένων και ήθελε πολλή δουλειά για να ανακτηθούν. Ένα επιχείρημα που η ευρωπαϊκή Ombudsmand (Συνήγορος του Πολίτη στο ελληνικό πλαίσιο), αποκάλεσε κακοδιαχείριση. Μπορείτε να βρείτε όλα αυτά τα έγγραφα στο http://bit.ly/eu-wobbing[wobbing.eu]. Πίσω στο 2004, δεν είχαμε τον χρόνο να είμαστε νομότυποι. Θέλαμε τα δεδομένα. 

[[FIG044]]
.The Farm Subsidy website (Farmsubsidy.org)
image::figs/incoming/04-BB.png[float="0"]

Επομένως συνεργαστήκαμε άτομα σε όλη τη Ευρώπη για να βρούμε τα δεδομένα από χώρα σε χώρα. Οι Άγγλοι, οι Σουηδοί, οι Ολλανδοί συνάδελφοι τα πήραν εντός του 2005. Η Φινλανδία, η Πολωνία, η Πορτογαλία, περιοχές της Ισπανίας, η Σλοβενία και άλλες χώρες δημοσίευσαν επίσης. Ακόμη και στη δύσκολη στο wobbing Γερμανία, είχαμε την ανατροπή και έλαβα κάποια δεδομένα από την επαρχία του βόρειου Ρήνου-στη Βεστφαλία- το 2007. Έπρεπε να πάω στο δικαστήριο να πάρω τα δεδομένα- αλλά αυτό οδήγησε σε μερικά ενδιαφέροντα άρθρα στο Στερν και στο http://bit.ly/stern-wobbing[διαδικτυακό περιοδικό του Στερν]. 

Ήταν συμπτωματικό ότι η Δανία και εις το Ηνωμένο Βασίλειο ήταν οι πρώτοι που άνοιξαν τα δεδομένα; Όχι απαραίτητα. Κοιτώντας το ευρύτερο πολιτικό κάδρο, οι αγροτικές επιχορηγήσεις εκείνη τη στιγμή έπρεπε να ειδωθούν στο πλαίσιο των διαπραγματεύσεων του Παγκόσμιου Οργανισμού Εμπορίου όπου οι επιχορηγήσεις ήταν υπ’ ατμόν. Η Δανία και το Ηνωμένο Βασίλειο είναι από τις πιο φιλελεύθερες χώρες στην Ευρώπη, οπότε υπήρχαν και πολιτικές πινελιές στον καμβά της διαφάνειας πίσω απ’ αυτήν την οδηγία αυτών των χωρών. 

Η ιστορία δεν σταμάτησε εκεί: για περισσότερα επεισόδια και για τα δεδομένα δείτε: http://farmsubsidy.org/[farmsubsidy.org].

Ηθικό δίδαγμα: Κάντε αγορά δεδομένων μέσω του wobbing. Υπάρχει μια θαυμάσια διαφοροποίηση νόμων για την ελευθερία της πληροφόρησης στην Ευρώπη και πολλές διαφορετικές χώρες έχουν διαφορετικά πολιτικά ενδιαφέροντα/κίνητρα σε διαφορετικές στιγμές. Αυτό μπορείτε να το χρησιμοποιήσετε προς όφελός σας.

.Μάθετε τα δικαιώματά σας 
****
Όταν δημοσιεύετε δεδομένα, θα έπρεπε να ανησυχείτε για πνευματική ιδιοκτησία και άλλα δικαιώματα όσον αφορά στα δεδομένα; Ενώ θα πρέπει πάντα να το ξεκαθαρίζετε αυτό με την νομική ομάδα σας, σαν εμπειρικό κανόνα κρατήστε αυτό: Αν δημοσιεύονται από την κυβέρνηση, δεν θα έπρεπε να ζητάτε ούτε συγγνώμη ούτε άδεια. Αν δημοσιεύονται από έναν οργανισμό που δεν είναι αρκετά προσοδοφόρα η πώληση δεδομένων, δεν θα έπρεπε να ανησυχείτε πολύ. Αν δημοσιεύετε δεδομένα από έναν οργανισμό που βγάζει χρήματα από την πώληση δεδομένων τότε σίγουρα πρέπει να ζητήσετε άδεια.

&mdash; _Simon Rogers, the Guardian_
****

==== Παράδειγμα 2: Παρενέργειες

Είμαστε όλοι πειραματόζωα σε ότι αφορά την λήψη φαρμακευτικής αγωγής. Τα φάρμακα ενδέχεται να έχουν παρενέργειες. Όλοι το ξέρουμε. Ισοσκελίζουμε τα πιθανά οφέλη με τους πιθανούς κανόνες και αποφασίζουμε. Δυστυχώς, δεν αποτελεί συχνά μια απόφαση για την οποία είμαστε πληροφορημένοι.

++++
<?dbfo-need height="1in"?>
++++

Όταν οι έφηβοι παίρνουν ένα χάπι ενάντια στην ακμή, ελπίζουν για λείο δέρμα και όχι στην κακή διάθεση. Ώσπου συνέβη ταυτό ακριβώς με ένα φάρμακο, όπου οι νέοι έγιναν καταθλιπτικοί ως και αυτοκτονικοί μετά τη λήψη του. Ο κίνδυνος της συγκεκριμένης παρενέργειας-μια καραμπινάτη ιστορία για δημοσιογράφους-δεν ήταν εύκολα διαθέσιμη. 

Υπήρχαν δεδομένα για τις παρενέργειες. Οι παραγωγοί ανά τακτά διαστήματα οφείλουν να δίνουν πληροφορίες στις υγειονομικές αρχές για τις παρατηρηθείσες παρενέργειες. Δεσμεύονται από τις εθνικές και τις ευρωπαϊκές αρχές από τη στιγμή που κυκλοφορεί ένα φάρμακο στην αγορά.

Η αρχική έκρηξη ξεκίνησε και πάλι από τη Δανία σε εθνικό επίπεδο. Κατά τη διάρκεια μιας υπερεθνικής έρευνας από μια ομάδα Δανών, Βέλγων και Ολλανδών, η Ολλανδία τα δημοσίευσε επίσης. Ένα ακόμη παράδειγμα αγοράς δεδομένων μέσω του wobbing βοήθησε πολύ στην υπόθεσή μας να καταστήσουμε σαφές στις Ολλανδικές αρχές ότι τα δεδομένα είναι προσβάσιμα στη Δανία. 

Η ιστορία όμως είχε βάση. Στην Ευρώπη υπήρχαν αυτοκτονικοί νέοι και δυστυχώς ακόμη και αυτοκτονίες σε αρκετές χώρες ως συνέπεια του φαρμάκου. Δημοσιογράφοι, ερευνητές και η οικογένεια ενός νεαρού θύματος πίεζαν έντονα για να αποκτήσουν πρόσβαση στις πληροφορίες. Ο Ευρωπαϊκός φορέας για τον Συνήγορο του Πολίτη, (η Ombudsmand), βοήθησε να ασκηθεί πίεση για διαφάνεια στον Ευρωπαϊκό Οργανισμό Φαρμάκων και http://bit.ly/eu-ombudsman[φαίνεται ότι τα κατάφερε]. Τώρα το θέμα είναι στη δικαιοδοσία των δημοσιογράφων ώστε να εξάγουν τα δεδομένα και να μελετήσουν ενδελεχώς το υλικό. Είμαστε όλοι πειραματόζωα όπως είπε και ένας ερευνητής ή είναι όλοι οι μηχανισμοί ακέραιοι;

Ηθικά διδάγματα: Μην δέχεστε το «όχι» ως απάντηση για ζητήματα σχετικά με τη διαφάνεια. Γίνετε επίμονοι και ακολουθήστε μια ιστορία στο πέρασμα του χρόνου. Τα πράγματα μπορεί να αλλάξουν αρκετά και να επιτρέψουν καλύτερη κάλυψη βασισμένη σε καλύτερη πρόσβαση σε ένα κατοπινό σημείο. 

==== Παράδειγμα 3: Λαθραίος θάνατος

Η πρόσφατη ιστορία μπορεί να είναι τελείως οδυνηρή για ολόκληρους πληθυσμούς-ιδίως μετά από πολέμους και σε εποχές μετάβασης. Επομένως, πως μπορούν οι δημοσιογράφοι να αποκτήσουν δύσκολα δεδομένα για έρευνα όταν, για παράδειγμα, οι κερδοσκόποι του πολέμου της τελευταίας δεκαετίας είναι τώρα στην εξουσία; Αυτή είναι η δουλειά που μια ομάδα Σλοβένων, Κροατών και Βόσνιων δημοσιογράφων ξεκίνησαν να ερευνούν.

Η ομάδα ξεκίνησε να ερευνά το εμπόριο όπλων στην πρώην Γιουγκοσλαβία στις αρχές της δεκαετίας του 1990 κατά το εμπάργκο στις αρχές της δεκαετίας του 1990 που είχε επιβληθεί από τον ΟΗΕ. Η βάση της δουλειάς ήταν έγγραφα κοινοβουλευτικών ερωτήσεων επί του θέματος. Προκειμένου να στοιχειοθετηθούν οι διαδρομές του φορτίου και να καταλάβουν τη δομή του εμπορίου, οι μεταφορές έπρεπε να ανιχνευτούν από σκάφη σε λιμάνια και αριθμούς κυκλοφορίας φορτηγών.

Οι κοινοβουλευτικές επιτροπές της Σλοβενίας έκαναν διερεύνηση γύρω από το θέμα της κερδοσκοπίας από τους Βαλκανικούς πολέμους, χωρίς να οδηγηθούν σε κάποιο συμπέρασμα. Ωστόσο υπήρχε ένα εξαιρετικά πολύτιμο ίχνος ανεπίσημων εγγράφων και δεδομένων, συμπεριλαμβανομένων 6.000 σελίδων, τις οποίες η Σλοβενική ομάδα απέκτησε μέσω αιτήματος για την ελευθερία της πληροφορίας. 

Σε αυτή την περίπτωση τα δεδομένα έπρεπε να εξαχθούν από τα έγγραφα και να ταξινομηθούν σε βάσεις δεδομένων. Με την περαιτέρω προσθήκη, ανάλυση και έρευνα δεδομένων μπόρεσαν να χαρτογραφήσουν αναρίθμητες διαδρομές από http://bit.ly/kaasogmulvad-smuggling[παράνομη εμπορία όπλων]. 

Η ομάδα πέτυχε και τα αποτελέσματα είναι http://bit.ly/journalismfund-smuggling1[μοναδικά] και έχουν ήδη κερδίσει το πρώτο βραβείο. Κυρίως όμως, η ιστορία έχει σημασία για όλη την περιοχή και μπορεί εύκολα να ανευρεθεί από δημοσιογράφους άλλων χωρών από τις οποίες το θανατηφόρο φορτίο έχει περάσει.

Ηθικά διδάγματα: Συλλέξτε καλό και ακατέργαστο υλικό ακόμη και αν το βρείτε στα πιο ανέλπιστα μέρη και συνδυάστε τα με δημόσια διαθέσιμα δεδομένα.

&mdash; _Brigitte Alfter, Journalismfund.eu_

.Η Ελευθερία της πληροφορίας με φίλους
****
Πολλές χώρες των Βαλκανίων έχουν θέματα με την κυβερνητική διαφθορά. Η διαφθορά είναι ακόμη υψηλότερη σε ότι αφορά την ευθύνη των κυβερνήσεων σε αυτές τις χώρες. Για αρκετούς μήνες μια ομάδα Σέρβων δημοσιογράφων γύρω από το http://www.cins.org.rs/[κέντρο ερευνητικής δημοσιογραφίας]-με έδρα το Βελιγράδι- ζήτησαν διαφορετικούς τύπους αιτημάτων για την πληροφορία από πάνω από 30 δήμους το 2009. Πριν από αυτό, σχεδόν τίποτα, δεν ήταν προσβάσιμο δημόσια. Η ιδέα ήταν να λάβουν τα αυθεντικά κυβερνητικά αρχεία και να βάλουν τα δεδομένα σε ανοιχτά έγγραφα, να κάνουν βασικούς ελέγχους και συγκρίσεις μεταξύ των δήμων και να λάβουν τόσο τα ελάχιστα όσο και τα περισσότερα στοιχεία. Οι βασικές συνιστώσες ήταν τα στοιχεία του προϋπολογισμού, οι τακτικές και οι έκτακτες δαπάνες, οι μισθοί των αξιωματούχων, τα έξοδα μετακίνησης, ο αριθμός των εργαζόμενων, τα έξοδα κινητής τηλεφωνίας, τα ημερομίσθια, τα στοιχεία των δημόσιων προμηθειών και άλλα. Ήταν η πρώτη φορά που οι δημοσιογράφοι ζητούσαν τέτοια στοιχεία.

Το αποτέλεσμα ήταν μια περιεκτική βάση δεδομένων που ξεδιπλώνει πολλές ψευδείς εκπροσωπήσεις, παρανομίες και περιπτώσεις διαφθοράς. Μια λίστα με τους πιο καλοπληρωμένους δήμαρχους έδειξε ότι ορισμένοι εξ αυτών έπαιρναν περισσότερα χρήματα και από τον πρόεδρο της Σερβίας. Πολλοί άλλοι αξιωματούχοι ήταν ακριβοπληρωμένοι με πολλούς να λαμβάνουν τεράστιες ταξιδιωτικές αμοιβές και ημερομίσθια. Τα δυσεύρετα δημόσια δεδομένα για τις προμήθειες βοήθησαν στην επισήμανση μιας επίσημης αταξίας. Περισσότερες από 150 ιστορίες βγήκαν από τη βάση δεδομένων και πολλές από αυτές ανασύρθηκαν από πολλά μέσα τοπικής και εθνικής εμβέλειας στη Σερβία.

Μάθαμε ότι η σύγκριση των αρχείων με τα συγκρίσιμα δεδομένα από παρόμοιες κυβερνητικές οντότητες μπορούν να παρουσιάσουν αποκλίσεις και να χυθεί φως σε πιθανές περιπτώσεις διαφθοράς. Υπερβολικά και ασυνήθη έξοδα μπορούν να ανιχνευθούν μόνο μέσω της σύγκρισης.

&mdash; _Djordje Padejski, Knight Journalism Fellow, Stanford University_
****

=== Ανάκτηση πληροφοριών από το Διαδίκτυο

Έχετε δοκιμάσει τα πάντα κι όμως ακόμα δεν έχετε στα χέρια σας τα δεδομένα που θέλετε. Τα δεδομένα που ναι μεν έχετε βρει στο Διαδίκτυο, όμως αλοίμονο –δεν υπάρχει τρόπος να τα κατεβάσετε, ενώ μέχρι και το copy-paste σας εγκατέλειψε. Μην ανησυχείτε, υπάρχει ακόμα τρόπος να τα αποκτήσετε. Για παράδειγμα θα μπορούσατε:

++++
<?dbfo-need height="1in"?>
++++

  * Να πάρετε τα δεδομένα αυτά από διαδικτυακές διεπαφές (ή API)  που παρέχονται από διαδικτυακές βάσεις δεδομένων και πολλές σύγχρονες εφαρμογές (όπως το Twitter, το Facebook και πολλές άλλες). Με αυτόν τον τρόπο μπορείτε να έχετε εύκολη πρόσβαση σε δεδομένα κυβερνητικού ή εμπορικού περιεχομένου, καθώς και σε δεδομένα από μέσα κοινωνικής δικτύωσης.
  * Να εξάγετε πληροφορίες από αρχεία PDF.  Πρόκειται για δύσκολο εγχείρημα, καθώς το PDF αποτελεί γλώσσα εκτυπωτών και δε συγκρατεί πολλές πληροφορίες σχετικά με τη δομή των δεδομένων, οι οποίες εμπεριέχονται σε ένα έγγραφο. Αν και η ανάκτηση στοιχείων από αρχείο PDF δεν εξετάζεται σε αυτό το βιβλίο, υπάρχουν διάφορα εργαλεία και βοηθητικά βίντεο.
  * •	Ιστοσελίδες για screen scrape. Κατά τη διαδικασία του screen scrape, ανακτάτε πληροφορίες σχετικά με τη δομή του περιεχομένου μιας κανονικής ιστοσελίδας με τη βοήθεια μιας εφαρμογής scraping ή με τη δημιουργία κάποιου μικρού κώδικα.  Η μέθοδος αυτή μπορεί να αποτελέσει ένα σημαντικό εργαλείο με πολλαπλές δυνατότητες, αλλά απαιτεί κάποιες γνώσεις σχετικά με το διαδίκτυο.
  
Μην παραμελείτε όμως με όλες αυτές τις τεχνικές επιλογές κάποιες απλούστερες διαδικασίες: συχνά αρκεί να ψάξετε για ένα αρχείο με δεδομένα αναγνώσιμα από μηχανή ή να επικοινωνήσετε με το φορέα που διαθέτει τις πληροφορίες που θέλετε.

Αυτό το κεφάλαιο αποτελεί ένα πολύ βασικό παράδειγμα ανάκτησης πληροφοριών από ιστοσελίδα σε μορφή HTML.

==== Τι είναι τα Δεδομένα Αναγνώσιμα από Μηχανή;

Όλες αυτές οι μέθοδοι αποσκοπούν στην πρόσβαση σε δεδομένα αναγνώσιμα από μηχανή. Τα δεδομένα αυτά προορίζονται για επεξεργασία από υπολογιστή, αντί για την άμεση παρουσίασή τους στον (άνθρωπο) χρήστη. Η δομή τους σχετίζεται με τις πληροφορίες που περιέχουν και όχι με την τελική οπτική μορφή τους. Μερικά παραδείγματα τέτοιων δεδομένων αποτελούν τα CSV, XML, JSON, και τα αρχεία Excel, ενω έγγραφα του Word, σελίδες ΗΤΜL και αρχεία PDF αφορούν περισσότερο την οπτική μορφή των πληροφοριών. Για παράδειγμα, ένα αρχείο PDF αποτελεί μια μορφή γλώσσας που απευθύνεται κατευθείαν στον εκτυπωτή σας και έχει να κάνει περισσότερο με τη θέση των γραμμών και των τελείων σε μια σελίδα παρά με τους διακριτέους χαρακτήρες της.

==== Scraping Websites: Για ποιο λόγο;

O καθένας το χει επιχειρήσει: είστε σε μια ιστοσελίδα, βλέπετε έναν ενδιαφέροντα πίνακα και προσπαθείτε να τον αντιγράψετε στο Excel για να προσθέσετε αργότερα κάποια νούμερα ή να τον αποθηκεύσετε για μελλοντική χρήση. Ωστόσο, αυτό δε συμβαίνει πάντα ή μπορεί οι πληροφορίες που ζητάτε να βρίσκονται διασκορπισμένες σε πολλές διαφορετικές σελίδες. Καθώς η αντιγραφή με το χέρι είναι κουραστική, είναι πιο λογικό να χρησιμοποιήσετε έναν κώδικα. 

Το πλεονέκτημα του scraping είναι ότι εφαρμόζεται σε κάθε ιστοσελίδα, από την πρόγνωση του καιρού μέχρι τις κρατικές δαπάνες, ακόμα κι αν η σελίδα δε διαθέτει διεπαφή για πρόσβαση σε ανεπεξέργαστα δεδομένα.

==== Scrape: Τι μπορείτε και τι δεν μπορείτε να κάνετε

Υπάρχουν φυσικά και περιορισμοί στο scraping. Μερικοί από τους παράγοντες που δυσκολεύουν τη διαδικασία αυτή είναι οι εξής:

  *	Κακοφορμισμένος κώδικας HTML με καθόλου ή ελάχιστες πληροφορίες σχετικά με τη δομή (όπως σε παλαιότερες κυβερνητικές ιστοσελίδες).
  *	Συστήματα πιστοποίησης που προορίζονται για να εμποδίζουν την αυτόματη πρόσβαση (όπως οι κώδικες CAPTCHA και τα paywalls).
  *	Συστήματα session-based που χρησιμοποιούν cookies από το πρόγραμμα περιήγησης για να καταγράφουν τις δραστηριότητες του χρήστη.
  *	Έλλειψη μιας ολοκληρωμένης καταχώρησης των αντικειμένων και πιθανές αναζητήσεις με μπαλαντέρ χαρακτήρες. 
  *	Απαγόρεψη πρόσβασης στα δεδομένα από τους διαχειριστές των εξυπηρετητών 


Ένα πρόσθετο είδος περιορισμών αποτελούν τα νομικά εμπόδια: κάποιες χώρες αναγνωρίζουν τα δικαιώματα στις βάσεις δεδομένων. Ως εκ τούτου, έχετε περιορισμένο δικαίωμα αναπαραγωγής ήδη δημοσιευμένων πληροφοριών στο διαδίκτυο. Μπορείτε βέβαια να αγνοήσετε αυτήν την παράμετρο και να ενεργήσετε πάραυτα. Αυτό όμως εξαρτάται από τη δικαιοδοσία σας –μπορεί να έχετε ειδικά δικαιώματα ως δημοσιογράφος. Το scraping σε διαθέσιμα κυβερνητικά δεδομένα επιτρέπεται, καλό θα ήταν όμως να είστε σίγουρος, πριν τα δημοσιεύσετε. Εμπορικοί οργανισμοί –και κάποιες ΜΚΟ- είναι λιγότερο ανεκτικοί και μπορεί να ισχυριστούν ότι «σαμποτάρετε» την πολιτική τους. Άλλες πληροφορίες παραβιάζουν την ιδιωτικότητα του πολίτη και καταστρατηγούν νόμους σχετικά με το απόρρητο δεδομένων ή την επαγγελματική ηθική. 

.Επιδιόρθωση, Scraping,  Μεταγλώττιση, Εκκαθάριση
****
H δυσκολία με τον τεράστιο όγκο των βρετανικών δεδομένων δεν είναι η δημοσίευσή τους, αλλά η σύνταξή τους σε μια λειτουργική μορφή. Πολλά δεδομένα σχετικά με τη φιλοξενία, τα ενδιαφέροντα των πολιτικών και την παρασκηνιακή πολιτική δημοσιεύονται τακτικά αλλά σε μορφή που δεν ευνοεί την ανάλυσή τους.

Για κάποιες από αυτές τις πληροφορίες, υπάρχει μόνο η δύσκολη οδός: η συγκέντρωση δεκάδων αρχείων Excel με δεκάδες καταγραφές ήταν ο μόνος τρόπος για να συσταθούν λίστες με υπουργικά συνέδρια. Ωστόσο, το web scraping αποδείχτηκε εξαιρετικά χρήσιμο για άλλες πληροφορίες. 

Με τη χρήση της υπηρεσίας ScraperWiki ζητήσαμε από τους τεχνικούς που ήταν υπεύθυνοι για τους κώδικες να δημιουργήσουν έναν scraper για τις πληροφορίες στον Κατάλογο με τα ενδιαφέροντα των πολιτικών. Έτσι έγινε η μισή δουλειά μας: συγκεντρώσαμε σε μια σελίδα όλες τις πληροφορίες για τους πολιτικούς και μπορέσαμε να προχωρήσουμε στη χρονοβόρα διαδικασία της ανάλυσης και της εκκαθάρισης.

Υπηρεσίες όπως αυτή (ή εργαλεία όπως το Outwit Hub) αποτελούν πολύτιμη βοήθεια για τους δημοσιογράφους που προσπαθούν να αρχειοθετήσουν ακατάστατα και μη κωδικοποιημένα δεδομένα.

&mdash; _James Ball, the Guardian_
****

==== Εργαλεία που βοηθούν το Scrape

Τα προγράμματα για την ανάκτηση τεράστιου όγκου πληροφοριών από ιστοσελίδες αφθονούν, ενώ περιλαμβάνουν πρόσθετα φυλλομετρητή και κάποιες διαδικτυακές υπηρεσίες. Ανάλογα με το φυλλομετρητή σας, εργαλεία όπως το http://www.readability.com/[Readability] (για την ανάκτηση του κειμένου από μια σελίδα) ή το http://www.downthemall.net/[DownThemAll] (για να κατεβάζετε πολλά αρχεία ταυτόχρονα) αυτοματοποιούν κουραστικές διαδικασίες, ενώ το http://bit.ly/chrome-scraper[πρόσθετο Scraper] του Chrome δημιουργήθηκε ακριβώς για την ανάκτηση πίνακα από ιστοσελίδες. Τα πρόσθετα του κατασκευαστικού λογισμικού όπως το  http://getfirebug.com/[FireBug] (για τον Firefox, ενώ υπάρχει ήδη το αντίστοιχο πρόγραμμα για τα Chrome, Safari και  ΙΕ) σας επιτρέπουν να καταγράψετε πώς ακριβώς είναι η δομή μιας ιστοσελίδας και τι μηνύματα ανταλλάσσονται μεταξύ του προγράμματος περιήγησής σας και του εξυπηρετητή.

Το https://scraperwiki.com/[ScraperWiki] είναι μια ιστοσελίδα που σας παρέχει τη δυνατότητα να κωδικοποιήσετε scrapers σε πολλές διαφορετικές γλώσσες προγραμματισμού, όπως οι Python, Ruby και PHP. Αν θέλετε να αποφύγετε το δύσκολο εγχείρημα της δημιουργίας περιβάλλοντος προγραμματισμού στον υπολογιστή σας και θέλετε να ξεκινήσετε κατευθείαν το scraping, τότε αυτός είναι ο τρόπος. Άλλες διαδικτυακές υπηρεσίες, όπως το Google Spreadsheets και το Yahoo! Pipes σας επιτρέπουν επίσης να ανακτήσετε κάποιες πληροφορίες από ιστοσελίδες.

==== Πώς λειτουργεί ένας Web Scraper;

Οι Web Scrapers είναι συνήθως μικρά κομμάτια κώδικα γραμμένα σε μια γλώσσα προγραμματισμού όπως οι Python, Ruby ή PHP. Η επιλογή της γλώσσας εξαρτάται σε μεγάλο βαθμό από την κοινότητα στην οποία έχετε πρόσβαση: εάν κάποιος στο γραφείο τύπου ή στην πόλη σας δουλεύει ήδη με μια από αυτές τις γλώσσες, καλό θα ήταν να χρησιμοποιήσετε την ίδια. 

Παρόλο που μπορεί κάποια εύκολα προαναφερθέντα εργαλεία να είναι χρήσιμα στην αρχή, η πραγματική δυσκολία του scraping βρίσκεται στον εντοπισμό των σωστών σελίδων και των σωστών στοιχείων μέσα σε αυτές, προκειμένου να ανακτήσετε τις πληροφορίες που επιθυμείτε.  Οι διαδικασίες αυτές δε σχετίζονται με τον προγραμματισμό, αλλά με την κατανόηση της δομής της ιστοσελίδας και της βάσης δεδομένων.

Κατά την προβολή μιας ιστοσελίδας, το πρόγραμμα περιήγησής σας θα χρησιμοποιήσει δύο τεχνολογίες: την HTTP, για να επικοινωνήσει με τον εξυπηρετητή και να ζητήσει συγκεκριμένες πληροφορίες όπως έγγραφα, εικόνες ή βίντεο, και το HTML, τη γλώσσα κατασκευής ιστοσελίδων.

==== Η Ανατομία μιας Ιστοσελίδας

Κάθε ιστοσελίδα είναι δομημένη σαν μια ιεραρχία κουτιών (που ορίζονται από τις «ετικέτες» του HTML). Ένα μεγάλο κουτί περιέχει πολλά μικρότερα –για παράδειγμα, ένας πίνακας αποτελείται από μικρότερα τμήματα: τις σειρές και τα κελιά. Υπάρχουν πολλά είδη ετικέτας για διαφορετικές λειτουργίες –κάποια δημιουργούν κελιά κι άλλα πίνακες, εικόνες ή συνδέσμους. Μπορούν επίσης να έχουν πρόσθετες δυνατότητες (κάποια είναι μοναδικά αναγνωριστικά), να ανήκουν σε ομάδες, τις επωνομαζόμενες «τάξεις» που επιτρέπουν τον εντοπισμό και την καταγραφή μεμονωμένων στοιχείων σε ένα έγγραφο. Η επιλογή των κατάλληλων στοιχείων με αυτόν τον τρόπο και η ανάκτηση του περιεχομένου τους αποτελούν σημαντικά βήματα για το γράψιμο ενός scraper.

Κατά την προβολή των στοιχείων μιας ιστοσελίδας είναι δυνατός ο διαχωρισμός τους σε κουτιά μέσα σε άλλα κουτιά.

Για το scrape σε ιστοσελίδες, πρέπει να γνωρίζετε κάποια πράγματα σχετικά με τα διαφορετικά είδη στοιχείων που βρίσκονται σε ένα έγγραφο HTML. Για παράδειγμα, το στοιχείο +<table>+ περιλαμβάνει έναν πίνακα, ο οποίος έχει +<tr>+  στοιχεία (σειρές πίνακα) για τις σειρές του που με τη σειρά τους περιλαμβάνουν +<td>+ (δεδομένα πίνακα) για κάθε κελί. Το πιο κοινό στοιχείο που θα συναντήσετε είναι το +<div>+ που ουσιαστικά περιλαμβάνει κάθε στοιχείο περιεχομένου. Ο ευκολότερος τρόπος για να καταλάβετε τη σημασία των στοιχείων αυτών είναι με το πρόγραμμα http://bit.ly/developer-toolbar[developer toolbar] στο πρόγραμμα περιήγησής σας: έτσι θα μπορέσετε να δείτε οποιαδήποτε ιστοσελίδα μαζί με τον υποκείμενο κώδικά της.
To scrape web pages, you'll need to learn a bit about the different types of elements that can be in an HTML document. For example, the +<table>+ element wraps a whole table, which has +<tr>+ (table row) elements for its rows, which in turn contain +<td>+ (table data) for each cell. The most common element type you will encounter is +<div>+, which can basically mean any block of content. The easiest way to get a feel for these elements is by using the http://bit.ly/developer-toolbar[developer toolbar] in your browser: they will allow you to hover over any part of a web page and see what the underlying code is.

Oι ετικέτες μοιάζουν με βιβλιοστάτες, καθώς σηματοδοτούν την αρχή και το τέλος μιας ενότητας. Για παράδειγμα, η ετικέτα +<em>+ συμβολίζει την αρχή μιας φράσης με πλάγιους χαρακτήρες ενώ το </em> συμβολίζει το τέλος της. Εύκολο. 

==== An Example: Scraping Nuclear Incidents with Python

Το http://www-news.iaea.org/EventList.aspx[NEWS] είναι η πύλη του Διεθνούς Οργανισμού Πυρηνικής Ενέργειας (IAEA) για τα ατυχήματα ακτινοβολίας σε παγκόσμια κλίμακα (και πιθανή υποψήφια για ένταξη στην ομάδα Περίεργων Ονομάτων!). Η ιστοσελίδα περιλαμβάνει λίστες των ατυχημάτων με απλό τρόπο -σαν blog- που ευνοεί το scraping.

[[FIG045]]
.The International Atomic Energy Agency's (IAEA) portal (news.iaea.org)
image::figs/incoming/04-CC.png[float="none"]

Αρχικά, δημιουργήστε έναν καινούριο Python Scraper στο https://scraperwiki.com/[ScraperWiki]. Θα εμφανιστεί ένα έγγραφο που θα περιέχει μόνο το σκελετό ενός κώδικα. Σε άλλο παράθυρο, ανοίξτε την http://www-news.iaea.org/EventList.aspx[ιστοσελίδα του IAEA] και το developer toolbar του προγράμματος περιήγησής σας. Στην προβολή «Στοιχείων», επιχειρήστε να εντοπίσετε το στοιχείο HTML για ένα από τα αντικείμενα τίτλων. Το developer toolbar σας βοηθά να συνδέσετε τα στοιχεία της ιστοσελίδας με τον υποκείμενο κώδικα HTML.

Με την επεξεργασία της ιστοσελίδας θα ανακαλύψετε ότι οι τίτλοι αποτελούν στοιχεία +<h4>+ ενός +<table>+.  Κάθε γεγονός αποτελεί μια +<tr>+ σειρά, η οποία περιλαμβάνει μια περιγραφή και ημερομηνία. Αν επιθυμείτε να εξάγετε τους τίτλους όλων των γεγονότων, θα πρέπει να επιλέξετε κάθε σειρά  του πίνακα διαδοχικά και να πάρετε το κείμενο που περιλαμβάνεται στα στοιχεία των τίτλων. 

Προκειμένου να μετατρέψουμε αυτή τη διαδικασία σε κώδικα, χρειάζεται να κατανοήσουμε όλα τα βήματα. Για να κατανοήσετε τι βήματα απαιτούνται, ας παίξουμε ένα απλό παιχνίδι: στο παράθυρο του ScraperWiki, προσπαθήστε να γράψετε οδηγίες για τον εαυτό σας σχετικά με κάθε σας βήμα σε αυτή τη διαδικασία, σαν την εκτέλεση μιας συνταγής (ξεκινήστε κάθε γραμμή με μια δίεση, ώστε να ξέρει ο Python ότι δεν πρόκειται για πραγματικό κώδικα). Για παράδειγμα:

----
# Εντόπισε κάθε σειρά του πίνακα
# Tο Unicorn δεν πρέπει να εξέχει αριστερά.
----

Προσπαθήστε να είστε όσο το δυνατόν πιο ακριβής, υποθέτοντας ότι το πρόγραμμα δε γνωρίζει τίποτα για τη σελίδα που θέλετε να κάνετε scrape.

Συγκρίνετε αυτόν τον ψευδοκώδικα με τον πραγματικό κώδικα για το πρώτο σας scraper:

----
import scraperwiki
from lxml import html
----

Αρχικά, εισάγουμε υπάρχουσες λειτουργίες από βιβλιοθήκες –μικρά κομμάτια έτοιμου κώδικα. Το +scraperwiki+ μας επιτρέπει να κατεβάσουμε ιστοσελίδες, ενώ με το +lxml+ μπορούμε να αναλύσουμε τη δομή των εγγράφων HTML. Τα καλά νέα είναι ότι αν γράφετε scraper σε γλώσσα Python με το ScraperWiki, αυτές οι δύο γραμμές είναι πάντα ίδιες.

----
url = "http://www-news.iaea.org/EventList.aspx"
doc_text = scraperwiki.scrape(url)
doc = html.fromstring(doc_text)
----

Στη συνέχεια, ο κώδικας παράγει ένα όνομα (μεταβλητή): το +url+ και αποδίδει το URL της σελίδας IAEA ως τιμή.  Έτσι πληροφορείται ο scraper για την ύπαρξη και τη σημασία της σελίδας. Προσέξτε ότι το URL βρίσκεται σε εισαγωγικά καθώς δεν αποτελεί μέρος του κώδικα, αλλά μια σειρά, μια διαδοχή χαρακτήρων. 

Στη συνέχεια, εισάγουμε τη μεταβλητή του +url+ σε ένα λειτουργικό σύστημα, το +scraperwiki.scrape+. Το σύστημα αυτό εκτελεί μια συγκεκριμένη λειτουργία –στην περίπτωση αυτή, θα κατεβάσει μια ιστοσελίδα. Όταν ολοκληρώσει την ενέργεια αυτή, θα αναθέσει το αποτέλεσμα σε μια άλλη μεταβλητή, +doc_text+, το οποίο θα εμπεριέχει το κείμενο της ιστοσελίδας. Δεν πρόκειται για την οπτική μορφή του κειμένου που εμφανίζεται στον περιηγητή σας, αλλά για την πηγή του κώδικα μαζί με τις ετικέτες. Καθώς η μορφή αυτή παρουσιάζει δυσκολίες στην ανάλυσή της, θα χρησιμοποιήσουμε μια άλλη λειτουργία, το +html.fromstring+, για να δημιουργήσουμε μια ειδική αναπαράσταση, το μοντέλο αντικειμένων εγγράφων (DOM), ώστε να εντοπίσουμε εύκολα τα διάφορα στοιχεία. 

----
for row in doc.cssselect("#tblEvents tr"):
link_in_header = row.cssselect("h4 a").pop()
event_title = link_in_header.text
print event_title
----

Σε αυτό το τελικό στάδιο, χρησιμοποιούμε το DOM για να βρούμε κάθε σειρά στον πίνακά μας και να πάρουμε τον τίτλο του γεγονότος από την επικεφαλίδα. Επιπλέον, χρησιμοποιούμε δύο νέες λειτουργίες: μία for-loop  και μία για επιλογή στοιχείων (+.cssselect+). Η εντολή for-loop  κάνει αυτό που λέει και το όνομά της: θα διαβάσει μια λίστα αντικειμένων, δίνοντας στο καθένα ένα προσωρινό ψευδώνυμο (+row+ στην περίπτωσή μας) και μετά θα τρέξει ό,τι οδηγίες αντιστοιχούν στο καθένα. 

Η άλλη νέα λειτουργία, η επιλογή στοιχείων, χρησιμοποιεί μια ειδική γλώσσα, προκειμένου να εντοπίσει στοιχεία στο έγγραφο. Οι επιλογείς CSS αξιοποιούνται συνήθως για την προσθήκη πληροφοριών διάταξης σε στοιχεία HTML και για την ακριβή επιλογή των στοιχείων από μια σελίδα. Σε αυτήν την περίπτωση (γραμμή 6), επιλέγουμε +#tblEvents tr+,  το οποίο αντιστοιχεί στη συνέχεια κάθε +<tr>+ του πίνακα με την ταυτότητα +tblEvents+ (η δίεση συμβολίζει την ταυτότητα). Αυτή η λειτουργία θα μας δώσει μια λίστα στοιχείων +<tr>+.

Το αποτέλεσμα αυτό είναι εμφανές στην επόμενη γραμμή (7), όπου χρησιμοποιούμε έναν άλλο επιλογέα για να βρούμε το +<a>+ (έναν υπερσύνδεσμο) μέσα στο +<h4>+ (έναν τίτλο). Εδώ θέλουμε απλώς να εντοπίσουμε ένα μεμονωμένο στοιχείο (καθώς υπάρχει μόνο ένας τίτλος ανά σειρά) το οποίο πρέπει να αφαιρέσουμε από την κορυφή της λίστας του επιλογέα μας με τη λειτουργία +.pop()+.

Μερικά στοιχεία του DOM περιέχουν πραγματικό κείμενο (δηλ. κείμενο που δεν ανήκει σε γλώσσα σήμανσης) το οποίο μπορούμε να επεξεργαστούμε με την εντολή +[element].text+ στη γραμμή 8. Στο τέλος, στη γραμμή 9, τυπώνουμε το κείμενο αυτό στην κονσόλα του ScraperWiki. Αν δώσετε την εντολή run στο scraper σας, θα πρέπει στο μικρότερο παράθυρο να ξεκινήσει η καταγραφή των ονομάτων των γεγονότων που βρίσκονται στη σελίδα του ΙΑΕΑ.  

[[FIG046]]
.A scraper in action (ScraperWiki)
image::figs/incoming/04-DD.png[scale="90",float="none"]

++++
<?dbfo-need height="1in"?>
++++

Πλέον μπορείτε να δείτε πώς λειτουργεί ένας βασικός scraper: κατεβάζει την ιστοσελίδα, τη μεταγράφει σε μορφή DOM και μετά σας επιτρέπει να διαλέξετε και να ανακτήσετε συγκεκριμένο περιεχόμενο. Με βάση αυτό το σκελετό, μπορείτε να λύσετε κάποια από τα υπόλοιπα προβλήματα με τη βοήθεια του ScraperWiki και της γλώσσας Python:

  *	Μπορείτε να βρείτε τη διεύθυνση του συνδέσμου σε κάθε τίτλο γεγονότος;
  *	Μπορείτε να επιλέξετε το κουτάκι με την ημερομηνία και το μέρος με τη βοήθεια του CSS class name του και να ανακτήσετε το κείμενο του στοιχείου;
  *	Το ScraperWiki περιέχει μια μικρή βάση δεδομένων για κάθε scraper, όπου μπορείτε να αποθηκεύετε αποτελέσματα. Αντιγράψτε το αντίστοιχο παράδειγμα από τα έγγραφά τους και τροποποιήστε το, ώστε να αποθηκεύει τους τίτλους των γεγονότων, τους συνδέσμους και τις ημερομηνίες.
  *	Η λίστα με τα γεγονότα αποτελείται από πολλές σελίδες. Μπορείτε να κάνετε scrape σε όλες αυτές και να ανακτήσετε και ιστορικά γεγονότα;

Καθώς προσπαθείτε να λύσετε αυτά τα προβλήματα, μπορείτε να εξερευνήσετε παραπάνω τις δυνατότητες του ScraperWiki: υπάρχουν πολλά χρήσιμα παραδείγματα στους scrapers με δεδομένα που μπορούν ακόμα και να σας εντυπωσιάσουν. Με αυτόν τον τρόπο, δε χρειάζεται να ξεκινάτε τον scraper σας από το μηδέν: διαλέξτε απλώς κάποιον παρόμοιο, δώστε την εντολή fork  και προσαρμόστε τον στις ανάγκες του προβλήματός σας.

&mdash; _Friedrich Lindenberg, Open Knowledge Foundation_

.Scrape σε Δημόσια Βάση Δεδομένων
****
Κάποιοι Γάλλοι γιατροί έχουν τη δυνατότητα να ορίσουν οι ίδιοι τις χρεώσεις τους, με αποτέλεσμα να πληρώνει κανείς από 70 μέχρι 500 ευρώ για μια μισάωρη επίσκεψη σε έναν ογκολόγο, για παράδειγμα. Παρόλο που τα δεδομένα αυτών  των τιμολογήσεων είναι νόμιμα δημοσιευμένα, oι διαχειριστές τα έχουν αναρτήσει σε μια βάση που είναι δύσκολη κατά την πλοήγησή της. Προκειμένου να έχω μια συνολική εικόνα από τις τιμολογήσεις των γιατρών για τη Le Monde, αποφάσισα να κάνω scrape ολόκληρη τη βάση δεδομένων.

Κι εκεί άρχισαν τα βάσανα. Η πρώτη φόρμα αναζήτησης ήταν μια εφαρμογή Flash που σε ανακατηύθυνε σε μία σελίδα HTML μέσω POST request. Mε τη βοήθεια του Nicolas Kayser-Brill μας πήρε αρκετή ώρα για να ανακαλύψουμε ότι η εφαρμογή χρησιμοποιούσε μια τρίτη σελίδα ως «κρυφό» βήμα μεταξύ της φόρμας αναζήτησης και της σελίδας αποτελεσμάτων. Η σελίδα αυτή χρησίμευε στην αποθήκευση ενός cookie με εκτιμήσεις της φόρμας αναζήτησης οι οποίες ήταν μετά προσβάσιμες για τη σελίδα αποτελεσμάτων. Δε νομίζω να υπάρχει πιο πολύπλοκη διαδικασία από αυτή, αν όμως τα εντοπίσεις, τα εμπόδια ξεπερνιούνται εύκολα, με τις επιλογές της βιβλιοθήκης PHP cURL ! Η διαδικασία ανάκτησης της βάσης δεδομένων μας πήρε 10 ώρες, αλλά άξιζε.

&mdash; _Alexandre Léchenet, Le Monde_
****

++++
<?dbfo-need height="1in"?>
++++

=== Το διαδίκτυο ως πηγή δεδομένων ===

Πώς μπορείτε να μάθετε περισσότερα σχετικά με κάτι που υπάρχει μόνο στο διαδίκτυο; Είτε ψάχνετε μια διεύθυνση ηλεκτρονικού ταχυδρομείου, μια ιστοσελίδα, μια εικόνα ή ένα άρθρο της Wikipedia, στο κεφάλαιο αυτό θα σας δείξω τα εργαλεία που θα σας πουν περισσότερα για τους υπόβαθρο τους.

==== Εργαλεία Web

Καταρχάς, μερικές διαφορετικές υπηρεσίες που μπορείτε να χρησιμοποιήσετε για να ανακαλύψετε περισσότερα για μια ολόκληρη ιστοσελίδα, παρά για μια συγκεκριμένη σελίδα:

Whois::
  Αν πάτε στο http://whois.domaintools.com/[whois.domaintools.com]/  (ή αν απλά πληκτρολογήσετε  whois στο _www.example.com_ στο Terminal.app σε Mac, με μια διεύθυνση URL στη θέση της κράτησης θέσης (placeholder ) εδώ), μπορείτε να πάρετε τις βασικές πληροφορίες εγγραφής οποιασδήποτε ιστοσελίδας. Τα τελευταία χρόνια, ορισμένοι ιδιοκτήτες έχουν επιλέξει ιδιωτική εγγραφή, που κρύβει τα στοιχεία τους από την κοινή προβολή, αλλά σε πολλές περιπτώσεις θα δείτε ένα όνομα, μια διεύθυνση,  μια ηλεκτρονική διεύθυνση και έναν αριθμό τηλεφώνου για το άτομο που έχει εγγεγραφεί στην ιστοσελίδα. Μπορείτε επίσης να εισάγετε αριθμητικές διευθύνσεις IP εδώ και να πάρετε τα δεδομένα σχετικά με τον οργανισμό ή άτομο που κατέχει τον εν λόγω διακομιστή. Αυτό είναι ιδιαίτερα χρήσιμο όταν προσπαθείτε να εντοπίσετε περισσότερες πληροφορίες σχετικά με μια καταχρηστική ή με μιας κακόβουλης χρήσης μιας υπηρεσίας, δεδομένου ότι οι περισσότερες ιστοσελίδες καταγράφουν μια διεύθυνση IP για τον καθένα που έχει πρόσβαση.

Blekko::
  Η http://blekko.com/[μηχανή αναζήτησης Blekko] προσφέρει μια ασυνήθιστη ποσότητα διορατικότητας στα εσωτερικά στατιστικά στοιχεία που συγκεντρώνει από ιστοσελίδες , καθώς ανιχνεύει το Web . Εάν πληκτρολογήσετε ένα όνομα τομέα(domain) που ακολουθείται από " /seo " , θα λάβετε μια σελίδα με πληροφορίες σχετικά με αυτήν τη διεύθυνση URL . Η πρώτη καρτέλα στο <<FIG048>> σας δείχνει ποιες άλλες ιστοσελιδες συνδέονται  με το domain, με σειρά popularity . Αυτό μπορεί να είναι εξαιρετικά χρήσιμο όταν προσπαθείτε να καταλάβετε τι κάλυψη έχει ένα site, και αν θέλετε να καταλάβετε γιατί έχει υψηλή κατάταξη στα αποτελέσματα αναζήτησης του Google, με βάση αυτές τις εισερχόμενες συνδέσεις . Το <<FIG049>> δείχνει ποιες άλλες ιστοσελίδες τρέχουν από το ίδια μηχανή. Είναι κοινό για τους απατεώνες και τους spammers να ακολουθούν  τον δρόμο τους προς την νομιμότητα με την δημιουργία  πολλαπλών ιστοσελίδων οι οποίες συνδέονται  μεταξύ τους . Μοιάζουν ανεξάρτητα πεδία , και μπορεί ακόμη και να έχουν διαφορετικά στοιχεία εγγραφής , αλλά στην πραγματικότητα βρίσκονται στον ίδιο διακομιστή , επειδή αυτό είναι πολύ φθηνότερο . Αυτά τα στατιστικά στοιχεία σας δίνουν μια εικόνα για την κρυφή επιχειρηματική δομή του site που ερευνάτε.

[[FIG047]]
.The Blekko search engine (Blekko.com)
image::figs/incoming/06-PP-01.png[float="none"]

[[FIG048]]
.Understanding web popularity: who links to who? The other handy tab is "Crawl stats", especially the "Cohosted with" section. (Blekko.com)
image::figs/incoming/06-PP-02.png[float="none"]

[[FIG049]]
.Spotting web spammers and scammers (Blekko.com)
image::figs/incoming/06-PP-03.png[float="none"]

Compete.com::
  Με την εξέταση ενός μέρους  των Αμερικανών καταναλωτών, η http://www.compete.com/[compete.com] συσσωρεύει λεπτομερή στατιστικά στοιχεία χρήσης για τις περισσότερες ιστοσελίδες, και κάνει ορισμένες βασικές λεπτομέρειες ελεύθερα διαθέσιμες. Επιλέξτε την καρτέλα Site Profile και εισάγετε ένα domain (<<FIG0410>>). Θα δείτε τότε μια γραφική παράσταση της κίνησης του site  κατά το τελευταίο έτος, μαζί με αριθμητικά στοιχεία για το πόσοι άνθρωποι το έχουν επισκεφτεί, και πόσο συχνά (όπως στην εικόνα 4-10). Από τη στιγμή που βασίζονται σε έρευνες, οι αριθμοί είναι κατά προσέγγιση, αλλά έχω διαπιστώσει ότι είναι αρκετά ακριβή, σε περιπτώσεις που ήμουν σε θέση να συγκρίνω με τα εσωτερικά στατιστικά. Συγκεκριμένα, φαίνεται να είναι μια καλή πηγή όταν συγκρίνεις δύο ιστοσελίδες, δεδομένου ότι, ενώ οι απόλυτοι αριθμοί μπορεί να είναι μακριά για δύο, είναι ακόμα μια καλή αναπαράσταση της σχετικής διαφοράς τους σε δημοτικότητα. Όμως εξετάζουν μόνο τους Αμερικάνους καταναλωτές, έτσι τα δεδομένα θα είναι φτωχά για διεθνείς τοποθεσίες.

[[FIG0410]]
.Compete.com's site profile service (Compete.com)
image::figs/incoming/06-PP-04.png[float="none"]

[[FIG0411]]
.What's in vogue? What's in demand?: Hotspots on the web (Compete.com)
image::figs/incoming/06-PP-05.png[float="none"]

Αναζήτηση με την ιστοσελίδα της Google::
  Ένα χαρακτηριστικό που μπορεί να είναι εξαιρετικά χρήσιμο όταν προσπαθείτε να εξερευνήσετε όλο το περιεχόμενο σε ένα συγκεκριμένο τομέα είναι το "site:" σαν λέξη κλειδί. Αν προσθέσετε το "site: example.com"  μαζί με τη φράση αναζήτησης, το Google θα εμφανίσει αποτελέσματα μόνο από την τοποθεσία που έχετε ορίσει. Μπορείτε να το περιορίσετε κι άλλο, συμπεριλαμβάνοντας  το προθεμα των σελίδων που σας ενδιαφέρει, για παράδειγμα, "site: example.com / pages /", και θα δείτε μόνο τα αποτελέσματα που ταιριάζουν με αυτό το μοτίβο. Αυτό μπορεί να είναι εξαιρετικά χρήσιμο όταν προσπαθείτε να βρείτε πληροφορίες, τις οποίες οι ιδιοκτήτες των domain μπορεί να τις έχουν διαθέσιμες στο κοινό, χωρίς να είναι πρόθυμοι για τη δημοσιοποίηση τους, έτσι ώστε με τις σωστές λέξεις κλειδιά μπορεί να εμφανιστεί κάποιο πολύ αποκαλυπτικό υλικό.
  
==== Web Pages, Images, and Videos

Sometimes you're interested in the activity that's surrounding a particular story, rather than an entire website. The tools below give you different angles on how people are reading, responding to, copying, and sharing content on the web.

Bit.ly::
  I always turn to http://bitly.com/[bit.ly] when I want to know how people are sharing a particular link with each other. To use it, enter the URL you're interested in. Then click on the Info Page+ link. That takes you to the full statistics page (though you may need to choose "aggregrate bit.ly link" first if you're signed in to the service). This will give you an idea of how popular the page is, including activity on Facebook and Twitter, and below that you'll see public conversations about the link provided by backtype.com. I find this combination of traffic data and conversations very helpful when I'm trying to understand why a site or page is popular, and who exactly its fans are. For example, it provided me with strong evidence that the prevailing narrative about grassroots sharing and Sarah Palin was wrong.

++++
<?dbfo-need height="1in"?>
++++

Twitter::
  As the micro-blogging service becomes more widely used, it becomes more useful as a gauge of how people are sharing and talking about individual pieces of content. It's deceptively simple to discover public conversations about a link. You just paste the URL you're interested in into the search box, and then possibly hit "more tweets" to see the full set of results.

Google's Cache::
  When a page becomes controversial, the publishers may take it down or alter it without acknowledgment. If you suspect you're running into the problem, the first place to turn is Google's cache of the page as it was when it did its last crawl. The frequency of crawls is constantly increasing, so you'll have the most luck if you try this within a few hours of the suspected changes. Enter the target URL in Google's search box, and then click the triple arrow on the right of the result for that page. A graphical preview should appear, and if you're lucky, there will be a small "Cache" link at the top of it. Click that to see Google's snapshot of the page. If that has trouble loading, you can switch over to the more primitive text-only page by clicking another link at the top of the full cache page. You'll want to take a screenshot or copy-paste any relevant content you do find, since it may be invalidated at any time by a subsequent crawl.

The Internet Archive's Wayback Machine::
  If you need to know how a particular page has changed over a longer time period, like months or years, the Internet Archive runs a service called http://archive.org/web/web.php[The Wayback Machine] that periodically takes snapshots of the most popular pages on the web. You go to the site, enter the link you want to research, and if it has any copies, it will show you a calendar so you can pick the time you'd like to examine. It will then present a version of the page roughly as it was at that point. It will often be missing styling or images, but it's usually enough to understand what the focus of that page's content was then.

View Source::
  It's a bit of a long shot, but developers often leave comments or other clues in the HTML code that underlies any page. It will be on different menus depending on your browser, but there's always a "View source" option that will let you browse the raw HTML. You don't need to understand what the machine-readable parts mean, just keep an eye out for the pieces of text that are often scattered amongst them. Even if they're just copyright notices or mentions of the author's names, these can often give important clues about the creation and purpose of the page.

TinEye::
  Sometimes you really want to know the source of an image, but without clear attribution text there's no obvious way to do this with traditional search engines like Google. http://www.tineye.com/[TinEye] offers a specialized "reverse image search" process, where you give it the image you have, and it finds other pictures on the web that look very similar. Because they use image recognition to do the matching, it even works when a copy has been cropped, distorted, or compressed. This can be extremely effective when you suspect that an image that's being passed off as original or new is being misrepresented, since it can lead back to the actual source.

YouTube::
  If you click on the Statistics icon to the lower right of any video, you can get a rich set of information about its audience over time. While it's not complete, it is useful for understanding roughly who the viewers are, where they are coming from, and when.

==== Emails
If you have some emails that you're researching, you'll often want to know more details about the sender's identity and location. There isn't a good off-the-shelf tool available to help with this, but it can be very helpful to know the basics about the hidden headers included in every email message. These work like postmarks, and can reveal a surprising amount about the sender. In particular, they often include the IP address of the machine that the email was sent from, a lot like caller ID on a phone call. You can then run whois on that IP number to find out which organization owns that machine. If it turns out to be someone like Comcast or AT&T who provide connections to consumers, then you can visit MaxMind to get its approximate location.

To view these headers in Gmail, open the message and open the menu next to reply on the top right and choose "Show original".

You'll then see a new page revealing the hidden content. There will be a couple of dozen lines at the start that are words followed by a colon. The IP address you're after may be in one of these, but its name will depend on how the email was sent. If it was from Hotmail, it will be called +X-Originating-IP:+, but if it's from Outlook or Yahoo it will be in the first line starting with +Received:+.

Running the address through Whois tells me it's assigned to Virgin Media, an ISP in the UK, so I put it through MaxMind's geolocation service to discover it's coming from my home town of Cambridge. That means I can be reasonably confident this is actually my parents emailing me, not impostors!

==== Trends
If you're digging into a broad topic rather than a particular site or item, here's a couple of tools that can give you some insight:

Wikipedia Article Traffic::
  If you're interested in knowing how public interest in a topic or person has varied over time, you can actually get day-by-day viewing figures for any page on Wikipedia at http://stats.grok.se/[stats.grok.se]. This site is a bit rough and ready, but will let you uncover the information you need with a bit of digging. Enter the name you're interested in to get a monthly view of the traffic on that page. That will bring up a graph showing how many times the page was viewed for each day in the month you specify. Unfortunately you can only see one month at a time, so you'll have to select a new month and search again to see longer-term changes.

Google Insights::
  You can get a clear view into the public's search habits using http://www.google.com/insights/search/[Insights from Google] (<<FIG0412>>). Enter a couple of common search phrases, like "Justin Bieber vs Lady Gaga", and you'll see a graph of their relative number of searches over time. There's a lot of options for refining your view of the data, from narrower geographic areas, to more detail over time. The only disappointment is the lack of absolute values--you only get relative percentages, which can be hard to interpret.

[[FIG0412]]
.Google Insights (Google) 
image::figs/incoming/06-PP-06.png[float="none"]

&mdash; _Pete Warden, independent data analyst and developer_

=== Crowdsourcing Data at the Guardian Datablog

Crowdsourcing, http://en.wikipedia.org/wiki/Crowdsourcing[according to Wikipedia], is "a distributed problem-solving and production process that involves outsourcing tasks to a network of people, also known as the crowd." The following is from an interview with Simon Rogers on how the Datablog used crowdsourcing to cover the MPs' expenses scandal, drug use, and the Sarah Palin papers:

Sometimes you will get a ton of files, statistics, or reports which it is impossible for one person to go through. Also you may get hold of material that is inaccessible or in a bad format and you aren't able to do much with it. This is where crowdsourcing can help.

One thing the Guardian has got is lots of readers, lots of pairs of eyes. If there is an interesting project where we need input, then we can ask them to help us. That is what we did with the http://mps-expenses.guardian.co.uk/[MPs' Expenses]. We had 450,000 documents and very little time to do anything. So what better way than open up the task to our readership?

[[FIG0413]]
.A redacted copy of Stephen Pound's incidental expenses (the Guardian)
image::figs/incoming/04-EE.png[float="none"]

The MPs' Expenses project generated lots of tip-offs. We got more stories than data. The project was remarkably successful in terms of traffic. People really liked it.

We are currently http://bit.ly/guardian-drugs[doing something with MixMag on drug use], which has been phenomenal as well. It looks like it is going to be bigger than the British crime survey in terms of how many people come back to it, which is brilliant. 

What both of these projects have in common is that they are about issues that people really care about, so they are willing to spend time on them. A lot of the crowdsourcing we have done relies on help from obsessives. With the MPs' expenses, we had a massive amount of traffic at the beginning and it really died down. But we still have people that are obsessively going through every page looking for anomalies and stories. One person has done 30,000 pages. They know a lot of stuff.

We also used crowdsourcing with the http://bit.ly/guardian-palin-papers[Sarah Palin papers]. Again this was a great help in scouring the raw information for stories. 

In terms of generating stories crowdsourcing has worked really well for us. People really liked it and it made the Guardian look good. But in terms of generating data, we haven't used crowdsourcing so much.

Some of the crowdsourcing projects that we've done that have worked really well have been more like old-fashioned surveys. When you are asking people about their experience, about their lives, about what they've done, they work very well because people aren't as likely to make that up. They will say what they feel. When we asked people to kind of do our job for us, you have to find a framework for people to produce the data in a way you can trust them.

Regarding the reliability of data, I think the approach that http://www.oldweather.org/[Old Weather] have got is really good. They get ten people to do each entry, which is a good way to ensure accuracy. With the MPs' expenses, we tried to minimize the risk of MPs going online and editing their own records to make themselves look better. But you can't permanently guard against this. You can only really look out for certain URLs or if it's coming from the SW1 area of London. So that's a bit trickier. The data we were getting out was not always reliable. Even though stories were great, it wasn't producing raw numbers that we could confidently use.

If I were to give advice to aspiring data journalists who want to use crowdsourcing to collect data, I would encourage them do this on something that people really care about, and will continue to care about when it stops making front page headlines. Also if you make something more like a game, this can really help to engage people. When we did the expenses story a second time, it was much more like a game with individual tasks for people to do. It really helped to give people specific tasks. That made a big difference because I think if you just present people with the mountain of information to go through and say "go through this," it can make for hard and rather unrewarding work. So I think making it fun is really important.

&mdash; _Marianne Bouchart, Data Journalism Blog, interviewing Simon Rogers, the Guardian_

=== How the Datablog Used Crowdsourcing to Cover Olympic Ticketing

I think the crowdsourcing project that got the biggest response was a http://bit.ly/guardian-olympics[piece on the Olympic ticket ballot]. Thousands of people in the UK tried to get tickets for the 2012 Olympics and there was a lot of fury that people hadn't received them. People had ordered hundreds of pounds worth and were told that they'd get nothing. But no one really knew if it was just some people complaining quite loudly while actually most people were happy. So we tried to work out a way to find out.

We decided the best thing we could really do, with the absence of any good data on the topic, was to ask people. And we thought we'd have to treat it as a light thing because it wasn't a balanced sample. 

We created a Google form and http://bit.ly/guardian-olympics2[asked very specific questions]. It was actually a long form: it asked how much in value people had ordered their tickets, how much their card had been debited for, which events they went for, this kind of thing.

[[FIG0414]]
.How many Olympic tickets did you get?: the readers' results (the Guardian)
image::figs/incoming/04-FF.png[float="0"]

We put it up as a small picture on the front of the site and it was shared around really rapidly. I think this is one of the key things; you can't just think "What do I want to know for my story?", you have to think "What do people want to tell me right now?" And it's only when you tap into what people want to talk about that crowdsourcing is going to be successful. The volume of responses for this project, which is one of our first attempts at crowdsourcing, was huge. We had a thousand responses in less than an hour and seven thousand by the end of that day.

So obviously, we took presenting the results a bit more seriously at this point. Initially, we had no idea how well it would do. So we added some caveats: Guardian readers may be more wealthy than other people, people who got less than they expected might be more willing to talk to us, and so on.

We didn't know how much value the results would have. We ended up having a good seven thousand records to base our piece on, and we found that about half the people who'd asked for tickets had got nothing. We ran all of this stuff and because so many people had taken part the day before, there was a lot of interest in the results.

A few weeks later, the official summary report came out, and our numbers were shockingly close. They were almost exactly spot-on. I think partly through luck, but also because we got just so many people to respond.

If you start asking your readers about something like this on a comments thread, you will be limited in what you can do with the results. So you have to start by thinking, "What is the best tool for what I want to know?" Is it a comment thread? Or is it building an app? And if it is building an app, you have to think "Is this worth the wait? And is it worth the resources that are required to do it?"

In this case, we thought of Google Forms. If someone fills in the form, you can see the result as a row on a spreadsheet. This meant that even if it was still updating, even if results were still coming in, I could open up the spreadsheet and see all of the results straight away.

I could have tried to do the work in Google, but I downloaded it into Microsoft Excel and then did things like sort it from low to high; I also found the entries where people had written out numbers (instead of putting digits) for how much they spent, and fixed all of those. I decided to exclude as little as I could. So rather than taking only valid responses, I tried to fix what I had. Some people had used foreign currencies, so I converted them to sterling, all of which was a bit painstaking.

But the whole analysis was done in a few hours, and I knocked out the obviously silly entries. A lot of people decided to point out that they spent nothing on tickets. That's a bit facetious, but fine. That was less than a hundred out of over seven thousand entries.

Then there were a few dozen who put in obviously fake high amounts to try to distort the results. Things like ten million pounds. So that left me with a set that I could use with the normal data principles we use every day. I did what's called a "pivot table." I did some averaging. That kind of thing.

We didn't have any idea how much momentum the project would have, so it was just me working with the Sports blog editor. We put our heads together and thought this might be a fun project. We did it, start to finish, in 24 hours. We had the idea, we put something up at lunchtime, we put it on the front of the site, we saw it was proving quite popular, we kept it on the front of the site for the rest of the day, and we presented the results online the next morning.

We decided to use Google Docs because it gives complete control over the results. I didn't have to use anyone else's analytic tools. I can put it easily into a database software or into spreadsheets. When you start using specialist polling software, you are often restricted to using their tools. If the information we'd been asking for was particularly sensitive, we might have hesitated before using Google and thought about doing something "in-house." But generally, it is very easy to drop a Google Form into a Guardian page and it's virtually invisible to the user that we are using one. So it is very convenient.

In terms of advice for data journalists who want to use crowdsourcing, you have to have very specific things you want to know. Ask things that get multiple choice responses as much as possible. Try to get some basic demographics of who you are talking to so you can see if your sample might be biased. If you are asking for amounts and things like this, try in the guidance to specify that it's in digits, that they have to use a specific currency, and things like that. A lot won't, but the more you hold their hand throughout, the better. And always, always, add a comment box because a lot of people will fill out the other fields but what they really want is to give you their opinion on the story. Especially on a consumer story or an outrage.

&mdash; _Marianne Bouchart, Data Journalism Blog, interviewing James Ball, the Guardian_

=== Using and Sharing Data: the Black Letter, the Fine Print, and Reality

In this section we'll have a quick look at the state of the law with respect to data and databases, and what you can do to open up your data using readily available public licenses and legal tools. Don't let any of the following dampen your enthusiasm for data-driven journalism. Legal restrictions on data usually won't get in your way, and you can easily make sure they won't get in the way of others using data you've published.

To state the obvious, obtaining data has never been easier. Before the widespread publishing of data on the Web, even if you had identified a dataset you needed, you'd need to ask whoever had a copy to make it accessible to you, possibly involving paper and the post or a personal visit. Now, you have your computer ask their computer to send a copy to your computer. Conceptually similar, but you have a copy right now, and they (the creator or publisher) haven't done anything, and probably have no idea that you have downloaded a copy.
 
What about downloading data with a program (sometimes called ``scraping'') and terms of service (ToS)? Consider the previous paragraph: your browser is just such a program. Might ToS permit access by only certain kinds of programs? If you have inordinate amounts of time and money to spend reading such documents and perhaps asking a lawyer for advice, by all means, do. But usually, just don't be a jerk: if your program hammers a site, your network may well get blocked from accessing the site in question--and perhaps you will have deserved it. There is now a large body of practice around accessing and scraping data from the web. If you plan to do this, reading about examples at a site like ScraperWiki will give you a head start.
 
Once you have some data of interest, you can query, pore over, sort, visualize, correlate, and perform any other kind of analysis you like using your copy of the data. You can publish your analysis, which can cite any data. There's a lot to the catchphrase ``facts are free'' (as in free speech), but maybe this is only a catchphrase among those who think too much about the legalities of databases, or even more broadly (and more wonkily), data governance.

What if, being a good or aspiring-to-be-good data-driven journalist, you intend to publish not just your analysis, including some facts or data points, but also the datasets/databases you used--and perhaps added to--in conducting your analysis? Or maybe you're just curating data and haven't done any analysis (good: the world needs data curators). If you're using data collected by some other entity, there could be a hitch. (If your database is wholly assembled by you, read the next paragraph anyway as motivation for the sharing practices in the next next paragraph.)

If you're familiar with how copyright restricts creative works--if the copyright holder hasn't given permission to use a work (or the work is in the public domain or your use might be covered by exceptions and limitations such as fair use) and you use--distribute, perform, etc.&mdash;the work anyway, the copyright holder could force you to stop. Although facts are free, collections of facts can be restricted very similarly, though there's more variation in the relevant laws than there is for copyright as applied to creative works. Briefly, a database can be subject to copyright, as a creative work. In many jurisdictions, by the ``sweat of the brow,'' merely assembling a database, even in an uncreative fashion, makes the database subject to copyright. In the United States in particular, there tends to be a higher minimum of creativity for copyright to apply (Feist v. Rural, a case about a phone book, is the U.S. classic if you want to look it up). But in some jurisdictions there are also ``database rights'' that restrict databases, separate from copyright (though there is lots of overlap in terms of what is covered, in particular where creativity thresholds for copyright are nearly nonexistent). The best known of such are the European Union's _sui generis_ database rights. Again, especially if you're in Europe, you may want to make sure you have permission before publishing a database from some other entity.

Obviously such restrictions aren't the best way to grow an ecosystem of data-driven journalism (nor are they good for society at large--social scientists and others told the EU they wouldn't be before _sui generis_ came about, and studies since have shown them to be right). Fortunately, as a publisher of a database, you can remove such restrictions from the database (assuming it doesn't have elements that you don't have permission to grant further permissions around), essentially by granting permission in advance. You can do this by releasing your database under a public license or public domain dedication--just as many programmers release their code under a free and open source license, so that others can build on their code (as data-driven journalism often involves code, not just data, of course you should release your code too, so that your data collection and analysis are reproducible). There are lots of reasons for opening up your data. For example, your audience might create new visualizations or applications with it that you can link to--as the Guardian does with their data visualization Flickr pool. Your datasets can be combined with other datasets to give you and your readers greater insight into a topic. Things that others do with your data might give you leads for new stories, or ideas for stories, or ideas for other data-driven projects. And they will certainly bring you kudos.

[[FIG0415]]
.Open Data badges (Open Knowledge Foundation)
image::figs/incoming/04-GG.jpg[float="none"]

When one realizes that releasing works under public licenses is a necessity, the question becomes, which license? That tricky question will frequently be answered by the project or community whose work you're building on, or that you hope to contribute your work to--use the license they use. If you need to dig deeper, start from the set of licenses that are free and open--meaning that anyone has permission, for any use (attribution and sharing alike might be required). What the Free Software Definition and Open Source Definition do for software, the http://opendefinition.org/[Open Knowledge Definition] does for all other knowledge, including databases: define what makes a work open, and what open licenses allow users to do.
 
You can visit the Open Knowledge Definition website to see the http://opendefinition.org/licenses/[current set of licenses which qualify]. In summary, there are basically three classes of open licenses:

Public domain dedications::
  These also serve as maximally permissive licenses; there are no conditions put upon using the work.

Permissive or attribution-only licenses::
  Giving credit is the only substantial condition of these licenses.

Copyleft, reciprocal, or share-alike licenses::
  These also require that modified works, if published, be shared under the same license.

Note if you're using a dataset published by someone else under an open license, consider the above paragraph a very brief guide as to how to fulfill the conditions of that open license. The licenses you're most likely to encounter, from Creative Commons, Open Data Commons, and various governments, usually feature a summary that will easily allow you to see what the substantial conditions are. Typically the license will be noted on a web page from which a dataset may be downloaded (or ``scraped'', as of course, web pages can contain datasets) or in a conspicuous place within the dataset itself, depending on format. This marking is what you should do as well, when you open up your datasets.

Going back to the beginning, what if the dataset you need to obtain is still not available online, or behind a some kind of access control? Consider, in addition to asking for access yourself, requesting that the data to be opened up for the world to reuse. You could give some pointers to some of the great things that can happen with their data if they do this.
 
Sharing with the world might bring to mind that privacy and other considerations and regulations might come into play for some datasets. Indeed, just because open data lowers many technical and copyright and copyright-like barriers, doesn't mean you don't have to follow other applicable laws. But that's as it always was, and there are tremendous resources and sometimes protections for journalists should your common sense indicate a need to investigate those.
 
Good luck! But in all probability you'll need more of it for other areas of your project than you'll need for managing the (low) legal risks.

&mdash; _Mike Linksvayer, Creative Commons_

